{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Read Datasets<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4510 entries, 0 to 4509\n",
      "Data columns (total 17 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Unnamed: 0      4510 non-null   int64  \n",
      " 1   Text            4510 non-null   object \n",
      " 2   emoji           4510 non-null   object \n",
      " 3   Tokenized       4510 non-null   object \n",
      " 4   final_text      4494 non-null   object \n",
      " 5   text_emoji      4510 non-null   object \n",
      " 6   Pos_Word        4510 non-null   int64  \n",
      " 7   Neg_Word        4510 non-null   int64  \n",
      " 8   Total_Word      4510 non-null   int64  \n",
      " 9   Pos_Ratio       4510 non-null   float64\n",
      " 10  Neg_Ratio       4510 non-null   float64\n",
      " 11  Sentimen_Text   4510 non-null   object \n",
      " 12  Tokenize_Emoji  4510 non-null   object \n",
      " 13  Pos_Emoji       4510 non-null   int64  \n",
      " 14  Neg_Emoji       4510 non-null   int64  \n",
      " 15  Sentimen_Emoji  4510 non-null   object \n",
      " 16  Sarcasm         4510 non-null   object \n",
      "dtypes: float64(2), int64(6), object(9)\n",
      "memory usage: 599.1+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Text</th>\n",
       "      <th>emoji</th>\n",
       "      <th>Tokenized</th>\n",
       "      <th>final_text</th>\n",
       "      <th>text_emoji</th>\n",
       "      <th>Pos_Word</th>\n",
       "      <th>Neg_Word</th>\n",
       "      <th>Total_Word</th>\n",
       "      <th>Pos_Ratio</th>\n",
       "      <th>Neg_Ratio</th>\n",
       "      <th>Sentimen_Text</th>\n",
       "      <th>Tokenize_Emoji</th>\n",
       "      <th>Pos_Emoji</th>\n",
       "      <th>Neg_Emoji</th>\n",
       "      <th>Sentimen_Emoji</th>\n",
       "      <th>Sarcasm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>kawan2 sunda bersatu jemput arteria dahlan</td>\n",
       "      <td>ğŸ˜</td>\n",
       "      <td>['kawan', 'sunda', 'bersatu', 'jemput', 'arter...</td>\n",
       "      <td>kawan sunda bersatu jemput arteria dahlan</td>\n",
       "      <td>kawan sunda bersatu jemput arteria dahlan ğŸ˜</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Positif</td>\n",
       "      <td>['kawan', 'sunda', 'bersatu', 'jemput', 'arter...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Positif</td>\n",
       "      <td>Negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>arteria dahlan disidang adat sunda daerah menu...</td>\n",
       "      <td>ğŸ˜</td>\n",
       "      <td>['arteria', 'dahlan', 'sidang', 'adat', 'sunda...</td>\n",
       "      <td>arteria dahlan sidang adat sunda daerah menunt...</td>\n",
       "      <td>arteria dahlan sidang adat sunda daerah menunt...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>Positif</td>\n",
       "      <td>['arteria', 'dahlan', 'sidang', 'adat', 'sunda...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Positif</td>\n",
       "      <td>Negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>ga ditafsirkan membanding bandingkan edy arter...</td>\n",
       "      <td>ğŸ˜</td>\n",
       "      <td>['ga', 'tafsir', 'membanding', 'membandingkan'...</td>\n",
       "      <td>ga tafsir membanding membandingkan edy arteria...</td>\n",
       "      <td>ga tafsir membanding membandingkan edy arteria...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>Positif</td>\n",
       "      <td>['ga', 'tafsir', 'membanding', 'membandingkan'...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Positif</td>\n",
       "      <td>Negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>nantik ngak divhumas polri nya bilang palsu td...</td>\n",
       "      <td>ğŸ˜</td>\n",
       "      <td>['nanti', 'tidak', 'divisi humas', 'polri', '....</td>\n",
       "      <td>divisi humas polri bilang palsu mengeluarkan a...</td>\n",
       "      <td>divisi humas polri bilang palsu mengeluarkan a...</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>Negatif</td>\n",
       "      <td>['divisi', 'humas', 'polri', 'bilang', 'palsu'...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Positif</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>urut dada dech kuasa hukum tdk mengerti hukum ...</td>\n",
       "      <td>ğŸ˜</td>\n",
       "      <td>['urut', 'dada', 'deh', 'kuasa', 'hukum', 'tid...</td>\n",
       "      <td>urut dada deh kuasa hukum mengerti hukum arter...</td>\n",
       "      <td>urut dada deh kuasa hukum mengerti hukum arter...</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>28</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>Positif</td>\n",
       "      <td>['urut', 'dada', 'deh', 'kuasa', 'hukum', 'men...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Positif</td>\n",
       "      <td>Negatif</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               Text  \\\n",
       "0           0         kawan2 sunda bersatu jemput arteria dahlan   \n",
       "1           2  arteria dahlan disidang adat sunda daerah menu...   \n",
       "2           4  ga ditafsirkan membanding bandingkan edy arter...   \n",
       "3           5  nantik ngak divhumas polri nya bilang palsu td...   \n",
       "4           6  urut dada dech kuasa hukum tdk mengerti hukum ...   \n",
       "\n",
       "                           emoji  \\\n",
       "0                              ğŸ˜   \n",
       "1                              ğŸ˜   \n",
       "2                              ğŸ˜   \n",
       "3                              ğŸ˜   \n",
       "4                              ğŸ˜   \n",
       "\n",
       "                                           Tokenized  \\\n",
       "0  ['kawan', 'sunda', 'bersatu', 'jemput', 'arter...   \n",
       "1  ['arteria', 'dahlan', 'sidang', 'adat', 'sunda...   \n",
       "2  ['ga', 'tafsir', 'membanding', 'membandingkan'...   \n",
       "3  ['nanti', 'tidak', 'divisi humas', 'polri', '....   \n",
       "4  ['urut', 'dada', 'deh', 'kuasa', 'hukum', 'tid...   \n",
       "\n",
       "                                          final_text  \\\n",
       "0          kawan sunda bersatu jemput arteria dahlan   \n",
       "1  arteria dahlan sidang adat sunda daerah menunt...   \n",
       "2  ga tafsir membanding membandingkan edy arteria...   \n",
       "3  divisi humas polri bilang palsu mengeluarkan a...   \n",
       "4  urut dada deh kuasa hukum mengerti hukum arter...   \n",
       "\n",
       "                                          text_emoji  Pos_Word  Neg_Word  \\\n",
       "0        kawan sunda bersatu jemput arteria dahlan ğŸ˜         2         0   \n",
       "1  arteria dahlan sidang adat sunda daerah menunt...         5         4   \n",
       "2  ga tafsir membanding membandingkan edy arteria...         3         2   \n",
       "3  divisi humas polri bilang palsu mengeluarkan a...         4         8   \n",
       "4  urut dada deh kuasa hukum mengerti hukum arter...        14         6   \n",
       "\n",
       "   Total_Word  Pos_Ratio  Neg_Ratio Sentimen_Text  \\\n",
       "0           6   0.333333   0.000000       Positif   \n",
       "1           9   0.555556   0.444444       Positif   \n",
       "2           9   0.333333   0.222222       Positif   \n",
       "3          16   0.250000   0.500000       Negatif   \n",
       "4          28   0.500000   0.214286       Positif   \n",
       "\n",
       "                                      Tokenize_Emoji  Pos_Emoji  Neg_Emoji  \\\n",
       "0  ['kawan', 'sunda', 'bersatu', 'jemput', 'arter...          1          0   \n",
       "1  ['arteria', 'dahlan', 'sidang', 'adat', 'sunda...          1          0   \n",
       "2  ['ga', 'tafsir', 'membanding', 'membandingkan'...          1          0   \n",
       "3  ['divisi', 'humas', 'polri', 'bilang', 'palsu'...          1          0   \n",
       "4  ['urut', 'dada', 'deh', 'kuasa', 'hukum', 'men...          1          0   \n",
       "\n",
       "  Sentimen_Emoji  Sarcasm  \n",
       "0        Positif  Negatif  \n",
       "1        Positif  Negatif  \n",
       "2        Positif  Negatif  \n",
       "3        Positif  Positif  \n",
       "4        Positif  Negatif  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('Datasets_Ready.xlsx')\n",
    "\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unused column/feature\n",
    "df = df.drop(columns='Unnamed: 0')\n",
    "df = df.drop(columns='Text')\n",
    "df = df.drop(columns='emoji')\n",
    "df = df.drop(columns='Tokenized')\n",
    "df = df.drop(columns='final_text')\n",
    "df = df.drop(columns='Pos_Word')\n",
    "df = df.drop(columns='Neg_Word')\n",
    "df = df.drop(columns='Total_Word')\n",
    "df = df.drop(columns='Pos_Ratio')\n",
    "df = df.drop(columns='Neg_Ratio')\n",
    "df = df.drop(columns='Tokenize_Emoji')\n",
    "df = df.drop(columns='Pos_Emoji')\n",
    "df = df.drop(columns='Neg_Emoji')\n",
    "df = df.drop(columns='Sentimen_Emoji')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_emoji</th>\n",
       "      <th>Sentimen_Text</th>\n",
       "      <th>Sarcasm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kawan sunda bersatu jemput arteria dahlan ğŸ˜</td>\n",
       "      <td>Positif</td>\n",
       "      <td>Negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>arteria dahlan sidang adat sunda daerah menunt...</td>\n",
       "      <td>Positif</td>\n",
       "      <td>Negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ga tafsir membanding membandingkan edy arteria...</td>\n",
       "      <td>Positif</td>\n",
       "      <td>Negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>divisi humas polri bilang palsu mengeluarkan a...</td>\n",
       "      <td>Negatif</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>urut dada deh kuasa hukum mengerti hukum arter...</td>\n",
       "      <td>Positif</td>\n",
       "      <td>Negatif</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          text_emoji Sentimen_Text  Sarcasm\n",
       "0        kawan sunda bersatu jemput arteria dahlan ğŸ˜       Positif  Negatif\n",
       "1  arteria dahlan sidang adat sunda daerah menunt...       Positif  Negatif\n",
       "2  ga tafsir membanding membandingkan edy arteria...       Positif  Negatif\n",
       "3  divisi humas polri bilang palsu mengeluarkan a...       Negatif  Positif\n",
       "4  urut dada deh kuasa hukum mengerti hukum arter...       Positif  Negatif"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Duplicated Data: 120\n"
     ]
    }
   ],
   "source": [
    "print(f'Total Duplicated Data: {df.duplicated().sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Duplicated Data After Handling: 0\n"
     ]
    }
   ],
   "source": [
    "print(f'Total Duplicated Data After Handling: {df.duplicated().sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Missing Value: \n",
      "text_emoji       0\n",
      "Sentimen_Text    0\n",
      "Sarcasm          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f'Total Missing Value: \\n{df.isnull().sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Sentimen_Text'] = df['Sentimen_Text'].replace('Positif', 1)\n",
    "df['Sentimen_Text'] = df['Sentimen_Text'].replace('Negatif', 0)\n",
    "\n",
    "df['Sarcasm'] = df['Sarcasm'].replace('Positif', 1)\n",
    "df['Sarcasm'] = df['Sarcasm'].replace('Negatif', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    2244\n",
      "1    2146\n",
      "Name: Sarcasm, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['Sarcasm'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Splitting Data</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['text_emoji'].values\n",
    "y = df['Sarcasm'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Tokenization</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "maxlen = 100\n",
    "tokenizer = Tokenizer(num_words=10000, oov_token='<OOV>')\n",
    "\n",
    "tokenizer.fit_on_texts(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<OOV>': 1,\n",
       " 'ğŸ‘': 2,\n",
       " 'luhut': 3,\n",
       " 'ğŸ’©': 4,\n",
       " 'ğŸ˜': 5,\n",
       " 'indonesia': 6,\n",
       " 'cak': 7,\n",
       " 'ğŸ˜ ': 8,\n",
       " 'puan': 9,\n",
       " 'orang': 10,\n",
       " 'ğŸ’¯': 11,\n",
       " 'nun': 12,\n",
       " 'jokowi': 13,\n",
       " 'presiden': 14,\n",
       " 'binsar': 15,\n",
       " 'ğŸ‘': 16,\n",
       " 'partai': 17,\n",
       " 'ğŸ˜Š': 18,\n",
       " 'anies': 19,\n",
       " 'rakyat': 20,\n",
       " 'ğŸ˜­': 21,\n",
       " 'maharani': 22,\n",
       " 'bu': 23,\n",
       " 'ğŸ˜¨': 24,\n",
       " 'ganjar': 25,\n",
       " 'menteri': 26,\n",
       " 'prabowo': 27,\n",
       " 'pemimpin': 28,\n",
       " 'semoga': 29,\n",
       " 'aja': 30,\n",
       " 'baswedan': 31,\n",
       " 'ga': 32,\n",
       " 'negara': 33,\n",
       " 'masyarakat': 34,\n",
       " 'ğŸ˜†': 35,\n",
       " 'anak': 36,\n",
       " 'calon': 37,\n",
       " '2024': 38,\n",
       " 'ğŸ’•': 39,\n",
       " 'jakarta': 40,\n",
       " 'kalo': 41,\n",
       " 'bangsa': 42,\n",
       " 'demokrasi': 43,\n",
       " 'politik': 44,\n",
       " 'banget': 45,\n",
       " 'ketua': 46,\n",
       " 'perjuangan': 47,\n",
       " 'lucu': 48,\n",
       " 'ğŸ˜”': 49,\n",
       " 'mbak': 50,\n",
       " 'nama': 51,\n",
       " 'salah': 52,\n",
       " 'âœŒ': 53,\n",
       " 'firaun': 54,\n",
       " 'kerja': 55,\n",
       " 'israel': 56,\n",
       " 'capres': 57,\n",
       " 'beliau': 58,\n",
       " 'sih': 59,\n",
       " '1': 60,\n",
       " 'investasi': 61,\n",
       " 'ğŸ˜´': 62,\n",
       " 'mulyadi': 63,\n",
       " 'cocok': 64,\n",
       " 'program': 65,\n",
       " 'kadrun': 66,\n",
       " 'biar': 67,\n",
       " 'ri': 68,\n",
       " 'dunia': 69,\n",
       " 'dg': 70,\n",
       " 'edi': 71,\n",
       " 'lu': 72,\n",
       " 'negeri': 73,\n",
       " 'pilih': 74,\n",
       " 'gubernur': 75,\n",
       " 'nih': 76,\n",
       " 'bikin': 77,\n",
       " 'keren': 78,\n",
       " 'bagus': 79,\n",
       " 'rt': 80,\n",
       " 'bohong': 81,\n",
       " 'tau': 82,\n",
       " 'maaf': 83,\n",
       " 'bidang': 84,\n",
       " 'pilpres': 85,\n",
       " 'manusia': 86,\n",
       " 'pemerintah': 87,\n",
       " 'suka': 88,\n",
       " 'masuk': 89,\n",
       " 'hidup': 90,\n",
       " 'dukung': 91,\n",
       " 'pemilu': 92,\n",
       " 'kali': 93,\n",
       " 'kemaritiman': 94,\n",
       " 'tp': 95,\n",
       " 'bilang': 96,\n",
       " 'pencitraan': 97,\n",
       " 'emang': 98,\n",
       " 'warga': 99,\n",
       " 'maju': 100,\n",
       " 'sehat': 101,\n",
       " 'langsung': 102,\n",
       " 'berbicara': 103,\n",
       " 'sosok': 104,\n",
       " 'pakai': 105,\n",
       " 'semangat': 106,\n",
       " 'mbah': 107,\n",
       " 'allah': 108,\n",
       " 'krn': 109,\n",
       " 'koordinator': 110,\n",
       " 'lihat': 111,\n",
       " 'mas': 112,\n",
       " 'rumah': 113,\n",
       " 'hati': 114,\n",
       " 'pejabat': 115,\n",
       " 'berani': 116,\n",
       " 'dpr': 117,\n",
       " 'membangun': 118,\n",
       " 'mendukung': 119,\n",
       " 'jalan': 120,\n",
       " 'keluarga': 121,\n",
       " 'hukum': 122,\n",
       " 'pendidikan': 123,\n",
       " 'kau': 124,\n",
       " 'kayak': 125,\n",
       " 'memiliki': 126,\n",
       " 'hasil': 127,\n",
       " 'merakyat': 128,\n",
       " 'setuju': 129,\n",
       " 'cari': 130,\n",
       " 'prestasi': 131,\n",
       " 'subianto': 132,\n",
       " 'kaya': 133,\n",
       " 'nkri': 134,\n",
       " 'takut': 135,\n",
       " 'aparat': 136,\n",
       " 'mantap': 137,\n",
       " 'islam': 138,\n",
       " 'terbaik': 139,\n",
       " 'contoh': 140,\n",
       " 'uang': 141,\n",
       " 'malu': 142,\n",
       " 'bodoh': 143,\n",
       " 'muda': 144,\n",
       " 'menolak': 145,\n",
       " 'pernyataan': 146,\n",
       " 'kasih': 147,\n",
       " 'coba': 148,\n",
       " 'air': 149,\n",
       " 'penuh': 150,\n",
       " 'kesambet': 151,\n",
       " 'tuh': 152,\n",
       " 'beda': 153,\n",
       " 'perempuan': 154,\n",
       " 'caknun': 155,\n",
       " 'mimpi': 156,\n",
       " 'gitu': 157,\n",
       " 'tuhan': 158,\n",
       " 'hebat': 159,\n",
       " 'pendukung': 160,\n",
       " 'n': 161,\n",
       " 'keadilan': 162,\n",
       " 'jawa': 163,\n",
       " 'daerah': 164,\n",
       " 'yudhoyono': 165,\n",
       " 'korupsi': 166,\n",
       " 'pikir': 167,\n",
       " 'paham': 168,\n",
       " 'video': 169,\n",
       " 'politisi': 170,\n",
       " 'haman': 171,\n",
       " 'koruptor': 172,\n",
       " 'dukungan': 173,\n",
       " 'kaos': 174,\n",
       " 'palestina': 175,\n",
       " 'otak': 176,\n",
       " 'kpk': 177,\n",
       " 'bangsat': 178,\n",
       " 'tni': 179,\n",
       " '2022': 180,\n",
       " 'agama': 181,\n",
       " 'acara': 182,\n",
       " 'nilai': 183,\n",
       " 'ott': 184,\n",
       " 'goblok': 185,\n",
       " 'bantuan': 186,\n",
       " 'dah': 187,\n",
       " 'tangkap': 188,\n",
       " 'pintar': 189,\n",
       " 'diam': 190,\n",
       " 'china': 191,\n",
       " 'b': 192,\n",
       " 'wakil': 193,\n",
       " 'tangan': 194,\n",
       " 'cawapres': 195,\n",
       " 'makasih': 196,\n",
       " 'kawan': 197,\n",
       " 'muka': 198,\n",
       " 'kota': 199,\n",
       " 'turun': 200,\n",
       " 'asli': 201,\n",
       " 'mending': 202,\n",
       " 'main': 203,\n",
       " 'kalimantan': 204,\n",
       " 'menang': 205,\n",
       " 'mu': 206,\n",
       " 'amin': 207,\n",
       " 'kubu': 208,\n",
       " 'cinta': 209,\n",
       " 'kebenaran': 210,\n",
       " 'harga': 211,\n",
       " 'tokoh': 212,\n",
       " 'suara': 213,\n",
       " 'virus': 214,\n",
       " 'fakta': 215,\n",
       " 'sejahtera': 216,\n",
       " 'sejarah': 217,\n",
       " 'alasan': 218,\n",
       " 'pertemuan': 219,\n",
       " 'sosial': 220,\n",
       " 'iya': 221,\n",
       " 'pa': 222,\n",
       " 'bacot': 223,\n",
       " 'kader': 224,\n",
       " 'urusan': 225,\n",
       " 'sukses': 226,\n",
       " 'media': 227,\n",
       " 'bali': 228,\n",
       " 'arteria': 229,\n",
       " 'ad': 230,\n",
       " 'bola': 231,\n",
       " 'fifa': 232,\n",
       " 'menjadikan': 233,\n",
       " 'pkb': 234,\n",
       " 'petani': 235,\n",
       " 'sayang': 236,\n",
       " 'rezim': 237,\n",
       " 'liat': 238,\n",
       " 'pembangunan': 239,\n",
       " 'senyum': 240,\n",
       " 'sbg': 241,\n",
       " 'deh': 242,\n",
       " 'baca': 243,\n",
       " 'mendampingi': 244,\n",
       " 'berita': 245,\n",
       " 'tolak': 246,\n",
       " 'd': 247,\n",
       " 'kl': 248,\n",
       " 'gue': 249,\n",
       " 'mata': 250,\n",
       " 'pas': 251,\n",
       " 'lempar': 252,\n",
       " 'jiwa': 253,\n",
       " 'belajar': 254,\n",
       " 'bayar': 255,\n",
       " 'makan': 256,\n",
       " 'ğŸ¤£ğŸ¤£ğŸ¤£': 257,\n",
       " 'generasi': 258,\n",
       " 'sahabat': 259,\n",
       " 'tim': 260,\n",
       " 'gini': 261,\n",
       " 'silakan': 262,\n",
       " 'publik': 263,\n",
       " 'menilai': 264,\n",
       " 'doang': 265,\n",
       " 'bebas': 266,\n",
       " 'habis': 267,\n",
       " 'percaya': 268,\n",
       " 'kasihan': 269,\n",
       " 'ğŸ‘‡': 270,\n",
       " 'jenderal': 271,\n",
       " 'peduli': 272,\n",
       " '2023': 273,\n",
       " 'hak': 274,\n",
       " 'sesuai': 275,\n",
       " 'mati': 276,\n",
       " 'senang': 277,\n",
       " 'paman': 278,\n",
       " 'ayo': 279,\n",
       " 'kalah': 280,\n",
       " 'menyebut': 281,\n",
       " 'anis': 282,\n",
       " 'bangun': 283,\n",
       " 'fitnah': 284,\n",
       " 'mah': 285,\n",
       " 'dahlan': 286,\n",
       " 'butuh': 287,\n",
       " 'polisi': 288,\n",
       " 'erick': 289,\n",
       " 'pimpin': 290,\n",
       " 'kepala': 291,\n",
       " 'kepemimpinan': 292,\n",
       " 'jujur': 293,\n",
       " 'utang': 294,\n",
       " 'ğŸ˜‚': 295,\n",
       " 'membantu': 296,\n",
       " 'u': 297,\n",
       " 'cerdas': 298,\n",
       " 'mudah': 299,\n",
       " 'terima': 300,\n",
       " 'tenaga': 301,\n",
       " 'terkait': 302,\n",
       " 'hutang': 303,\n",
       " 'mulut': 304,\n",
       " 'bangga': 305,\n",
       " 'era': 306,\n",
       " 'kelompok': 307,\n",
       " 'kunjungan': 308,\n",
       " 'ekonomi': 309,\n",
       " 'timnas': 310,\n",
       " 'gagal': 311,\n",
       " 'kena': 312,\n",
       " 'ğŸ¤£': 313,\n",
       " 'edy': 314,\n",
       " 'agus': 315,\n",
       " 'memimpin': 316,\n",
       " 'janji': 317,\n",
       " 'pki': 318,\n",
       " 'viral': 319,\n",
       " 'relawan': 320,\n",
       " 'jabatan': 321,\n",
       " 'sakit': 322,\n",
       " 'selamat': 323,\n",
       " 'pandjaitan': 324,\n",
       " 'e': 325,\n",
       " 'duet': 326,\n",
       " 'foto': 327,\n",
       " 'miskin': 328,\n",
       " 'barat': 329,\n",
       " 'cina': 330,\n",
       " 'proyek': 331,\n",
       " 'kebanyakan': 332,\n",
       " 'bpk': 333,\n",
       " 'lo': 334,\n",
       " 'pribadi': 335,\n",
       " 'sikap': 336,\n",
       " 'susah': 337,\n",
       " 'nasional': 338,\n",
       " 'anjing': 339,\n",
       " 'cerita': 340,\n",
       " 'aspirasi': 341,\n",
       " 'kalangan': 342,\n",
       " 'sok': 343,\n",
       " 'qorun': 344,\n",
       " 'sifat': 345,\n",
       " 'cantik': 346,\n",
       " 'dungu': 347,\n",
       " 'anggap': 348,\n",
       " 'mengaku': 349,\n",
       " 'melanjutkan': 350,\n",
       " 'cilik': 351,\n",
       " 'isi': 352,\n",
       " 'nyata': 353,\n",
       " 'sadar': 354,\n",
       " 'buruk': 355,\n",
       " 'wan': 356,\n",
       " 'k': 357,\n",
       " 'periode': 358,\n",
       " 'kemarin': 359,\n",
       " 'elu': 360,\n",
       " 'megawati': 361,\n",
       " '00': 362,\n",
       " 'sm': 363,\n",
       " 'layak': 364,\n",
       " 'tua': 365,\n",
       " 'mobil': 366,\n",
       " 'harapan': 367,\n",
       " 'piala': 368,\n",
       " 'hancur': 369,\n",
       " 'ğŸ™': 370,\n",
       " 'soekarno': 371,\n",
       " 'istana': 372,\n",
       " 'senyuman': 373,\n",
       " 'listrik': 374,\n",
       " 'drama': 375,\n",
       " 'asing': 376,\n",
       " 'ama': 377,\n",
       " 'alhamdulillah': 378,\n",
       " 'pasangan': 379,\n",
       " 'membagikan': 380,\n",
       " 'komitmen': 381,\n",
       " 'desa': 382,\n",
       " 'buka': 383,\n",
       " 'data': 384,\n",
       " 's': 385,\n",
       " 'kaum': 386,\n",
       " 'puncak': 387,\n",
       " 'penerus': 388,\n",
       " 'nasib': 389,\n",
       " 'hadir': 390,\n",
       " 'bermanfaat': 391,\n",
       " 'momen': 392,\n",
       " 'kepentingan': 393,\n",
       " 'jaman': 394,\n",
       " 'demokrat': 395,\n",
       " 'budi': 396,\n",
       " 'komentar': 397,\n",
       " 'mega': 398,\n",
       " 'spt': 399,\n",
       " 'g': 400,\n",
       " 'gibran': 401,\n",
       " 'ambil': 402,\n",
       " 'super': 403,\n",
       " 'melawan': 404,\n",
       " 'tanah': 405,\n",
       " 'kekuasaan': 406,\n",
       " 'kinerja': 407,\n",
       " 'menjaga': 408,\n",
       " 'widodo': 409,\n",
       " 'utama': 410,\n",
       " '2019': 411,\n",
       " 'penguasa': 412,\n",
       " 'bukti': 413,\n",
       " 'olahraga': 414,\n",
       " 'mendengarkan': 415,\n",
       " 'politikus': 416,\n",
       " 'memilih': 417,\n",
       " 'menerima': 418,\n",
       " 'loh': 419,\n",
       " 'stadion': 420,\n",
       " 'negri': 421,\n",
       " 'gua': 422,\n",
       " 'akun': 423,\n",
       " 'identitas': 424,\n",
       " 'tingkat': 425,\n",
       " 'bang': 426,\n",
       " 'melindungi': 427,\n",
       " 'keputusan': 428,\n",
       " 'y': 429,\n",
       " 'perubahan': 430,\n",
       " 'bro': 431,\n",
       " 'petugas': 432,\n",
       " 'ni': 433,\n",
       " 'ente': 434,\n",
       " 'isu': 435,\n",
       " 'gagasan': 436,\n",
       " 'muslim': 437,\n",
       " 'bawa': 438,\n",
       " 'maksud': 439,\n",
       " 'maritim': 440,\n",
       " 'jelek': 441,\n",
       " 'tujuan': 442,\n",
       " 'tuan': 443,\n",
       " 'pamer': 444,\n",
       " 'cebong': 445,\n",
       " 'najis': 446,\n",
       " 'rusak': 447,\n",
       " 'sekolah': 448,\n",
       " 'proses': 449,\n",
       " 'thohir': 450,\n",
       " 'jateng': 451,\n",
       " 'penjilat': 452,\n",
       " 'jaga': 453,\n",
       " 'aman': 454,\n",
       " 'membela': 455,\n",
       " 'direktur': 456,\n",
       " 'visi': 457,\n",
       " 'vaksin': 458,\n",
       " 'kafir': 459,\n",
       " 'kebijakan': 460,\n",
       " 'ketemu': 461,\n",
       " 'peraturan': 462,\n",
       " 'sembunyi': 463,\n",
       " 'merdeka': 464,\n",
       " 'umat': 465,\n",
       " 'bicara': 466,\n",
       " 'tinggal': 467,\n",
       " 'manfaat': 468,\n",
       " 'kementerian': 469,\n",
       " 'ğŸ¤­': 470,\n",
       " 'kip': 471,\n",
       " 'sepak': 472,\n",
       " 'bahasa': 473,\n",
       " 'wajar': 474,\n",
       " 'anti': 475,\n",
       " 'wajib': 476,\n",
       " 'teman': 477,\n",
       " 'tata': 478,\n",
       " 'suruh': 479,\n",
       " 'yah': 480,\n",
       " 'sampah': 481,\n",
       " 'misi': 482,\n",
       " 'terbukti': 483,\n",
       " 'duit': 484,\n",
       " 'ğŸ˜…': 485,\n",
       " 'lupa': 486,\n",
       " 'pilihan': 487,\n",
       " 'kegiatan': 488,\n",
       " 'tolol': 489,\n",
       " 'semarang': 490,\n",
       " 'cepat': 491,\n",
       " 'tsb': 492,\n",
       " 'kuat': 493,\n",
       " 'alias': 494,\n",
       " 'salam': 495,\n",
       " 'sunda': 496,\n",
       " 'uu': 497,\n",
       " 'berjuang': 498,\n",
       " 'mengikuti': 499,\n",
       " 'bego': 500,\n",
       " 'citra': 501,\n",
       " 'pemain': 502,\n",
       " 'koalisi': 503,\n",
       " 'ganti': 504,\n",
       " 'pecat': 505,\n",
       " 'berkuasa': 506,\n",
       " 'dasar': 507,\n",
       " 'kosong': 508,\n",
       " 'said': 509,\n",
       " 'dpp': 510,\n",
       " 'ulama': 511,\n",
       " 'mantan': 512,\n",
       " 'marah': 513,\n",
       " 'ğŸ¤£ğŸ¤£': 514,\n",
       " 'doa': 515,\n",
       " 'ktt': 516,\n",
       " 'pemerintahan': 517,\n",
       " 'tahi': 518,\n",
       " 'penghargaan': 519,\n",
       " 'biaya': 520,\n",
       " 'cc': 521,\n",
       " 'lbh': 522,\n",
       " 'tugas': 523,\n",
       " 'ğŸ˜‚ğŸ˜‚ğŸ˜‚': 524,\n",
       " 'badan': 525,\n",
       " 'papua': 526,\n",
       " 'berpikir': 527,\n",
       " 'sengkuni': 528,\n",
       " 'berharap': 529,\n",
       " 'mengunjungi': 530,\n",
       " 'parah': 531,\n",
       " 'ahok': 532,\n",
       " 'bandung': 533,\n",
       " 'ku': 534,\n",
       " 'soeharto': 535,\n",
       " 'kabar': 536,\n",
       " 'beli': 537,\n",
       " 'ha': 538,\n",
       " 'omongan': 539,\n",
       " 'cek': 540,\n",
       " 'ruwet': 541,\n",
       " 'kelas': 542,\n",
       " 'wajah': 543,\n",
       " 'menghina': 544,\n",
       " 'berkunjung': 545,\n",
       " 'ormas': 546,\n",
       " 'kawal': 547,\n",
       " 'lawan': 548,\n",
       " 'setan': 549,\n",
       " 'bambang': 550,\n",
       " 'ilmu': 551,\n",
       " 'p': 552,\n",
       " 'kelebihan': 553,\n",
       " 'olah': 554,\n",
       " 'bumn': 555,\n",
       " 'via': 556,\n",
       " 'j': 557,\n",
       " 'juta': 558,\n",
       " 'pusat': 559,\n",
       " 'perang': 560,\n",
       " 'tukang': 561,\n",
       " 'mengubah': 562,\n",
       " 'kemampuan': 563,\n",
       " 'zaman': 564,\n",
       " 'ahli': 565,\n",
       " 'kebaikan': 566,\n",
       " 'perusahaan': 567,\n",
       " 'komen': 568,\n",
       " 'gus': 569,\n",
       " 'ğŸ˜‚ğŸ˜‚': 570,\n",
       " 'radikal': 571,\n",
       " 'urus': 572,\n",
       " 'jejak': 573,\n",
       " 'padi': 574,\n",
       " 'bareng': 575,\n",
       " 'buang': 576,\n",
       " 'boneka': 577,\n",
       " 'ambisi': 578,\n",
       " 'tanggung': 579,\n",
       " 'ngerti': 580,\n",
       " 'mundur': 581,\n",
       " 'bertemu': 582,\n",
       " 'kecewa': 583,\n",
       " 'berubah': 584,\n",
       " 'pengamat': 585,\n",
       " 'pembela': 586,\n",
       " 'saudara': 587,\n",
       " 'sri': 588,\n",
       " 'patut': 589,\n",
       " 'ham': 590,\n",
       " 'cuman': 591,\n",
       " 'lepas': 592,\n",
       " 'paksa': 593,\n",
       " 'om': 594,\n",
       " 'gaya': 595,\n",
       " 'sepakat': 596,\n",
       " 'membawa': 597,\n",
       " 'hubungan': 598,\n",
       " 'ruang': 599,\n",
       " 'tidur': 600,\n",
       " 'jusuf': 601,\n",
       " 'kesehatan': 602,\n",
       " 'gara': 603,\n",
       " 'puasa': 604,\n",
       " 'positif': 605,\n",
       " 'narasi': 606,\n",
       " 'muncul': 607,\n",
       " 'komplotan': 608,\n",
       " 'suci': 609,\n",
       " 'laku': 610,\n",
       " 'panggung': 611,\n",
       " 'alam': 612,\n",
       " 'musuh': 613,\n",
       " 'ma': 614,\n",
       " 'produk': 615,\n",
       " 'internasional': 616,\n",
       " 'dana': 617,\n",
       " 'hujan': 618,\n",
       " 'kenyataan': 619,\n",
       " 'mencari': 620,\n",
       " 'front': 621,\n",
       " 'cemberut': 622,\n",
       " 'berbeda': 623,\n",
       " 'mulyani': 624,\n",
       " 'konsisten': 625,\n",
       " 'menjabat': 626,\n",
       " 'bentuk': 627,\n",
       " 'inti': 628,\n",
       " 'dewan': 629,\n",
       " 'omong': 630,\n",
       " 'operasi': 631,\n",
       " 'banjir': 632,\n",
       " 'mohon': 633,\n",
       " 'menanggapi': 634,\n",
       " 'wali': 635,\n",
       " 'keturunan': 636,\n",
       " 'pekerja': 637,\n",
       " 'oligarki': 638,\n",
       " 'menghadapi': 639,\n",
       " 'menunggu': 640,\n",
       " 'berat': 641,\n",
       " 'menjalankan': 642,\n",
       " 'bkn': 643,\n",
       " 'mendadak': 644,\n",
       " 'lantas': 645,\n",
       " 'kondisi': 646,\n",
       " 'mikropon': 647,\n",
       " 'solusi': 648,\n",
       " 'anggota': 649,\n",
       " 'banding': 650,\n",
       " 'usia': 651,\n",
       " 'pertanahan': 652,\n",
       " 'nu': 653,\n",
       " 'debat': 654,\n",
       " 'penjara': 655,\n",
       " 'kalla': 656,\n",
       " 'republik': 657,\n",
       " 'korban': 658,\n",
       " 'komunis': 659,\n",
       " 'kagum': 660,\n",
       " 'ko': 661,\n",
       " '11': 662,\n",
       " 'al': 663,\n",
       " 'dirjen': 664,\n",
       " 'korps': 665,\n",
       " 'beruntung': 666,\n",
       " 'kaki': 667,\n",
       " 'kepedulian': 668,\n",
       " 'demo': 669,\n",
       " 'bbm': 670,\n",
       " 'resmi': 671,\n",
       " 'memikirkan': 672,\n",
       " 'hina': 673,\n",
       " 'blunder': 674,\n",
       " 'mulia': 675,\n",
       " 'motor': 676,\n",
       " 'memuji': 677,\n",
       " 'pagar': 678,\n",
       " 'malas': 679,\n",
       " 'kritik': 680,\n",
       " 'pekerjaan': 681,\n",
       " 'menangis': 682,\n",
       " 'membutuhkan': 683,\n",
       " 'pasukan': 684,\n",
       " 'mesti': 685,\n",
       " 'rencana': 686,\n",
       " 'adat': 687,\n",
       " 'beras': 688,\n",
       " 'golkar': 689,\n",
       " 'selesai': 690,\n",
       " 'infrastruktur': 691,\n",
       " 'kiai': 692,\n",
       " 'kesalahan': 693,\n",
       " 'gelandangan': 694,\n",
       " 'cm': 695,\n",
       " 'putri': 696,\n",
       " 'untung': 697,\n",
       " 'pagi': 698,\n",
       " 'teriak': 699,\n",
       " 'membandingkan': 700,\n",
       " 'babi': 701,\n",
       " 'tulus': 702,\n",
       " 'kampanye': 703,\n",
       " 'asuhan': 704,\n",
       " 'budayawan': 705,\n",
       " 'mencalonkan': 706,\n",
       " 'pajak': 707,\n",
       " 'lancar': 708,\n",
       " 'jam': 709,\n",
       " 'ucapan': 710,\n",
       " 'mengakui': 711,\n",
       " 'cita': 712,\n",
       " 'elektabilitas': 713,\n",
       " 'ridwan': 714,\n",
       " 'harap': 715,\n",
       " 'formula': 716,\n",
       " 'berjalan': 717,\n",
       " 'bahan': 718,\n",
       " 'sari': 719,\n",
       " 'kamis': 720,\n",
       " 'mentri': 721,\n",
       " 'kenal': 722,\n",
       " 'manis': 723,\n",
       " 'buta': 724,\n",
       " 'mencapai': 725,\n",
       " 'pancasila': 726,\n",
       " 'lokasi': 727,\n",
       " 'berbuat': 728,\n",
       " 'persen': 729,\n",
       " 'surya': 730,\n",
       " 'karya': 731,\n",
       " 'km': 732,\n",
       " 'beredar': 733,\n",
       " 'bersatu': 734,\n",
       " 'warung': 735,\n",
       " 'pikiran': 736,\n",
       " 'kecoa': 737,\n",
       " 'buku': 738,\n",
       " 'forum': 739,\n",
       " 'bp': 740,\n",
       " 'mendengar': 741,\n",
       " 'gerombolan': 742,\n",
       " 'penjelasan': 743,\n",
       " 'menyerahkan': 744,\n",
       " 'pindah': 745,\n",
       " 'bokep': 746,\n",
       " 'hilang': 747,\n",
       " 'murah': 748,\n",
       " 'tunggu': 749,\n",
       " 'sang': 750,\n",
       " 'berhasil': 751,\n",
       " 'pengembangan': 752,\n",
       " 'merasakan': 753,\n",
       " 'waras': 754,\n",
       " 'halo': 755,\n",
       " 'penyelenggaraan': 756,\n",
       " 'energi': 757,\n",
       " 'bos': 758,\n",
       " 'kereta': 759,\n",
       " 'bantu': 760,\n",
       " 'mewujudkan': 761,\n",
       " 'gratis': 762,\n",
       " 'penyataan': 763,\n",
       " 'nasionalis': 764,\n",
       " 'perbuatan': 765,\n",
       " 'mengatur': 766,\n",
       " 'blusukan': 767,\n",
       " 'ular': 768,\n",
       " 'dengar': 769,\n",
       " 'salut': 770,\n",
       " 'sandiwara': 771,\n",
       " 'malam': 772,\n",
       " 'tu': 773,\n",
       " 'kak': 774,\n",
       " 'gila': 775,\n",
       " 'solo': 776,\n",
       " 'jual': 777,\n",
       " 'konstitusi': 778,\n",
       " 'bahas': 779,\n",
       " 'berkah': 780,\n",
       " 'pakde': 781,\n",
       " 'psi': 782,\n",
       " 'dpt': 783,\n",
       " 'ğŸ‡®ğŸ‡©': 784,\n",
       " 'junjungan': 785,\n",
       " 'pembenci': 786,\n",
       " 'angkat': 787,\n",
       " 'pesantren': 788,\n",
       " 'embun': 789,\n",
       " 'lengkap': 790,\n",
       " 'haram': 791,\n",
       " 'memperhatikan': 792,\n",
       " 'siswa': 793,\n",
       " 'membuktikan': 794,\n",
       " 'suku': 795,\n",
       " 'sesungguhnya': 796,\n",
       " 'ğŸ‘‰': 797,\n",
       " 'logika': 798,\n",
       " 'bahagia': 799,\n",
       " 'sungguh': 800,\n",
       " 'daya': 801,\n",
       " 'jin': 802,\n",
       " 'bumi': 803,\n",
       " 'kekayaan': 804,\n",
       " 'memperbaiki': 805,\n",
       " 'permainan': 806,\n",
       " 'menciptakan': 807,\n",
       " 'kesempatan': 808,\n",
       " 'kekasih': 809,\n",
       " 'ketahuan': 810,\n",
       " 'penolakan': 811,\n",
       " 'mengenal': 812,\n",
       " 'kerjaan': 813,\n",
       " 'bergabung': 814,\n",
       " 'pemimpi': 815,\n",
       " 'simak': 816,\n",
       " 'no': 817,\n",
       " 'jualan': 818,\n",
       " 'kemenangan': 819,\n",
       " 'habib': 820,\n",
       " 'bijak': 821,\n",
       " 'kehidupan': 822,\n",
       " 'to': 823,\n",
       " 'rame': 824,\n",
       " 'stop': 825,\n",
       " 'memahami': 826,\n",
       " 'agenda': 827,\n",
       " 'cucu': 828,\n",
       " 'perjanjian': 829,\n",
       " 'terdengar': 830,\n",
       " 'ragu': 831,\n",
       " 'menyalahkan': 832,\n",
       " 'upaya': 833,\n",
       " 'pabrik': 834,\n",
       " 'zalim': 835,\n",
       " 'pro': 836,\n",
       " 'tahan': 837,\n",
       " 'risma': 838,\n",
       " 'panti': 839,\n",
       " 'surabaya': 840,\n",
       " 'kritis': 841,\n",
       " 'kotak': 842,\n",
       " 'survei': 843,\n",
       " 'melarang': 844,\n",
       " 'jaya': 845,\n",
       " 'sambo': 846,\n",
       " 'busuk': 847,\n",
       " 'arah': 848,\n",
       " 'mahasiswa': 849,\n",
       " 'vs': 850,\n",
       " 'pk': 851,\n",
       " 'rekam': 852,\n",
       " 'keliling': 853,\n",
       " 'ğŸ”¥': 854,\n",
       " 'bunuh': 855,\n",
       " 'atur': 856,\n",
       " 'dadah': 857,\n",
       " 'survey': 858,\n",
       " 'sibuk': 859,\n",
       " 'huruf': 860,\n",
       " 'sumur': 861,\n",
       " 'resapan': 862,\n",
       " 'kitab': 863,\n",
       " 'terhormat': 864,\n",
       " 'daftar': 865,\n",
       " 'munafik': 866,\n",
       " 'monyet': 867,\n",
       " 'kebohongan': 868,\n",
       " 'sepatu': 869,\n",
       " 'laporan': 870,\n",
       " 'nyinyir': 871,\n",
       " 'sawah': 872,\n",
       " 'pandai': 873,\n",
       " 'ide': 874,\n",
       " 'berkat': 875,\n",
       " 'mendorong': 876,\n",
       " 'wapres': 877,\n",
       " 'paloh': 878,\n",
       " 'enak': 879,\n",
       " 'm': 880,\n",
       " 'beban': 881,\n",
       " 'makanan': 882,\n",
       " 'persatuan': 883,\n",
       " 'trans': 884,\n",
       " 'emas': 885,\n",
       " 'agung': 886,\n",
       " 'menyamakan': 887,\n",
       " 'keuangan': 888,\n",
       " 'kebahagiaan': 889,\n",
       " 'polri': 890,\n",
       " 'ajak': 891,\n",
       " 'komnas': 892,\n",
       " 'fokus': 893,\n",
       " 'buah': 894,\n",
       " 'mental': 895,\n",
       " 'susilo': 896,\n",
       " 'amanah': 897,\n",
       " 'khawatir': 898,\n",
       " 'aneh': 899,\n",
       " 'kolaborasi': 900,\n",
       " 'persiapan': 901,\n",
       " 'tampik': 902,\n",
       " 'capek': 903,\n",
       " 'maling': 904,\n",
       " 'mensos': 905,\n",
       " '27': 906,\n",
       " 'hutan': 907,\n",
       " 'sistem': 908,\n",
       " 'yuk': 909,\n",
       " 'ketawa': 910,\n",
       " 'mendoakan': 911,\n",
       " 'keras': 912,\n",
       " 'aktif': 913,\n",
       " 'engkau': 914,\n",
       " 'pelaku': 915,\n",
       " 'arahan': 916,\n",
       " 'bersinergi': 917,\n",
       " 'kek': 918,\n",
       " 'sanksi': 919,\n",
       " 'waspada': 920,\n",
       " 'kehilangan': 921,\n",
       " 'kabinet': 922,\n",
       " 'kuasa': 923,\n",
       " 'kelak': 924,\n",
       " 'serius': 925,\n",
       " 'kang': 926,\n",
       " 'mengerti': 927,\n",
       " 'diskusi': 928,\n",
       " 'prinsip': 929,\n",
       " 'biang': 930,\n",
       " 'raga': 931,\n",
       " 'wanita': 932,\n",
       " 'rendah': 933,\n",
       " 'kekalutan': 934,\n",
       " 'jongos': 935,\n",
       " 'pengecut': 936,\n",
       " 'nusantara': 937,\n",
       " 'subsidi': 938,\n",
       " 'insyaallah': 939,\n",
       " 'bermain': 940,\n",
       " 'sulit': 941,\n",
       " 'merusak': 942,\n",
       " 'saking': 943,\n",
       " 'menanam': 944,\n",
       " 'larang': 945,\n",
       " 'pendapat': 946,\n",
       " 'urutan': 947,\n",
       " 'menarik': 948,\n",
       " 'peringatan': 949,\n",
       " '2014': 950,\n",
       " 'berkomentar': 951,\n",
       " 'pasar': 952,\n",
       " 'jago': 953,\n",
       " 'timur': 954,\n",
       " 'menjilat': 955,\n",
       " 'usaha': 956,\n",
       " 'cikeas': 957,\n",
       " 'sungai': 958,\n",
       " 'melayani': 959,\n",
       " 'desember': 960,\n",
       " 'hajat': 961,\n",
       " 'pemikiran': 962,\n",
       " 'ğŸ‘ˆ': 963,\n",
       " 'barang': 964,\n",
       " 'menandai': 965,\n",
       " 'usung': 966,\n",
       " 'benci': 967,\n",
       " 'komunikasi': 968,\n",
       " 'waduk': 969,\n",
       " 'kejujuran': 970,\n",
       " 'tanam': 971,\n",
       " 'bisnis': 972,\n",
       " 'lapor': 973,\n",
       " 'palsu': 974,\n",
       " 'kehadiran': 975,\n",
       " 'tuk': 976,\n",
       " 'ribut': 977,\n",
       " 'keselamatan': 978,\n",
       " 'roboh': 979,\n",
       " 'kandidat': 980,\n",
       " 'bismillah': 981,\n",
       " 'pecel': 982,\n",
       " 'masak': 983,\n",
       " 'peristiwa': 984,\n",
       " 'wilayah': 985,\n",
       " 'antek': 986,\n",
       " 'ulah': 987,\n",
       " 'karakter': 988,\n",
       " 'meninggalkan': 989,\n",
       " 'kades': 990,\n",
       " 'panas': 991,\n",
       " 'pesan': 992,\n",
       " 'umkm': 993,\n",
       " 'modal': 994,\n",
       " 'hitam': 995,\n",
       " 'ekspresi': 996,\n",
       " 'kuliah': 997,\n",
       " 'hotel': 998,\n",
       " 'kebencian': 999,\n",
       " 'kemaren': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Sequence</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_train = tokenizer.texts_to_sequences(X_train)\n",
    "sequence_test = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Padding</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "X_train_padded = pad_sequences(sequence_train, maxlen=100, padding='post', truncating='post')\n",
    "X_test_padded = pad_sequences(sequence_test, maxlen=100, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 269,  242,  786,   19,   37,   14,  858,  284,   81,   19,  200,\n",
       "        713,   17,   17,   29,   17,  465, 3800,    5,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_padded[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Build Matrix Embedding</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coefs(word,*arr): \n",
    "    return word, np.asarray(arr, dtype='float32')\n",
    "\n",
    "def load_embedding(file):\n",
    "    embeddings_index = dict(get_coefs(*i.split(\" \")) for i in open(file, encoding='utf-8'))\n",
    "    \n",
    "    return embeddings_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_embedding_matrix(embedding, tokenizer, len_voc):\n",
    "    all_embs = np.stack(embedding.values())\n",
    "    emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "    embed_size = all_embs.shape[1]\n",
    "    word_index = tokenizer.word_index\n",
    "    # embedding_matrix = np.random.normal(emb_mean, emb_std, (len_voc, embed_size))\n",
    "    embedding_matrix = np.zeros((len_voc + 1, embed_size))\n",
    "    \n",
    "    for word, i in word_index.items():\n",
    "        if i >= len_voc:\n",
    "            continue\n",
    "        embedding_vector = embedding.get(word)\n",
    "        if embedding_vector is not None: \n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    \n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_50D = load_embedding('Misc/Embeddings/embeddings50D_300E.txt')\n",
    "glove_100D = load_embedding('Misc/Embeddings/embeddings100D_300E.txt')\n",
    "glove_150D = load_embedding('Misc/Embeddings/embeddings150D_300E.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Implement SMOTE</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_padded, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_values, value_counts = np.unique(y_train_resampled, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 2012\n",
      "1: 2012\n"
     ]
    }
   ],
   "source": [
    "for value, count in zip(unique_values, value_counts):\n",
    "    print(f\"{value}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py:3378: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "embed_matrix_50D = make_embedding_matrix(glove_50D, tokenizer, len(word_index))\n",
    "embed_matrix_100D = make_embedding_matrix(glove_100D, tokenizer, len(word_index))\n",
    "embed_matrix_150D = make_embedding_matrix(glove_150D, tokenizer, len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension matrix 50D: (6520, 50)\n",
      "\n",
      "Dimension matrix 100D : (6520, 100)\n",
      "\n",
      "Dimension matrix 150D : (6520, 150)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'Dimension matrix 50D: {embed_matrix_50D.shape}\\n')\n",
    "print(f'Dimension matrix 100D : {embed_matrix_100D.shape}\\n')\n",
    "print(f'Dimension matrix 150D : {embed_matrix_150D.shape}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Create Bi-LSTM Architecture</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Callbacks\n",
    "# class myCallback(tf.keras.callbacks.Callback):\n",
    "#   def on_epoch_end(self, epoch, logs={}):\n",
    "#     if(logs.get('accuracy')>=0.8): #logs.get('val_accuracy')>0.8\n",
    "#       print(\"\\nAkurasi telah mencapai > 75%!\")\n",
    "#       self.model.stop_training = True\n",
    "# callbacks = myCallback()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Train Model Bi-LSTM (Parameter embedding_size = 50)</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 100, 50)           326000    \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 200)              120800    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 200)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                12864     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 459,729\n",
      "Trainable params: 133,729\n",
      "Non-trainable params: 326,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_bilstm_embedsize_50 = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Embedding(embed_matrix_50D.shape[0], embed_matrix_50D.shape[1], input_length=maxlen, weights=[embed_matrix_50D], trainable=False),\n",
    "        tf.keras.layers.Bidirectional(LSTM(100)),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Create Optimizer\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model_bilstm_embedsize_50.compile(\n",
    "        optimizer=opt,\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model_bilstm_embedsize_50.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "126/126 - 9s - loss: 0.6508 - accuracy: 0.6118 - val_loss: 0.5890 - val_accuracy: 0.6629 - 9s/epoch - 68ms/step\n",
      "Epoch 2/10\n",
      "126/126 - 5s - loss: 0.5622 - accuracy: 0.7090 - val_loss: 0.5507 - val_accuracy: 0.6902 - 5s/epoch - 39ms/step\n",
      "Epoch 3/10\n",
      "126/126 - 5s - loss: 0.5394 - accuracy: 0.7259 - val_loss: 0.5518 - val_accuracy: 0.6879 - 5s/epoch - 39ms/step\n",
      "Epoch 4/10\n",
      "126/126 - 5s - loss: 0.5258 - accuracy: 0.7331 - val_loss: 0.5217 - val_accuracy: 0.7130 - 5s/epoch - 38ms/step\n",
      "Epoch 5/10\n",
      "126/126 - 5s - loss: 0.5106 - accuracy: 0.7393 - val_loss: 0.5269 - val_accuracy: 0.7267 - 5s/epoch - 38ms/step\n",
      "Epoch 6/10\n",
      "126/126 - 5s - loss: 0.4962 - accuracy: 0.7495 - val_loss: 0.5236 - val_accuracy: 0.7267 - 5s/epoch - 38ms/step\n",
      "Epoch 7/10\n",
      "126/126 - 5s - loss: 0.4842 - accuracy: 0.7589 - val_loss: 0.5227 - val_accuracy: 0.7244 - 5s/epoch - 39ms/step\n",
      "Epoch 8/10\n",
      "126/126 - 5s - loss: 0.4792 - accuracy: 0.7587 - val_loss: 0.5135 - val_accuracy: 0.7517 - 5s/epoch - 39ms/step\n",
      "Epoch 9/10\n",
      "126/126 - 5s - loss: 0.4648 - accuracy: 0.7689 - val_loss: 0.5086 - val_accuracy: 0.7449 - 5s/epoch - 39ms/step\n",
      "Epoch 10/10\n",
      "126/126 - 5s - loss: 0.4487 - accuracy: 0.7786 - val_loss: 0.5221 - val_accuracy: 0.7244 - 5s/epoch - 39ms/step\n"
     ]
    }
   ],
   "source": [
    "history_bilstm_embedsize_50 = model_bilstm_embedsize_50.fit(\n",
    "        X_train_resampled,\n",
    "        y_train_resampled,\n",
    "        epochs=10,\n",
    "        validation_data=(X_test_padded, y_test),\n",
    "        verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Train Model Bi-LSTM (Parameter embedding_size = 100)</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 100, 100)          652000    \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 200)              160800    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 200)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                12864     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 825,729\n",
      "Trainable params: 173,729\n",
      "Non-trainable params: 652,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_bilstm_embedsize_100 = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Embedding(embed_matrix_100D.shape[0], embed_matrix_100D.shape[1], input_length=maxlen, weights=[embed_matrix_100D], trainable=False),\n",
    "        tf.keras.layers.Bidirectional(LSTM(100)),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Create Optimizer\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model_bilstm_embedsize_100.compile(\n",
    "        optimizer=opt,\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model_bilstm_embedsize_100.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "126/126 - 9s - loss: 0.6239 - accuracy: 0.6543 - val_loss: 0.5791 - val_accuracy: 0.6788 - 9s/epoch - 72ms/step\n",
      "Epoch 2/10\n",
      "126/126 - 6s - loss: 0.5604 - accuracy: 0.7065 - val_loss: 0.5576 - val_accuracy: 0.6879 - 6s/epoch - 50ms/step\n",
      "Epoch 3/10\n",
      "126/126 - 6s - loss: 0.5285 - accuracy: 0.7366 - val_loss: 0.5320 - val_accuracy: 0.7107 - 6s/epoch - 50ms/step\n",
      "Epoch 4/10\n",
      "126/126 - 6s - loss: 0.5084 - accuracy: 0.7438 - val_loss: 0.5284 - val_accuracy: 0.7062 - 6s/epoch - 50ms/step\n",
      "Epoch 5/10\n",
      "126/126 - 6s - loss: 0.4906 - accuracy: 0.7517 - val_loss: 0.5210 - val_accuracy: 0.7358 - 6s/epoch - 48ms/step\n",
      "Epoch 6/10\n",
      "126/126 - 6s - loss: 0.4737 - accuracy: 0.7627 - val_loss: 0.5135 - val_accuracy: 0.7380 - 6s/epoch - 47ms/step\n",
      "Epoch 7/10\n",
      "126/126 - 6s - loss: 0.4596 - accuracy: 0.7691 - val_loss: 0.5078 - val_accuracy: 0.7380 - 6s/epoch - 46ms/step\n",
      "Epoch 8/10\n",
      "126/126 - 6s - loss: 0.4406 - accuracy: 0.7781 - val_loss: 0.4920 - val_accuracy: 0.7654 - 6s/epoch - 47ms/step\n",
      "Epoch 9/10\n",
      "126/126 - 6s - loss: 0.4293 - accuracy: 0.7903 - val_loss: 0.5059 - val_accuracy: 0.7540 - 6s/epoch - 47ms/step\n",
      "Epoch 10/10\n",
      "126/126 - 6s - loss: 0.4079 - accuracy: 0.8009 - val_loss: 0.5185 - val_accuracy: 0.7403 - 6s/epoch - 47ms/step\n"
     ]
    }
   ],
   "source": [
    "history_bilstm_embedsize_100 = model_bilstm_embedsize_100.fit(\n",
    "        X_train_resampled,\n",
    "        y_train_resampled,\n",
    "        epochs=10,\n",
    "        validation_data=(X_test_padded, y_test),\n",
    "        verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Train Model Bi-LSTM (Parameter embedding_size = 150)</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 100, 150)          978000    \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirectio  (None, 200)              200800    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 200)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                12864     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,191,729\n",
      "Trainable params: 213,729\n",
      "Non-trainable params: 978,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_bilstm_embedsize_150 = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Embedding(embed_matrix_150D.shape[0], embed_matrix_150D.shape[1], input_length=maxlen, weights=[embed_matrix_150D], trainable=False),\n",
    "        tf.keras.layers.Bidirectional(LSTM(100)),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Create Optimizer\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model_bilstm_embedsize_150.compile(\n",
    "        optimizer=opt,\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model_bilstm_embedsize_150.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "126/126 - 9s - loss: 0.6209 - accuracy: 0.6451 - val_loss: 0.5696 - val_accuracy: 0.6811 - 9s/epoch - 72ms/step\n",
      "Epoch 2/10\n",
      "126/126 - 6s - loss: 0.5488 - accuracy: 0.7127 - val_loss: 0.5594 - val_accuracy: 0.6811 - 6s/epoch - 46ms/step\n",
      "Epoch 3/10\n",
      "126/126 - 6s - loss: 0.5376 - accuracy: 0.7239 - val_loss: 0.5461 - val_accuracy: 0.6856 - 6s/epoch - 48ms/step\n",
      "Epoch 4/10\n",
      "126/126 - 6s - loss: 0.5066 - accuracy: 0.7453 - val_loss: 0.5335 - val_accuracy: 0.7175 - 6s/epoch - 51ms/step\n",
      "Epoch 5/10\n",
      "126/126 - 6s - loss: 0.4845 - accuracy: 0.7614 - val_loss: 0.5332 - val_accuracy: 0.7221 - 6s/epoch - 50ms/step\n",
      "Epoch 6/10\n",
      "126/126 - 6s - loss: 0.4692 - accuracy: 0.7719 - val_loss: 0.5117 - val_accuracy: 0.7403 - 6s/epoch - 47ms/step\n",
      "Epoch 7/10\n",
      "126/126 - 6s - loss: 0.4465 - accuracy: 0.7863 - val_loss: 0.5264 - val_accuracy: 0.7517 - 6s/epoch - 47ms/step\n",
      "Epoch 8/10\n",
      "126/126 - 6s - loss: 0.4339 - accuracy: 0.7955 - val_loss: 0.5099 - val_accuracy: 0.7745 - 6s/epoch - 46ms/step\n",
      "Epoch 9/10\n",
      "126/126 - 6s - loss: 0.4099 - accuracy: 0.8106 - val_loss: 0.5330 - val_accuracy: 0.7449 - 6s/epoch - 46ms/step\n",
      "Epoch 10/10\n",
      "126/126 - 6s - loss: 0.3921 - accuracy: 0.8218 - val_loss: 0.5184 - val_accuracy: 0.7654 - 6s/epoch - 46ms/step\n"
     ]
    }
   ],
   "source": [
    "history_bilstm_embedsize_150 = model_bilstm_embedsize_150.fit(\n",
    "        X_train_resampled,\n",
    "        y_train_resampled,\n",
    "        epochs=10,\n",
    "        validation_data=(X_test_padded, y_test),\n",
    "        verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Train Model Bi-LSTM (Parameter epochs = 10)</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_8 (Embedding)     (None, 100, 150)          978000    \n",
      "                                                                 \n",
      " bidirectional_3 (Bidirectio  (None, 200)              200800    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 200)               0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 64)                12864     \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,191,729\n",
      "Trainable params: 213,729\n",
      "Non-trainable params: 978,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_bilstm_epochs_10 = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Embedding(embed_matrix_150D.shape[0], embed_matrix_150D.shape[1], input_length=maxlen, weights=[embed_matrix_150D], trainable=False),\n",
    "        tf.keras.layers.Bidirectional(LSTM(100)),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Create Optimizer\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model_bilstm_epochs_10.compile(\n",
    "        optimizer=opt,\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model_bilstm_epochs_10.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "126/126 - 12s - loss: 0.6233 - accuracy: 0.6412 - val_loss: 0.5892 - val_accuracy: 0.6697 - 12s/epoch - 94ms/step\n",
      "Epoch 2/10\n",
      "126/126 - 6s - loss: 0.5469 - accuracy: 0.7259 - val_loss: 0.5453 - val_accuracy: 0.6993 - 6s/epoch - 51ms/step\n",
      "Epoch 3/10\n",
      "126/126 - 6s - loss: 0.5169 - accuracy: 0.7403 - val_loss: 0.5254 - val_accuracy: 0.7312 - 6s/epoch - 50ms/step\n",
      "Epoch 4/10\n",
      "126/126 - 6s - loss: 0.4980 - accuracy: 0.7532 - val_loss: 0.5342 - val_accuracy: 0.7107 - 6s/epoch - 51ms/step\n",
      "Epoch 5/10\n",
      "126/126 - 6s - loss: 0.4805 - accuracy: 0.7619 - val_loss: 0.5231 - val_accuracy: 0.7221 - 6s/epoch - 51ms/step\n",
      "Epoch 6/10\n",
      "126/126 - 6s - loss: 0.4623 - accuracy: 0.7781 - val_loss: 0.5032 - val_accuracy: 0.7517 - 6s/epoch - 51ms/step\n",
      "Epoch 7/10\n",
      "126/126 - 6s - loss: 0.4448 - accuracy: 0.7791 - val_loss: 0.5124 - val_accuracy: 0.7608 - 6s/epoch - 51ms/step\n",
      "Epoch 8/10\n",
      "126/126 - 6s - loss: 0.4200 - accuracy: 0.8009 - val_loss: 0.5238 - val_accuracy: 0.7016 - 6s/epoch - 51ms/step\n",
      "Epoch 9/10\n",
      "126/126 - 6s - loss: 0.4062 - accuracy: 0.7972 - val_loss: 0.5245 - val_accuracy: 0.7540 - 6s/epoch - 51ms/step\n",
      "Epoch 10/10\n",
      "126/126 - 6s - loss: 0.3833 - accuracy: 0.8226 - val_loss: 0.5154 - val_accuracy: 0.7494 - 6s/epoch - 51ms/step\n"
     ]
    }
   ],
   "source": [
    "history_bilstm_epochs_10 = model_bilstm_epochs_10.fit(\n",
    "        X_train_resampled,\n",
    "        y_train_resampled,\n",
    "        epochs=10,\n",
    "        validation_data=(X_test_padded, y_test),\n",
    "        verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Train Model Bi-LSTM (Parameter epochs = 50)</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_9 (Embedding)     (None, 100, 150)          978000    \n",
      "                                                                 \n",
      " bidirectional_4 (Bidirectio  (None, 200)              200800    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 200)               0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 64)                12864     \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,191,729\n",
      "Trainable params: 213,729\n",
      "Non-trainable params: 978,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_bilstm_epochs_50 = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Embedding(embed_matrix_150D.shape[0], embed_matrix_150D.shape[1], input_length=maxlen, weights=[embed_matrix_150D], trainable=False),\n",
    "        tf.keras.layers.Bidirectional(LSTM(100)),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Create Optimizer\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model_bilstm_epochs_50.compile(\n",
    "        optimizer=opt,\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model_bilstm_epochs_50.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "126/126 - 9s - loss: 0.6247 - accuracy: 0.6362 - val_loss: 0.5803 - val_accuracy: 0.6720 - 9s/epoch - 74ms/step\n",
      "Epoch 2/50\n",
      "126/126 - 6s - loss: 0.5525 - accuracy: 0.7189 - val_loss: 0.5473 - val_accuracy: 0.7016 - 6s/epoch - 47ms/step\n",
      "Epoch 3/50\n",
      "126/126 - 6s - loss: 0.5192 - accuracy: 0.7341 - val_loss: 0.5236 - val_accuracy: 0.7358 - 6s/epoch - 47ms/step\n",
      "Epoch 4/50\n",
      "126/126 - 6s - loss: 0.5084 - accuracy: 0.7411 - val_loss: 0.5166 - val_accuracy: 0.7449 - 6s/epoch - 48ms/step\n",
      "Epoch 5/50\n",
      "126/126 - 6s - loss: 0.4867 - accuracy: 0.7589 - val_loss: 0.5178 - val_accuracy: 0.7289 - 6s/epoch - 48ms/step\n",
      "Epoch 6/50\n",
      "126/126 - 6s - loss: 0.4653 - accuracy: 0.7751 - val_loss: 0.5275 - val_accuracy: 0.7267 - 6s/epoch - 48ms/step\n",
      "Epoch 7/50\n",
      "126/126 - 6s - loss: 0.4479 - accuracy: 0.7816 - val_loss: 0.4957 - val_accuracy: 0.7813 - 6s/epoch - 48ms/step\n",
      "Epoch 8/50\n",
      "126/126 - 6s - loss: 0.4275 - accuracy: 0.7967 - val_loss: 0.5298 - val_accuracy: 0.7039 - 6s/epoch - 48ms/step\n",
      "Epoch 9/50\n",
      "126/126 - 6s - loss: 0.4031 - accuracy: 0.8086 - val_loss: 0.5140 - val_accuracy: 0.7563 - 6s/epoch - 47ms/step\n",
      "Epoch 10/50\n",
      "126/126 - 6s - loss: 0.3835 - accuracy: 0.8208 - val_loss: 0.5482 - val_accuracy: 0.7540 - 6s/epoch - 47ms/step\n",
      "Epoch 11/50\n",
      "126/126 - 6s - loss: 0.3541 - accuracy: 0.8355 - val_loss: 0.5601 - val_accuracy: 0.7517 - 6s/epoch - 48ms/step\n",
      "Epoch 12/50\n",
      "126/126 - 6s - loss: 0.3320 - accuracy: 0.8514 - val_loss: 0.5794 - val_accuracy: 0.7312 - 6s/epoch - 48ms/step\n",
      "Epoch 13/50\n",
      "126/126 - 6s - loss: 0.3122 - accuracy: 0.8598 - val_loss: 0.5747 - val_accuracy: 0.7563 - 6s/epoch - 48ms/step\n",
      "Epoch 14/50\n",
      "126/126 - 6s - loss: 0.2997 - accuracy: 0.8695 - val_loss: 0.5630 - val_accuracy: 0.7745 - 6s/epoch - 48ms/step\n",
      "Epoch 15/50\n",
      "126/126 - 6s - loss: 0.2507 - accuracy: 0.8904 - val_loss: 0.6452 - val_accuracy: 0.7608 - 6s/epoch - 48ms/step\n",
      "Epoch 16/50\n",
      "126/126 - 6s - loss: 0.2309 - accuracy: 0.8994 - val_loss: 0.6286 - val_accuracy: 0.7654 - 6s/epoch - 48ms/step\n",
      "Epoch 17/50\n",
      "126/126 - 6s - loss: 0.2150 - accuracy: 0.9066 - val_loss: 0.7087 - val_accuracy: 0.7745 - 6s/epoch - 47ms/step\n",
      "Epoch 18/50\n",
      "126/126 - 6s - loss: 0.1999 - accuracy: 0.9125 - val_loss: 0.6957 - val_accuracy: 0.7426 - 6s/epoch - 47ms/step\n",
      "Epoch 19/50\n",
      "126/126 - 6s - loss: 0.1867 - accuracy: 0.9230 - val_loss: 0.8050 - val_accuracy: 0.7608 - 6s/epoch - 47ms/step\n",
      "Epoch 20/50\n",
      "126/126 - 6s - loss: 0.1594 - accuracy: 0.9317 - val_loss: 0.7827 - val_accuracy: 0.7631 - 6s/epoch - 47ms/step\n",
      "Epoch 21/50\n",
      "126/126 - 6s - loss: 0.1391 - accuracy: 0.9431 - val_loss: 0.8400 - val_accuracy: 0.7677 - 6s/epoch - 47ms/step\n",
      "Epoch 22/50\n",
      "126/126 - 6s - loss: 0.1266 - accuracy: 0.9458 - val_loss: 0.8615 - val_accuracy: 0.7677 - 6s/epoch - 48ms/step\n",
      "Epoch 23/50\n",
      "126/126 - 6s - loss: 0.1087 - accuracy: 0.9565 - val_loss: 0.9319 - val_accuracy: 0.7790 - 6s/epoch - 48ms/step\n",
      "Epoch 24/50\n",
      "126/126 - 6s - loss: 0.1156 - accuracy: 0.9518 - val_loss: 0.9325 - val_accuracy: 0.7745 - 6s/epoch - 47ms/step\n",
      "Epoch 25/50\n",
      "126/126 - 6s - loss: 0.1420 - accuracy: 0.9438 - val_loss: 1.0516 - val_accuracy: 0.7563 - 6s/epoch - 47ms/step\n",
      "Epoch 26/50\n",
      "126/126 - 6s - loss: 0.1274 - accuracy: 0.9525 - val_loss: 0.8636 - val_accuracy: 0.7631 - 6s/epoch - 48ms/step\n",
      "Epoch 27/50\n",
      "126/126 - 6s - loss: 0.0812 - accuracy: 0.9724 - val_loss: 0.9819 - val_accuracy: 0.7745 - 6s/epoch - 48ms/step\n",
      "Epoch 28/50\n",
      "126/126 - 6s - loss: 0.0705 - accuracy: 0.9719 - val_loss: 0.9849 - val_accuracy: 0.7813 - 6s/epoch - 48ms/step\n",
      "Epoch 29/50\n",
      "126/126 - 6s - loss: 0.0673 - accuracy: 0.9747 - val_loss: 1.1029 - val_accuracy: 0.7654 - 6s/epoch - 48ms/step\n",
      "Epoch 30/50\n",
      "126/126 - 6s - loss: 0.0808 - accuracy: 0.9727 - val_loss: 0.9684 - val_accuracy: 0.7608 - 6s/epoch - 48ms/step\n",
      "Epoch 31/50\n",
      "126/126 - 6s - loss: 0.1053 - accuracy: 0.9630 - val_loss: 1.0251 - val_accuracy: 0.7608 - 6s/epoch - 48ms/step\n",
      "Epoch 32/50\n",
      "126/126 - 6s - loss: 0.0845 - accuracy: 0.9665 - val_loss: 1.0601 - val_accuracy: 0.7608 - 6s/epoch - 47ms/step\n",
      "Epoch 33/50\n",
      "126/126 - 6s - loss: 0.0665 - accuracy: 0.9744 - val_loss: 1.0935 - val_accuracy: 0.7722 - 6s/epoch - 47ms/step\n",
      "Epoch 34/50\n",
      "126/126 - 6s - loss: 0.0495 - accuracy: 0.9814 - val_loss: 1.1879 - val_accuracy: 0.7677 - 6s/epoch - 48ms/step\n",
      "Epoch 35/50\n",
      "126/126 - 6s - loss: 0.0446 - accuracy: 0.9846 - val_loss: 1.2720 - val_accuracy: 0.7859 - 6s/epoch - 48ms/step\n",
      "Epoch 36/50\n",
      "126/126 - 6s - loss: 0.0465 - accuracy: 0.9824 - val_loss: 1.3411 - val_accuracy: 0.7517 - 6s/epoch - 48ms/step\n",
      "Epoch 37/50\n",
      "126/126 - 6s - loss: 0.0415 - accuracy: 0.9846 - val_loss: 1.3230 - val_accuracy: 0.7699 - 6s/epoch - 47ms/step\n",
      "Epoch 38/50\n",
      "126/126 - 6s - loss: 0.0465 - accuracy: 0.9856 - val_loss: 1.4077 - val_accuracy: 0.7403 - 6s/epoch - 50ms/step\n",
      "Epoch 39/50\n",
      "126/126 - 6s - loss: 0.0748 - accuracy: 0.9732 - val_loss: 1.2394 - val_accuracy: 0.7608 - 6s/epoch - 48ms/step\n",
      "Epoch 40/50\n",
      "126/126 - 6s - loss: 0.0599 - accuracy: 0.9789 - val_loss: 1.2081 - val_accuracy: 0.7768 - 6s/epoch - 49ms/step\n",
      "Epoch 41/50\n",
      "126/126 - 6s - loss: 0.0617 - accuracy: 0.9774 - val_loss: 1.2100 - val_accuracy: 0.7608 - 6s/epoch - 49ms/step\n",
      "Epoch 42/50\n",
      "126/126 - 6s - loss: 0.0417 - accuracy: 0.9853 - val_loss: 1.2228 - val_accuracy: 0.7790 - 6s/epoch - 48ms/step\n",
      "Epoch 43/50\n",
      "126/126 - 6s - loss: 0.0288 - accuracy: 0.9906 - val_loss: 1.3320 - val_accuracy: 0.7768 - 6s/epoch - 48ms/step\n",
      "Epoch 44/50\n",
      "126/126 - 6s - loss: 0.0277 - accuracy: 0.9888 - val_loss: 1.4608 - val_accuracy: 0.7494 - 6s/epoch - 49ms/step\n",
      "Epoch 45/50\n",
      "126/126 - 6s - loss: 0.0257 - accuracy: 0.9923 - val_loss: 1.4389 - val_accuracy: 0.7677 - 6s/epoch - 48ms/step\n",
      "Epoch 46/50\n",
      "126/126 - 6s - loss: 0.0271 - accuracy: 0.9893 - val_loss: 1.5359 - val_accuracy: 0.7585 - 6s/epoch - 48ms/step\n",
      "Epoch 47/50\n",
      "126/126 - 6s - loss: 0.0204 - accuracy: 0.9918 - val_loss: 1.5474 - val_accuracy: 0.7722 - 6s/epoch - 48ms/step\n",
      "Epoch 48/50\n",
      "126/126 - 6s - loss: 0.0307 - accuracy: 0.9903 - val_loss: 1.6765 - val_accuracy: 0.7540 - 6s/epoch - 48ms/step\n",
      "Epoch 49/50\n",
      "126/126 - 6s - loss: 0.0419 - accuracy: 0.9836 - val_loss: 1.5188 - val_accuracy: 0.7608 - 6s/epoch - 48ms/step\n",
      "Epoch 50/50\n",
      "126/126 - 6s - loss: 0.0491 - accuracy: 0.9829 - val_loss: 1.4793 - val_accuracy: 0.7540 - 6s/epoch - 47ms/step\n"
     ]
    }
   ],
   "source": [
    "history_bilstm_epochs_50 = model_bilstm_epochs_50.fit(\n",
    "        X_train_resampled,\n",
    "        y_train_resampled,\n",
    "        epochs=50,\n",
    "        validation_data=(X_test_padded, y_test),\n",
    "        verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Train Model Bi-LSTM (Parameter epochs = 100)</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_10 (Embedding)    (None, 100, 150)          978000    \n",
      "                                                                 \n",
      " bidirectional_5 (Bidirectio  (None, 200)              200800    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 200)               0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 64)                12864     \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,191,729\n",
      "Trainable params: 213,729\n",
      "Non-trainable params: 978,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_bilstm_epochs_100 = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Embedding(embed_matrix_150D.shape[0], embed_matrix_150D.shape[1], input_length=maxlen, weights=[embed_matrix_150D], trainable=False),\n",
    "        tf.keras.layers.Bidirectional(LSTM(100)),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Create Optimizer\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model_bilstm_epochs_100.compile(\n",
    "        optimizer=opt,\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model_bilstm_epochs_100.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "126/126 - 6s - loss: 0.0328 - accuracy: 0.9888 - val_loss: 1.4728 - val_accuracy: 0.7813 - 6s/epoch - 49ms/step\n",
      "Epoch 2/100\n",
      "126/126 - 6s - loss: 0.0302 - accuracy: 0.9888 - val_loss: 1.5398 - val_accuracy: 0.7859 - 6s/epoch - 47ms/step\n",
      "Epoch 3/100\n",
      "126/126 - 6s - loss: 0.0337 - accuracy: 0.9883 - val_loss: 1.5002 - val_accuracy: 0.7677 - 6s/epoch - 47ms/step\n",
      "Epoch 4/100\n",
      "126/126 - 6s - loss: 0.1947 - accuracy: 0.9622 - val_loss: 1.1660 - val_accuracy: 0.7631 - 6s/epoch - 47ms/step\n",
      "Epoch 5/100\n",
      "126/126 - 6s - loss: 0.0380 - accuracy: 0.9883 - val_loss: 1.2780 - val_accuracy: 0.7494 - 6s/epoch - 46ms/step\n",
      "Epoch 6/100\n",
      "126/126 - 6s - loss: 0.0259 - accuracy: 0.9913 - val_loss: 1.3267 - val_accuracy: 0.7699 - 6s/epoch - 47ms/step\n",
      "Epoch 7/100\n",
      "126/126 - 6s - loss: 0.0194 - accuracy: 0.9943 - val_loss: 1.3557 - val_accuracy: 0.7745 - 6s/epoch - 47ms/step\n",
      "Epoch 8/100\n",
      "126/126 - 6s - loss: 0.0192 - accuracy: 0.9940 - val_loss: 1.4498 - val_accuracy: 0.7745 - 6s/epoch - 47ms/step\n",
      "Epoch 9/100\n",
      "126/126 - 6s - loss: 0.0152 - accuracy: 0.9948 - val_loss: 1.4898 - val_accuracy: 0.7836 - 6s/epoch - 47ms/step\n",
      "Epoch 10/100\n",
      "126/126 - 6s - loss: 0.0188 - accuracy: 0.9933 - val_loss: 1.4494 - val_accuracy: 0.7722 - 6s/epoch - 47ms/step\n",
      "Epoch 11/100\n",
      "126/126 - 6s - loss: 0.0450 - accuracy: 0.9903 - val_loss: 1.3803 - val_accuracy: 0.7654 - 6s/epoch - 47ms/step\n",
      "Epoch 12/100\n",
      "126/126 - 6s - loss: 0.0348 - accuracy: 0.9886 - val_loss: 1.3333 - val_accuracy: 0.7950 - 6s/epoch - 47ms/step\n",
      "Epoch 13/100\n",
      "126/126 - 6s - loss: 0.0258 - accuracy: 0.9911 - val_loss: 1.4586 - val_accuracy: 0.7790 - 6s/epoch - 46ms/step\n",
      "Epoch 14/100\n",
      "126/126 - 6s - loss: 0.0233 - accuracy: 0.9928 - val_loss: 1.4632 - val_accuracy: 0.7745 - 6s/epoch - 47ms/step\n",
      "Epoch 15/100\n",
      "126/126 - 6s - loss: 0.0144 - accuracy: 0.9960 - val_loss: 1.4590 - val_accuracy: 0.7904 - 6s/epoch - 47ms/step\n",
      "Epoch 16/100\n",
      "126/126 - 6s - loss: 0.0149 - accuracy: 0.9950 - val_loss: 1.4897 - val_accuracy: 0.7836 - 6s/epoch - 49ms/step\n",
      "Epoch 17/100\n",
      "126/126 - 6s - loss: 0.0139 - accuracy: 0.9948 - val_loss: 1.5605 - val_accuracy: 0.7973 - 6s/epoch - 47ms/step\n",
      "Epoch 18/100\n",
      "126/126 - 6s - loss: 0.0247 - accuracy: 0.9920 - val_loss: 1.5532 - val_accuracy: 0.7768 - 6s/epoch - 46ms/step\n",
      "Epoch 19/100\n",
      "126/126 - 6s - loss: 0.0227 - accuracy: 0.9930 - val_loss: 1.5100 - val_accuracy: 0.7813 - 6s/epoch - 47ms/step\n",
      "Epoch 20/100\n",
      "126/126 - 6s - loss: 0.0166 - accuracy: 0.9935 - val_loss: 1.5348 - val_accuracy: 0.7904 - 6s/epoch - 46ms/step\n",
      "Epoch 21/100\n",
      "126/126 - 6s - loss: 0.0187 - accuracy: 0.9933 - val_loss: 1.5225 - val_accuracy: 0.7699 - 6s/epoch - 47ms/step\n",
      "Epoch 22/100\n",
      "126/126 - 6s - loss: 0.0299 - accuracy: 0.9881 - val_loss: 1.5050 - val_accuracy: 0.7699 - 6s/epoch - 47ms/step\n",
      "Epoch 23/100\n",
      "126/126 - 6s - loss: 0.0335 - accuracy: 0.9901 - val_loss: 1.4418 - val_accuracy: 0.7768 - 6s/epoch - 46ms/step\n",
      "Epoch 24/100\n",
      "126/126 - 6s - loss: 0.0333 - accuracy: 0.9888 - val_loss: 1.5348 - val_accuracy: 0.7722 - 6s/epoch - 47ms/step\n",
      "Epoch 25/100\n",
      "126/126 - 6s - loss: 0.0376 - accuracy: 0.9863 - val_loss: 1.4875 - val_accuracy: 0.7494 - 6s/epoch - 47ms/step\n",
      "Epoch 26/100\n",
      "126/126 - 6s - loss: 0.0280 - accuracy: 0.9923 - val_loss: 1.5681 - val_accuracy: 0.7472 - 6s/epoch - 47ms/step\n",
      "Epoch 27/100\n",
      "126/126 - 6s - loss: 0.0227 - accuracy: 0.9916 - val_loss: 1.5528 - val_accuracy: 0.7790 - 6s/epoch - 46ms/step\n",
      "Epoch 28/100\n",
      "126/126 - 6s - loss: 0.0252 - accuracy: 0.9908 - val_loss: 1.6866 - val_accuracy: 0.7608 - 6s/epoch - 46ms/step\n",
      "Epoch 29/100\n",
      "126/126 - 6s - loss: 0.0184 - accuracy: 0.9943 - val_loss: 1.5088 - val_accuracy: 0.7882 - 6s/epoch - 47ms/step\n",
      "Epoch 30/100\n",
      "126/126 - 6s - loss: 0.0131 - accuracy: 0.9950 - val_loss: 1.7248 - val_accuracy: 0.7449 - 6s/epoch - 47ms/step\n",
      "Epoch 31/100\n",
      "126/126 - 6s - loss: 0.0141 - accuracy: 0.9943 - val_loss: 1.6641 - val_accuracy: 0.7631 - 6s/epoch - 46ms/step\n",
      "Epoch 32/100\n",
      "126/126 - 6s - loss: 0.0129 - accuracy: 0.9948 - val_loss: 1.7259 - val_accuracy: 0.7563 - 6s/epoch - 46ms/step\n",
      "Epoch 33/100\n",
      "126/126 - 6s - loss: 0.0166 - accuracy: 0.9935 - val_loss: 1.6248 - val_accuracy: 0.7745 - 6s/epoch - 46ms/step\n",
      "Epoch 34/100\n",
      "126/126 - 6s - loss: 0.0107 - accuracy: 0.9950 - val_loss: 1.6582 - val_accuracy: 0.7882 - 6s/epoch - 50ms/step\n",
      "Epoch 35/100\n",
      "126/126 - 6s - loss: 0.0072 - accuracy: 0.9980 - val_loss: 1.6941 - val_accuracy: 0.7904 - 6s/epoch - 49ms/step\n",
      "Epoch 36/100\n",
      "126/126 - 6s - loss: 0.0103 - accuracy: 0.9965 - val_loss: 1.8133 - val_accuracy: 0.7654 - 6s/epoch - 48ms/step\n",
      "Epoch 37/100\n",
      "126/126 - 6s - loss: 0.0112 - accuracy: 0.9960 - val_loss: 1.7222 - val_accuracy: 0.7882 - 6s/epoch - 48ms/step\n",
      "Epoch 38/100\n",
      "126/126 - 6s - loss: 0.0119 - accuracy: 0.9953 - val_loss: 1.8233 - val_accuracy: 0.7631 - 6s/epoch - 48ms/step\n",
      "Epoch 39/100\n",
      "126/126 - 6s - loss: 0.0121 - accuracy: 0.9950 - val_loss: 1.7530 - val_accuracy: 0.7859 - 6s/epoch - 48ms/step\n",
      "Epoch 40/100\n",
      "126/126 - 6s - loss: 0.0117 - accuracy: 0.9953 - val_loss: 1.9087 - val_accuracy: 0.7745 - 6s/epoch - 47ms/step\n",
      "Epoch 41/100\n",
      "126/126 - 6s - loss: 0.0146 - accuracy: 0.9943 - val_loss: 1.7598 - val_accuracy: 0.7813 - 6s/epoch - 47ms/step\n",
      "Epoch 42/100\n",
      "126/126 - 6s - loss: 0.0261 - accuracy: 0.9901 - val_loss: 1.7277 - val_accuracy: 0.7677 - 6s/epoch - 46ms/step\n",
      "Epoch 43/100\n",
      "126/126 - 6s - loss: 0.0464 - accuracy: 0.9843 - val_loss: 1.6700 - val_accuracy: 0.7790 - 6s/epoch - 47ms/step\n",
      "Epoch 44/100\n",
      "126/126 - 6s - loss: 0.0212 - accuracy: 0.9916 - val_loss: 1.6882 - val_accuracy: 0.7699 - 6s/epoch - 46ms/step\n",
      "Epoch 45/100\n",
      "126/126 - 6s - loss: 0.0156 - accuracy: 0.9938 - val_loss: 1.7772 - val_accuracy: 0.7722 - 6s/epoch - 46ms/step\n",
      "Epoch 46/100\n",
      "126/126 - 6s - loss: 0.0130 - accuracy: 0.9935 - val_loss: 1.7398 - val_accuracy: 0.7631 - 6s/epoch - 46ms/step\n",
      "Epoch 47/100\n",
      "126/126 - 6s - loss: 0.0103 - accuracy: 0.9963 - val_loss: 1.7888 - val_accuracy: 0.7813 - 6s/epoch - 46ms/step\n",
      "Epoch 48/100\n",
      "126/126 - 6s - loss: 0.0140 - accuracy: 0.9953 - val_loss: 1.7987 - val_accuracy: 0.7836 - 6s/epoch - 46ms/step\n",
      "Epoch 49/100\n",
      "126/126 - 6s - loss: 0.0094 - accuracy: 0.9965 - val_loss: 1.8711 - val_accuracy: 0.7654 - 6s/epoch - 46ms/step\n",
      "Epoch 50/100\n",
      "126/126 - 6s - loss: 0.0115 - accuracy: 0.9955 - val_loss: 1.9064 - val_accuracy: 0.7722 - 6s/epoch - 46ms/step\n",
      "Epoch 51/100\n",
      "126/126 - 6s - loss: 0.0254 - accuracy: 0.9911 - val_loss: 1.8084 - val_accuracy: 0.7677 - 6s/epoch - 46ms/step\n",
      "Epoch 52/100\n",
      "126/126 - 6s - loss: 0.0523 - accuracy: 0.9841 - val_loss: 1.6077 - val_accuracy: 0.7494 - 6s/epoch - 47ms/step\n",
      "Epoch 53/100\n",
      "126/126 - 6s - loss: 0.0167 - accuracy: 0.9943 - val_loss: 1.6637 - val_accuracy: 0.7540 - 6s/epoch - 47ms/step\n",
      "Epoch 54/100\n",
      "126/126 - 6s - loss: 0.0552 - accuracy: 0.9871 - val_loss: 1.5058 - val_accuracy: 0.7631 - 6s/epoch - 47ms/step\n",
      "Epoch 55/100\n",
      "126/126 - 6s - loss: 0.0357 - accuracy: 0.9888 - val_loss: 1.5890 - val_accuracy: 0.7699 - 6s/epoch - 47ms/step\n",
      "Epoch 56/100\n",
      "126/126 - 6s - loss: 0.0127 - accuracy: 0.9968 - val_loss: 1.5388 - val_accuracy: 0.7836 - 6s/epoch - 47ms/step\n",
      "Epoch 57/100\n",
      "126/126 - 6s - loss: 0.0095 - accuracy: 0.9963 - val_loss: 1.5907 - val_accuracy: 0.7790 - 6s/epoch - 47ms/step\n",
      "Epoch 58/100\n",
      "126/126 - 6s - loss: 0.0079 - accuracy: 0.9975 - val_loss: 1.6109 - val_accuracy: 0.7790 - 6s/epoch - 47ms/step\n",
      "Epoch 59/100\n",
      "126/126 - 6s - loss: 0.0077 - accuracy: 0.9963 - val_loss: 1.7110 - val_accuracy: 0.7722 - 6s/epoch - 47ms/step\n",
      "Epoch 60/100\n",
      "126/126 - 6s - loss: 0.0098 - accuracy: 0.9965 - val_loss: 1.7346 - val_accuracy: 0.7722 - 6s/epoch - 47ms/step\n",
      "Epoch 61/100\n",
      "126/126 - 6s - loss: 0.0098 - accuracy: 0.9965 - val_loss: 1.7813 - val_accuracy: 0.7699 - 6s/epoch - 46ms/step\n",
      "Epoch 62/100\n",
      "126/126 - 6s - loss: 0.0069 - accuracy: 0.9975 - val_loss: 1.7865 - val_accuracy: 0.7722 - 6s/epoch - 46ms/step\n",
      "Epoch 63/100\n",
      "126/126 - 6s - loss: 0.0066 - accuracy: 0.9978 - val_loss: 1.8142 - val_accuracy: 0.7745 - 6s/epoch - 47ms/step\n",
      "Epoch 64/100\n",
      "126/126 - 6s - loss: 0.0068 - accuracy: 0.9965 - val_loss: 1.8373 - val_accuracy: 0.7722 - 6s/epoch - 47ms/step\n",
      "Epoch 65/100\n",
      "126/126 - 6s - loss: 0.0069 - accuracy: 0.9975 - val_loss: 1.8725 - val_accuracy: 0.7768 - 6s/epoch - 47ms/step\n",
      "Epoch 66/100\n",
      "126/126 - 6s - loss: 0.0077 - accuracy: 0.9955 - val_loss: 1.8955 - val_accuracy: 0.7699 - 6s/epoch - 47ms/step\n",
      "Epoch 67/100\n",
      "126/126 - 6s - loss: 0.0067 - accuracy: 0.9975 - val_loss: 1.8545 - val_accuracy: 0.7790 - 6s/epoch - 46ms/step\n",
      "Epoch 68/100\n",
      "126/126 - 6s - loss: 0.0068 - accuracy: 0.9978 - val_loss: 1.8807 - val_accuracy: 0.7722 - 6s/epoch - 46ms/step\n",
      "Epoch 69/100\n",
      "126/126 - 6s - loss: 0.0081 - accuracy: 0.9968 - val_loss: 1.9436 - val_accuracy: 0.7631 - 6s/epoch - 48ms/step\n",
      "Epoch 70/100\n",
      "126/126 - 6s - loss: 0.0084 - accuracy: 0.9965 - val_loss: 1.8577 - val_accuracy: 0.7768 - 6s/epoch - 49ms/step\n",
      "Epoch 71/100\n",
      "126/126 - 6s - loss: 0.0082 - accuracy: 0.9968 - val_loss: 1.9098 - val_accuracy: 0.7677 - 6s/epoch - 49ms/step\n",
      "Epoch 72/100\n",
      "126/126 - 6s - loss: 0.0071 - accuracy: 0.9963 - val_loss: 1.9414 - val_accuracy: 0.7631 - 6s/epoch - 48ms/step\n",
      "Epoch 73/100\n",
      "126/126 - 6s - loss: 0.0107 - accuracy: 0.9968 - val_loss: 1.8219 - val_accuracy: 0.7768 - 6s/epoch - 48ms/step\n",
      "Epoch 74/100\n",
      "126/126 - 6s - loss: 0.0138 - accuracy: 0.9945 - val_loss: 1.7627 - val_accuracy: 0.7722 - 6s/epoch - 48ms/step\n",
      "Epoch 75/100\n",
      "126/126 - 6s - loss: 0.0316 - accuracy: 0.9898 - val_loss: 1.7835 - val_accuracy: 0.7699 - 6s/epoch - 48ms/step\n",
      "Epoch 76/100\n",
      "126/126 - 6s - loss: 0.0377 - accuracy: 0.9898 - val_loss: 1.8469 - val_accuracy: 0.7403 - 6s/epoch - 48ms/step\n",
      "Epoch 77/100\n",
      "126/126 - 6s - loss: 0.0438 - accuracy: 0.9868 - val_loss: 1.7572 - val_accuracy: 0.7722 - 6s/epoch - 49ms/step\n",
      "Epoch 78/100\n",
      "126/126 - 6s - loss: 0.0297 - accuracy: 0.9903 - val_loss: 1.6459 - val_accuracy: 0.7631 - 6s/epoch - 48ms/step\n",
      "Epoch 79/100\n",
      "126/126 - 6s - loss: 0.0275 - accuracy: 0.9916 - val_loss: 1.6200 - val_accuracy: 0.7608 - 6s/epoch - 48ms/step\n",
      "Epoch 80/100\n",
      "126/126 - 6s - loss: 0.0087 - accuracy: 0.9965 - val_loss: 1.6978 - val_accuracy: 0.7585 - 6s/epoch - 48ms/step\n",
      "Epoch 81/100\n",
      "126/126 - 6s - loss: 0.0081 - accuracy: 0.9960 - val_loss: 1.7715 - val_accuracy: 0.7563 - 6s/epoch - 48ms/step\n",
      "Epoch 82/100\n",
      "126/126 - 6s - loss: 0.0069 - accuracy: 0.9978 - val_loss: 1.8003 - val_accuracy: 0.7585 - 6s/epoch - 48ms/step\n",
      "Epoch 83/100\n",
      "126/126 - 6s - loss: 0.0057 - accuracy: 0.9978 - val_loss: 1.8376 - val_accuracy: 0.7654 - 6s/epoch - 49ms/step\n",
      "Epoch 84/100\n",
      "126/126 - 6s - loss: 0.0053 - accuracy: 0.9978 - val_loss: 1.9134 - val_accuracy: 0.7608 - 6s/epoch - 48ms/step\n",
      "Epoch 85/100\n",
      "126/126 - 6s - loss: 0.0054 - accuracy: 0.9975 - val_loss: 1.9376 - val_accuracy: 0.7585 - 6s/epoch - 48ms/step\n",
      "Epoch 86/100\n",
      "126/126 - 6s - loss: 0.0063 - accuracy: 0.9975 - val_loss: 1.9623 - val_accuracy: 0.7585 - 6s/epoch - 49ms/step\n",
      "Epoch 87/100\n",
      "126/126 - 6s - loss: 0.0065 - accuracy: 0.9973 - val_loss: 1.9555 - val_accuracy: 0.7654 - 6s/epoch - 48ms/step\n",
      "Epoch 88/100\n",
      "126/126 - 6s - loss: 0.0065 - accuracy: 0.9970 - val_loss: 1.9875 - val_accuracy: 0.7563 - 6s/epoch - 47ms/step\n",
      "Epoch 89/100\n",
      "126/126 - 6s - loss: 0.0063 - accuracy: 0.9970 - val_loss: 1.9688 - val_accuracy: 0.7608 - 6s/epoch - 47ms/step\n",
      "Epoch 90/100\n",
      "126/126 - 7s - loss: 0.0063 - accuracy: 0.9970 - val_loss: 1.9870 - val_accuracy: 0.7677 - 7s/epoch - 52ms/step\n",
      "Epoch 91/100\n",
      "126/126 - 7s - loss: 0.0064 - accuracy: 0.9978 - val_loss: 1.9908 - val_accuracy: 0.7631 - 7s/epoch - 52ms/step\n",
      "Epoch 92/100\n",
      "126/126 - 6s - loss: 0.0069 - accuracy: 0.9968 - val_loss: 2.0800 - val_accuracy: 0.7654 - 6s/epoch - 49ms/step\n",
      "Epoch 93/100\n",
      "126/126 - 6s - loss: 0.0060 - accuracy: 0.9975 - val_loss: 2.0907 - val_accuracy: 0.7654 - 6s/epoch - 50ms/step\n",
      "Epoch 94/100\n",
      "126/126 - 6s - loss: 0.0059 - accuracy: 0.9973 - val_loss: 2.0349 - val_accuracy: 0.7745 - 6s/epoch - 47ms/step\n",
      "Epoch 95/100\n",
      "126/126 - 6s - loss: 0.0066 - accuracy: 0.9968 - val_loss: 2.0602 - val_accuracy: 0.7722 - 6s/epoch - 48ms/step\n",
      "Epoch 96/100\n",
      "126/126 - 6s - loss: 0.0070 - accuracy: 0.9970 - val_loss: 2.1167 - val_accuracy: 0.7654 - 6s/epoch - 46ms/step\n",
      "Epoch 97/100\n",
      "126/126 - 6s - loss: 0.0051 - accuracy: 0.9975 - val_loss: 2.0490 - val_accuracy: 0.7631 - 6s/epoch - 48ms/step\n",
      "Epoch 98/100\n",
      "126/126 - 6s - loss: 0.0066 - accuracy: 0.9970 - val_loss: 2.0851 - val_accuracy: 0.7654 - 6s/epoch - 47ms/step\n",
      "Epoch 99/100\n",
      "126/126 - 6s - loss: 0.0274 - accuracy: 0.9908 - val_loss: 1.8935 - val_accuracy: 0.7699 - 6s/epoch - 46ms/step\n",
      "Epoch 100/100\n",
      "126/126 - 6s - loss: 0.0508 - accuracy: 0.9846 - val_loss: 1.6363 - val_accuracy: 0.7631 - 6s/epoch - 46ms/step\n"
     ]
    }
   ],
   "source": [
    "history_bilstm_epochs_100 = model_bilstm_epochs_100.fit(\n",
    "        X_train_resampled,\n",
    "        y_train_resampled,\n",
    "        epochs=100,\n",
    "        validation_data=(X_test_padded, y_test),\n",
    "        verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Train Model Bi-LSTM (Parameter Trainable = True)</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_15 (Embedding)    (None, 100, 150)          978000    \n",
      "                                                                 \n",
      " bidirectional_7 (Bidirectio  (None, 200)              200800    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 200)               0         \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 64)                12864     \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,191,729\n",
      "Trainable params: 1,191,729\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_bilstm_trainable_true = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Embedding(embed_matrix_150D.shape[0], embed_matrix_150D.shape[1], input_length=maxlen, weights=[embed_matrix_150D], trainable=True),\n",
    "        tf.keras.layers.Bidirectional(LSTM(100)),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Create Optimizer\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model_bilstm_trainable_true.compile(\n",
    "        optimizer=opt,\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model_bilstm_trainable_true.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "126/126 - 14s - loss: 0.6250 - accuracy: 0.6404 - val_loss: 0.5800 - val_accuracy: 0.6629 - 14s/epoch - 109ms/step\n",
      "Epoch 2/100\n",
      "126/126 - 10s - loss: 0.4781 - accuracy: 0.7599 - val_loss: 0.5707 - val_accuracy: 0.6834 - 10s/epoch - 81ms/step\n",
      "Epoch 3/100\n",
      "126/126 - 10s - loss: 0.2839 - accuracy: 0.8834 - val_loss: 0.6072 - val_accuracy: 0.7608 - 10s/epoch - 78ms/step\n",
      "Epoch 4/100\n",
      "126/126 - 11s - loss: 0.1311 - accuracy: 0.9565 - val_loss: 0.6602 - val_accuracy: 0.7904 - 11s/epoch - 84ms/step\n",
      "Epoch 5/100\n",
      "126/126 - 10s - loss: 0.0492 - accuracy: 0.9863 - val_loss: 0.8245 - val_accuracy: 0.7813 - 10s/epoch - 79ms/step\n",
      "Epoch 6/100\n",
      "126/126 - 10s - loss: 0.0301 - accuracy: 0.9913 - val_loss: 1.0459 - val_accuracy: 0.7631 - 10s/epoch - 78ms/step\n",
      "Epoch 7/100\n",
      "126/126 - 11s - loss: 0.0174 - accuracy: 0.9940 - val_loss: 1.0414 - val_accuracy: 0.7722 - 11s/epoch - 84ms/step\n",
      "Epoch 8/100\n",
      "126/126 - 10s - loss: 0.0116 - accuracy: 0.9968 - val_loss: 1.2222 - val_accuracy: 0.7790 - 10s/epoch - 80ms/step\n",
      "Epoch 9/100\n",
      "126/126 - 10s - loss: 0.0163 - accuracy: 0.9945 - val_loss: 1.2303 - val_accuracy: 0.7790 - 10s/epoch - 80ms/step\n",
      "Epoch 10/100\n",
      "126/126 - 10s - loss: 0.0079 - accuracy: 0.9980 - val_loss: 1.3074 - val_accuracy: 0.7813 - 10s/epoch - 81ms/step\n",
      "Epoch 11/100\n",
      "126/126 - 10s - loss: 0.0114 - accuracy: 0.9958 - val_loss: 1.3511 - val_accuracy: 0.7950 - 10s/epoch - 82ms/step\n",
      "Epoch 12/100\n",
      "126/126 - 10s - loss: 0.0795 - accuracy: 0.9766 - val_loss: 1.1632 - val_accuracy: 0.7449 - 10s/epoch - 79ms/step\n",
      "Epoch 13/100\n",
      "126/126 - 10s - loss: 0.0149 - accuracy: 0.9960 - val_loss: 1.2149 - val_accuracy: 0.7563 - 10s/epoch - 80ms/step\n",
      "Epoch 14/100\n",
      "126/126 - 10s - loss: 0.0056 - accuracy: 0.9985 - val_loss: 1.4757 - val_accuracy: 0.7426 - 10s/epoch - 80ms/step\n",
      "Epoch 15/100\n",
      "126/126 - 10s - loss: 0.0044 - accuracy: 0.9985 - val_loss: 1.5317 - val_accuracy: 0.7563 - 10s/epoch - 80ms/step\n",
      "Epoch 16/100\n",
      "126/126 - 10s - loss: 0.0037 - accuracy: 0.9993 - val_loss: 1.5197 - val_accuracy: 0.7677 - 10s/epoch - 80ms/step\n",
      "Epoch 17/100\n",
      "126/126 - 10s - loss: 0.0041 - accuracy: 0.9980 - val_loss: 1.6248 - val_accuracy: 0.7517 - 10s/epoch - 79ms/step\n",
      "Epoch 18/100\n",
      "126/126 - 10s - loss: 0.0030 - accuracy: 0.9990 - val_loss: 1.6709 - val_accuracy: 0.7563 - 10s/epoch - 79ms/step\n",
      "Epoch 19/100\n",
      "126/126 - 10s - loss: 0.0027 - accuracy: 0.9990 - val_loss: 1.7097 - val_accuracy: 0.7380 - 10s/epoch - 79ms/step\n",
      "Epoch 20/100\n",
      "126/126 - 10s - loss: 0.0029 - accuracy: 0.9985 - val_loss: 1.6794 - val_accuracy: 0.7449 - 10s/epoch - 81ms/step\n",
      "Epoch 21/100\n",
      "126/126 - 13s - loss: 0.0038 - accuracy: 0.9983 - val_loss: 1.6256 - val_accuracy: 0.7722 - 13s/epoch - 100ms/step\n",
      "Epoch 22/100\n",
      "126/126 - 13s - loss: 0.0037 - accuracy: 0.9983 - val_loss: 1.6865 - val_accuracy: 0.7449 - 13s/epoch - 103ms/step\n",
      "Epoch 23/100\n",
      "126/126 - 10s - loss: 0.0033 - accuracy: 0.9988 - val_loss: 1.6753 - val_accuracy: 0.7585 - 10s/epoch - 82ms/step\n",
      "Epoch 24/100\n",
      "126/126 - 10s - loss: 0.0032 - accuracy: 0.9983 - val_loss: 1.6994 - val_accuracy: 0.7631 - 10s/epoch - 79ms/step\n",
      "Epoch 25/100\n",
      "126/126 - 9s - loss: 0.0034 - accuracy: 0.9980 - val_loss: 1.7281 - val_accuracy: 0.7449 - 9s/epoch - 75ms/step\n",
      "Epoch 26/100\n",
      "126/126 - 10s - loss: 0.0018 - accuracy: 0.9990 - val_loss: 1.8492 - val_accuracy: 0.7403 - 10s/epoch - 80ms/step\n",
      "Epoch 27/100\n",
      "126/126 - 10s - loss: 0.0021 - accuracy: 0.9988 - val_loss: 1.7882 - val_accuracy: 0.7517 - 10s/epoch - 81ms/step\n",
      "Epoch 28/100\n",
      "126/126 - 10s - loss: 0.0043 - accuracy: 0.9985 - val_loss: 1.8749 - val_accuracy: 0.7312 - 10s/epoch - 81ms/step\n",
      "Epoch 29/100\n",
      "126/126 - 10s - loss: 0.0033 - accuracy: 0.9985 - val_loss: 1.7648 - val_accuracy: 0.7517 - 10s/epoch - 79ms/step\n",
      "Epoch 30/100\n",
      "126/126 - 10s - loss: 0.0025 - accuracy: 0.9988 - val_loss: 1.7236 - val_accuracy: 0.7585 - 10s/epoch - 79ms/step\n",
      "Epoch 31/100\n",
      "126/126 - 10s - loss: 0.0033 - accuracy: 0.9983 - val_loss: 1.7840 - val_accuracy: 0.7403 - 10s/epoch - 80ms/step\n",
      "Epoch 32/100\n",
      "126/126 - 10s - loss: 0.0030 - accuracy: 0.9980 - val_loss: 1.4775 - val_accuracy: 0.7882 - 10s/epoch - 80ms/step\n",
      "Epoch 33/100\n",
      "126/126 - 10s - loss: 0.0074 - accuracy: 0.9978 - val_loss: 1.7100 - val_accuracy: 0.7790 - 10s/epoch - 80ms/step\n",
      "Epoch 34/100\n",
      "126/126 - 10s - loss: 0.0048 - accuracy: 0.9983 - val_loss: 2.0368 - val_accuracy: 0.7472 - 10s/epoch - 81ms/step\n",
      "Epoch 35/100\n",
      "126/126 - 10s - loss: 0.0058 - accuracy: 0.9975 - val_loss: 1.5111 - val_accuracy: 0.7563 - 10s/epoch - 81ms/step\n",
      "Epoch 36/100\n",
      "126/126 - 10s - loss: 0.0098 - accuracy: 0.9965 - val_loss: 1.6521 - val_accuracy: 0.7585 - 10s/epoch - 81ms/step\n",
      "Epoch 37/100\n",
      "126/126 - 10s - loss: 0.0031 - accuracy: 0.9990 - val_loss: 1.7599 - val_accuracy: 0.7563 - 10s/epoch - 81ms/step\n",
      "Epoch 38/100\n",
      "126/126 - 10s - loss: 0.0124 - accuracy: 0.9958 - val_loss: 1.2835 - val_accuracy: 0.7745 - 10s/epoch - 80ms/step\n",
      "Epoch 39/100\n",
      "126/126 - 10s - loss: 0.0056 - accuracy: 0.9978 - val_loss: 1.5313 - val_accuracy: 0.7677 - 10s/epoch - 80ms/step\n",
      "Epoch 40/100\n",
      "126/126 - 10s - loss: 0.0043 - accuracy: 0.9983 - val_loss: 1.5662 - val_accuracy: 0.7631 - 10s/epoch - 80ms/step\n",
      "Epoch 41/100\n",
      "126/126 - 10s - loss: 0.0019 - accuracy: 0.9995 - val_loss: 1.6502 - val_accuracy: 0.7677 - 10s/epoch - 80ms/step\n",
      "Epoch 42/100\n",
      "126/126 - 10s - loss: 0.0029 - accuracy: 0.9983 - val_loss: 1.6835 - val_accuracy: 0.7631 - 10s/epoch - 79ms/step\n",
      "Epoch 43/100\n",
      "126/126 - 10s - loss: 0.0015 - accuracy: 0.9993 - val_loss: 1.7534 - val_accuracy: 0.7722 - 10s/epoch - 80ms/step\n",
      "Epoch 44/100\n",
      "126/126 - 10s - loss: 0.0024 - accuracy: 0.9983 - val_loss: 1.7374 - val_accuracy: 0.7654 - 10s/epoch - 80ms/step\n",
      "Epoch 45/100\n",
      "126/126 - 10s - loss: 0.0021 - accuracy: 0.9985 - val_loss: 1.7267 - val_accuracy: 0.7699 - 10s/epoch - 80ms/step\n",
      "Epoch 46/100\n",
      "126/126 - 10s - loss: 0.0026 - accuracy: 0.9985 - val_loss: 1.7699 - val_accuracy: 0.7631 - 10s/epoch - 80ms/step\n",
      "Epoch 47/100\n",
      "126/126 - 10s - loss: 0.0021 - accuracy: 0.9985 - val_loss: 1.7260 - val_accuracy: 0.7699 - 10s/epoch - 80ms/step\n",
      "Epoch 48/100\n",
      "126/126 - 10s - loss: 0.0036 - accuracy: 0.9983 - val_loss: 1.7539 - val_accuracy: 0.7677 - 10s/epoch - 81ms/step\n",
      "Epoch 49/100\n",
      "126/126 - 10s - loss: 0.0022 - accuracy: 0.9983 - val_loss: 1.6972 - val_accuracy: 0.7654 - 10s/epoch - 81ms/step\n",
      "Epoch 50/100\n",
      "126/126 - 10s - loss: 0.0026 - accuracy: 0.9988 - val_loss: 1.7781 - val_accuracy: 0.7699 - 10s/epoch - 81ms/step\n",
      "Epoch 51/100\n",
      "126/126 - 10s - loss: 0.0028 - accuracy: 0.9985 - val_loss: 1.7604 - val_accuracy: 0.7608 - 10s/epoch - 82ms/step\n",
      "Epoch 52/100\n",
      "126/126 - 10s - loss: 0.0027 - accuracy: 0.9985 - val_loss: 1.7102 - val_accuracy: 0.7608 - 10s/epoch - 82ms/step\n",
      "Epoch 53/100\n",
      "126/126 - 10s - loss: 0.0025 - accuracy: 0.9988 - val_loss: 1.7906 - val_accuracy: 0.7654 - 10s/epoch - 81ms/step\n",
      "Epoch 54/100\n",
      "126/126 - 10s - loss: 0.0026 - accuracy: 0.9980 - val_loss: 1.7270 - val_accuracy: 0.7654 - 10s/epoch - 82ms/step\n",
      "Epoch 55/100\n",
      "126/126 - 10s - loss: 0.0028 - accuracy: 0.9983 - val_loss: 1.7257 - val_accuracy: 0.7631 - 10s/epoch - 81ms/step\n",
      "Epoch 56/100\n",
      "126/126 - 10s - loss: 0.0021 - accuracy: 0.9988 - val_loss: 1.7268 - val_accuracy: 0.7654 - 10s/epoch - 81ms/step\n",
      "Epoch 57/100\n",
      "126/126 - 10s - loss: 0.0028 - accuracy: 0.9983 - val_loss: 1.7612 - val_accuracy: 0.7699 - 10s/epoch - 81ms/step\n",
      "Epoch 58/100\n",
      "126/126 - 10s - loss: 0.0024 - accuracy: 0.9980 - val_loss: 1.8025 - val_accuracy: 0.7654 - 10s/epoch - 81ms/step\n",
      "Epoch 59/100\n",
      "126/126 - 10s - loss: 0.0020 - accuracy: 0.9983 - val_loss: 1.8389 - val_accuracy: 0.7654 - 10s/epoch - 81ms/step\n",
      "Epoch 60/100\n",
      "126/126 - 10s - loss: 0.0023 - accuracy: 0.9983 - val_loss: 1.8469 - val_accuracy: 0.7677 - 10s/epoch - 81ms/step\n",
      "Epoch 61/100\n",
      "126/126 - 10s - loss: 0.0019 - accuracy: 0.9988 - val_loss: 1.8841 - val_accuracy: 0.7677 - 10s/epoch - 83ms/step\n",
      "Epoch 62/100\n",
      "126/126 - 10s - loss: 0.0019 - accuracy: 0.9988 - val_loss: 1.8841 - val_accuracy: 0.7654 - 10s/epoch - 82ms/step\n",
      "Epoch 63/100\n",
      "126/126 - 10s - loss: 0.0411 - accuracy: 0.9888 - val_loss: 1.2848 - val_accuracy: 0.7585 - 10s/epoch - 82ms/step\n",
      "Epoch 64/100\n",
      "126/126 - 10s - loss: 0.0273 - accuracy: 0.9916 - val_loss: 1.0147 - val_accuracy: 0.7585 - 10s/epoch - 82ms/step\n",
      "Epoch 65/100\n",
      "126/126 - 10s - loss: 0.0107 - accuracy: 0.9963 - val_loss: 1.3502 - val_accuracy: 0.7449 - 10s/epoch - 82ms/step\n",
      "Epoch 66/100\n",
      "126/126 - 10s - loss: 0.0050 - accuracy: 0.9978 - val_loss: 1.2255 - val_accuracy: 0.7722 - 10s/epoch - 82ms/step\n",
      "Epoch 67/100\n",
      "126/126 - 10s - loss: 0.0052 - accuracy: 0.9980 - val_loss: 1.5493 - val_accuracy: 0.7494 - 10s/epoch - 81ms/step\n",
      "Epoch 68/100\n",
      "126/126 - 10s - loss: 0.0024 - accuracy: 0.9988 - val_loss: 1.6326 - val_accuracy: 0.7517 - 10s/epoch - 82ms/step\n",
      "Epoch 69/100\n",
      "126/126 - 10s - loss: 0.0019 - accuracy: 0.9990 - val_loss: 1.6861 - val_accuracy: 0.7585 - 10s/epoch - 82ms/step\n",
      "Epoch 70/100\n",
      "126/126 - 11s - loss: 0.0019 - accuracy: 0.9990 - val_loss: 1.8095 - val_accuracy: 0.7585 - 11s/epoch - 90ms/step\n",
      "Epoch 71/100\n",
      "126/126 - 10s - loss: 0.0024 - accuracy: 0.9985 - val_loss: 1.7654 - val_accuracy: 0.7585 - 10s/epoch - 83ms/step\n",
      "Epoch 72/100\n",
      "126/126 - 10s - loss: 0.0019 - accuracy: 0.9988 - val_loss: 1.8137 - val_accuracy: 0.7608 - 10s/epoch - 83ms/step\n",
      "Epoch 73/100\n",
      "126/126 - 11s - loss: 0.0018 - accuracy: 0.9988 - val_loss: 1.8908 - val_accuracy: 0.7608 - 11s/epoch - 84ms/step\n",
      "Epoch 74/100\n",
      "126/126 - 11s - loss: 0.0019 - accuracy: 0.9988 - val_loss: 1.9078 - val_accuracy: 0.7585 - 11s/epoch - 84ms/step\n",
      "Epoch 75/100\n",
      "126/126 - 10s - loss: 0.0017 - accuracy: 0.9988 - val_loss: 1.8694 - val_accuracy: 0.7631 - 10s/epoch - 83ms/step\n",
      "Epoch 76/100\n",
      "126/126 - 10s - loss: 0.0021 - accuracy: 0.9985 - val_loss: 1.8839 - val_accuracy: 0.7654 - 10s/epoch - 80ms/step\n",
      "Epoch 77/100\n",
      "126/126 - 10s - loss: 0.0018 - accuracy: 0.9983 - val_loss: 1.9474 - val_accuracy: 0.7654 - 10s/epoch - 76ms/step\n",
      "Epoch 78/100\n",
      "126/126 - 10s - loss: 0.0019 - accuracy: 0.9983 - val_loss: 1.9520 - val_accuracy: 0.7677 - 10s/epoch - 78ms/step\n",
      "Epoch 79/100\n",
      "126/126 - 11s - loss: 0.0018 - accuracy: 0.9993 - val_loss: 1.9652 - val_accuracy: 0.7654 - 11s/epoch - 84ms/step\n",
      "Epoch 80/100\n",
      "126/126 - 10s - loss: 0.0019 - accuracy: 0.9985 - val_loss: 2.0221 - val_accuracy: 0.7585 - 10s/epoch - 82ms/step\n",
      "Epoch 81/100\n",
      "126/126 - 10s - loss: 0.0022 - accuracy: 0.9985 - val_loss: 1.9860 - val_accuracy: 0.7608 - 10s/epoch - 81ms/step\n",
      "Epoch 82/100\n",
      "126/126 - 10s - loss: 0.0017 - accuracy: 0.9988 - val_loss: 1.9873 - val_accuracy: 0.7631 - 10s/epoch - 81ms/step\n",
      "Epoch 83/100\n",
      "126/126 - 11s - loss: 0.0019 - accuracy: 0.9990 - val_loss: 1.9203 - val_accuracy: 0.7654 - 11s/epoch - 84ms/step\n",
      "Epoch 84/100\n",
      "126/126 - 10s - loss: 0.0020 - accuracy: 0.9988 - val_loss: 1.9764 - val_accuracy: 0.7608 - 10s/epoch - 78ms/step\n",
      "Epoch 85/100\n",
      "126/126 - 10s - loss: 0.0020 - accuracy: 0.9990 - val_loss: 1.9982 - val_accuracy: 0.7585 - 10s/epoch - 79ms/step\n",
      "Epoch 86/100\n",
      "126/126 - 10s - loss: 0.0017 - accuracy: 0.9983 - val_loss: 2.0621 - val_accuracy: 0.7608 - 10s/epoch - 80ms/step\n",
      "Epoch 87/100\n",
      "126/126 - 11s - loss: 0.0022 - accuracy: 0.9983 - val_loss: 2.0019 - val_accuracy: 0.7608 - 11s/epoch - 90ms/step\n",
      "Epoch 88/100\n",
      "126/126 - 10s - loss: 0.0017 - accuracy: 0.9988 - val_loss: 1.9324 - val_accuracy: 0.7677 - 10s/epoch - 83ms/step\n",
      "Epoch 89/100\n",
      "126/126 - 12s - loss: 0.0019 - accuracy: 0.9985 - val_loss: 2.0234 - val_accuracy: 0.7631 - 12s/epoch - 92ms/step\n",
      "Epoch 90/100\n",
      "126/126 - 11s - loss: 0.0021 - accuracy: 0.9983 - val_loss: 1.9873 - val_accuracy: 0.7677 - 11s/epoch - 87ms/step\n",
      "Epoch 91/100\n",
      "126/126 - 10s - loss: 0.0019 - accuracy: 0.9983 - val_loss: 2.0746 - val_accuracy: 0.7677 - 10s/epoch - 78ms/step\n",
      "Epoch 92/100\n",
      "126/126 - 10s - loss: 0.0019 - accuracy: 0.9990 - val_loss: 1.9984 - val_accuracy: 0.7563 - 10s/epoch - 78ms/step\n",
      "Epoch 93/100\n",
      "126/126 - 11s - loss: 0.0019 - accuracy: 0.9985 - val_loss: 2.0631 - val_accuracy: 0.7608 - 11s/epoch - 85ms/step\n",
      "Epoch 94/100\n",
      "126/126 - 11s - loss: 0.0016 - accuracy: 0.9990 - val_loss: 2.1829 - val_accuracy: 0.7540 - 11s/epoch - 89ms/step\n",
      "Epoch 95/100\n",
      "126/126 - 11s - loss: 0.0017 - accuracy: 0.9988 - val_loss: 2.2381 - val_accuracy: 0.7563 - 11s/epoch - 86ms/step\n",
      "Epoch 96/100\n",
      "126/126 - 10s - loss: 0.0018 - accuracy: 0.9990 - val_loss: 2.1629 - val_accuracy: 0.7563 - 10s/epoch - 83ms/step\n",
      "Epoch 97/100\n",
      "126/126 - 10s - loss: 0.0020 - accuracy: 0.9983 - val_loss: 2.1941 - val_accuracy: 0.7563 - 10s/epoch - 82ms/step\n",
      "Epoch 98/100\n",
      "126/126 - 10s - loss: 0.0019 - accuracy: 0.9985 - val_loss: 2.1977 - val_accuracy: 0.7585 - 10s/epoch - 82ms/step\n",
      "Epoch 99/100\n",
      "126/126 - 10s - loss: 0.0017 - accuracy: 0.9985 - val_loss: 2.2225 - val_accuracy: 0.7585 - 10s/epoch - 83ms/step\n",
      "Epoch 100/100\n",
      "126/126 - 10s - loss: 0.0020 - accuracy: 0.9983 - val_loss: 2.2582 - val_accuracy: 0.7563 - 10s/epoch - 82ms/step\n"
     ]
    }
   ],
   "source": [
    "history_bilstm_trainable_true = model_bilstm_trainable_true.fit(\n",
    "        X_train_resampled,\n",
    "        y_train_resampled,\n",
    "        epochs=100,\n",
    "        validation_data=(X_test_padded, y_test),\n",
    "        verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Train Model Bi-LSTM (Parameter Learning Rate = 0.0001)</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_17 (Embedding)    (None, 100, 150)          978000    \n",
      "                                                                 \n",
      " bidirectional_8 (Bidirectio  (None, 200)              200800    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 200)               0         \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 64)                12864     \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,191,729\n",
      "Trainable params: 1,191,729\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_bilstm_learningrate_0_0001 = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Embedding(embed_matrix_150D.shape[0], embed_matrix_150D.shape[1], input_length=maxlen, weights=[embed_matrix_150D], trainable=True),\n",
    "        tf.keras.layers.Bidirectional(LSTM(100)),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Create Optimizer\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "model_bilstm_learningrate_0_0001.compile(\n",
    "        optimizer=opt,\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model_bilstm_learningrate_0_0001.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "126/126 - 16s - loss: 0.6929 - accuracy: 0.5102 - val_loss: 0.6908 - val_accuracy: 0.5604 - 16s/epoch - 124ms/step\n",
      "Epoch 2/100\n",
      "126/126 - 10s - loss: 0.6833 - accuracy: 0.5927 - val_loss: 0.6696 - val_accuracy: 0.6401 - 10s/epoch - 77ms/step\n",
      "Epoch 3/100\n",
      "126/126 - 10s - loss: 0.6002 - accuracy: 0.6938 - val_loss: 0.5940 - val_accuracy: 0.6902 - 10s/epoch - 77ms/step\n",
      "Epoch 4/100\n",
      "126/126 - 10s - loss: 0.5497 - accuracy: 0.7254 - val_loss: 0.5781 - val_accuracy: 0.7039 - 10s/epoch - 77ms/step\n",
      "Epoch 5/100\n",
      "126/126 - 10s - loss: 0.5157 - accuracy: 0.7433 - val_loss: 0.5682 - val_accuracy: 0.6970 - 10s/epoch - 77ms/step\n",
      "Epoch 6/100\n",
      "126/126 - 10s - loss: 0.4884 - accuracy: 0.7662 - val_loss: 0.5715 - val_accuracy: 0.6948 - 10s/epoch - 80ms/step\n",
      "Epoch 7/100\n",
      "126/126 - 10s - loss: 0.4568 - accuracy: 0.7860 - val_loss: 0.5587 - val_accuracy: 0.6925 - 10s/epoch - 78ms/step\n",
      "Epoch 8/100\n",
      "126/126 - 10s - loss: 0.4291 - accuracy: 0.8089 - val_loss: 0.5717 - val_accuracy: 0.6788 - 10s/epoch - 76ms/step\n",
      "Epoch 9/100\n",
      "126/126 - 10s - loss: 0.4011 - accuracy: 0.8223 - val_loss: 0.5548 - val_accuracy: 0.6925 - 10s/epoch - 79ms/step\n",
      "Epoch 10/100\n",
      "126/126 - 10s - loss: 0.3689 - accuracy: 0.8365 - val_loss: 0.6029 - val_accuracy: 0.6879 - 10s/epoch - 77ms/step\n",
      "Epoch 11/100\n",
      "126/126 - 10s - loss: 0.3474 - accuracy: 0.8472 - val_loss: 0.5822 - val_accuracy: 0.6811 - 10s/epoch - 77ms/step\n",
      "Epoch 12/100\n",
      "126/126 - 10s - loss: 0.3129 - accuracy: 0.8631 - val_loss: 0.6119 - val_accuracy: 0.6902 - 10s/epoch - 77ms/step\n",
      "Epoch 13/100\n",
      "126/126 - 10s - loss: 0.2880 - accuracy: 0.8767 - val_loss: 0.6785 - val_accuracy: 0.6856 - 10s/epoch - 77ms/step\n",
      "Epoch 14/100\n",
      "126/126 - 10s - loss: 0.2581 - accuracy: 0.8926 - val_loss: 0.7158 - val_accuracy: 0.7062 - 10s/epoch - 78ms/step\n",
      "Epoch 15/100\n",
      "126/126 - 10s - loss: 0.2306 - accuracy: 0.9043 - val_loss: 0.7244 - val_accuracy: 0.7175 - 10s/epoch - 79ms/step\n",
      "Epoch 16/100\n",
      "126/126 - 10s - loss: 0.1961 - accuracy: 0.9220 - val_loss: 0.8813 - val_accuracy: 0.7107 - 10s/epoch - 77ms/step\n",
      "Epoch 17/100\n",
      "126/126 - 10s - loss: 0.1730 - accuracy: 0.9319 - val_loss: 0.8651 - val_accuracy: 0.7380 - 10s/epoch - 77ms/step\n",
      "Epoch 18/100\n",
      "126/126 - 10s - loss: 0.1480 - accuracy: 0.9421 - val_loss: 0.8817 - val_accuracy: 0.7494 - 10s/epoch - 77ms/step\n",
      "Epoch 19/100\n",
      "126/126 - 10s - loss: 0.1388 - accuracy: 0.9533 - val_loss: 0.8744 - val_accuracy: 0.7517 - 10s/epoch - 78ms/step\n",
      "Epoch 20/100\n",
      "126/126 - 10s - loss: 0.1394 - accuracy: 0.9575 - val_loss: 0.9640 - val_accuracy: 0.7494 - 10s/epoch - 78ms/step\n",
      "Epoch 21/100\n",
      "126/126 - 10s - loss: 0.1032 - accuracy: 0.9674 - val_loss: 1.0203 - val_accuracy: 0.7494 - 10s/epoch - 78ms/step\n",
      "Epoch 22/100\n",
      "126/126 - 10s - loss: 0.0857 - accuracy: 0.9734 - val_loss: 1.1211 - val_accuracy: 0.7608 - 10s/epoch - 78ms/step\n",
      "Epoch 23/100\n",
      "126/126 - 10s - loss: 0.0767 - accuracy: 0.9744 - val_loss: 1.1873 - val_accuracy: 0.7540 - 10s/epoch - 78ms/step\n",
      "Epoch 24/100\n",
      "126/126 - 10s - loss: 0.0698 - accuracy: 0.9774 - val_loss: 1.2332 - val_accuracy: 0.7585 - 10s/epoch - 79ms/step\n",
      "Epoch 25/100\n",
      "126/126 - 10s - loss: 0.0625 - accuracy: 0.9831 - val_loss: 1.1981 - val_accuracy: 0.7745 - 10s/epoch - 78ms/step\n",
      "Epoch 26/100\n",
      "126/126 - 10s - loss: 0.0539 - accuracy: 0.9856 - val_loss: 1.3589 - val_accuracy: 0.7654 - 10s/epoch - 78ms/step\n",
      "Epoch 27/100\n",
      "126/126 - 10s - loss: 0.0495 - accuracy: 0.9876 - val_loss: 1.4791 - val_accuracy: 0.7585 - 10s/epoch - 77ms/step\n",
      "Epoch 28/100\n",
      "126/126 - 10s - loss: 0.0731 - accuracy: 0.9816 - val_loss: 1.2001 - val_accuracy: 0.7631 - 10s/epoch - 78ms/step\n",
      "Epoch 29/100\n",
      "126/126 - 10s - loss: 0.0421 - accuracy: 0.9898 - val_loss: 1.3810 - val_accuracy: 0.7563 - 10s/epoch - 78ms/step\n",
      "Epoch 30/100\n",
      "126/126 - 10s - loss: 0.0432 - accuracy: 0.9901 - val_loss: 1.3318 - val_accuracy: 0.7745 - 10s/epoch - 78ms/step\n",
      "Epoch 31/100\n",
      "126/126 - 10s - loss: 0.0343 - accuracy: 0.9928 - val_loss: 1.4573 - val_accuracy: 0.7699 - 10s/epoch - 78ms/step\n",
      "Epoch 32/100\n",
      "126/126 - 10s - loss: 0.0694 - accuracy: 0.9853 - val_loss: 1.1911 - val_accuracy: 0.7813 - 10s/epoch - 78ms/step\n",
      "Epoch 33/100\n",
      "126/126 - 10s - loss: 0.0328 - accuracy: 0.9925 - val_loss: 1.2800 - val_accuracy: 0.7745 - 10s/epoch - 79ms/step\n",
      "Epoch 34/100\n",
      "126/126 - 10s - loss: 0.0284 - accuracy: 0.9943 - val_loss: 1.3725 - val_accuracy: 0.7745 - 10s/epoch - 79ms/step\n",
      "Epoch 35/100\n",
      "126/126 - 10s - loss: 0.0243 - accuracy: 0.9953 - val_loss: 1.4357 - val_accuracy: 0.7768 - 10s/epoch - 79ms/step\n",
      "Epoch 36/100\n",
      "126/126 - 10s - loss: 0.0217 - accuracy: 0.9965 - val_loss: 1.4736 - val_accuracy: 0.7813 - 10s/epoch - 79ms/step\n",
      "Epoch 37/100\n",
      "126/126 - 10s - loss: 0.0207 - accuracy: 0.9953 - val_loss: 1.5505 - val_accuracy: 0.7813 - 10s/epoch - 79ms/step\n",
      "Epoch 38/100\n",
      "126/126 - 10s - loss: 0.0185 - accuracy: 0.9955 - val_loss: 1.6106 - val_accuracy: 0.7836 - 10s/epoch - 79ms/step\n",
      "Epoch 39/100\n",
      "126/126 - 10s - loss: 0.0176 - accuracy: 0.9970 - val_loss: 1.6115 - val_accuracy: 0.7768 - 10s/epoch - 79ms/step\n",
      "Epoch 40/100\n",
      "126/126 - 10s - loss: 0.0154 - accuracy: 0.9970 - val_loss: 1.7292 - val_accuracy: 0.7608 - 10s/epoch - 79ms/step\n",
      "Epoch 41/100\n",
      "126/126 - 10s - loss: 0.0149 - accuracy: 0.9963 - val_loss: 1.7160 - val_accuracy: 0.7790 - 10s/epoch - 79ms/step\n",
      "Epoch 42/100\n",
      "126/126 - 10s - loss: 0.0134 - accuracy: 0.9968 - val_loss: 1.7935 - val_accuracy: 0.7745 - 10s/epoch - 79ms/step\n",
      "Epoch 43/100\n",
      "126/126 - 10s - loss: 0.0230 - accuracy: 0.9953 - val_loss: 1.7817 - val_accuracy: 0.7745 - 10s/epoch - 79ms/step\n",
      "Epoch 44/100\n",
      "126/126 - 10s - loss: 0.0157 - accuracy: 0.9978 - val_loss: 1.7634 - val_accuracy: 0.7745 - 10s/epoch - 80ms/step\n",
      "Epoch 45/100\n",
      "126/126 - 10s - loss: 0.0120 - accuracy: 0.9975 - val_loss: 1.7527 - val_accuracy: 0.7722 - 10s/epoch - 78ms/step\n",
      "Epoch 46/100\n",
      "126/126 - 10s - loss: 0.0106 - accuracy: 0.9983 - val_loss: 1.8368 - val_accuracy: 0.7768 - 10s/epoch - 79ms/step\n",
      "Epoch 47/100\n",
      "126/126 - 10s - loss: 0.0106 - accuracy: 0.9978 - val_loss: 1.8515 - val_accuracy: 0.7768 - 10s/epoch - 78ms/step\n",
      "Epoch 48/100\n",
      "126/126 - 10s - loss: 0.0090 - accuracy: 0.9975 - val_loss: 1.8644 - val_accuracy: 0.7722 - 10s/epoch - 78ms/step\n",
      "Epoch 49/100\n",
      "126/126 - 10s - loss: 0.0086 - accuracy: 0.9978 - val_loss: 1.9298 - val_accuracy: 0.7745 - 10s/epoch - 78ms/step\n",
      "Epoch 50/100\n",
      "126/126 - 10s - loss: 0.0077 - accuracy: 0.9985 - val_loss: 2.0083 - val_accuracy: 0.7745 - 10s/epoch - 78ms/step\n",
      "Epoch 51/100\n",
      "126/126 - 10s - loss: 0.0082 - accuracy: 0.9978 - val_loss: 2.0803 - val_accuracy: 0.7677 - 10s/epoch - 78ms/step\n",
      "Epoch 52/100\n",
      "126/126 - 10s - loss: 0.0087 - accuracy: 0.9975 - val_loss: 2.0146 - val_accuracy: 0.7790 - 10s/epoch - 78ms/step\n",
      "Epoch 53/100\n",
      "126/126 - 10s - loss: 0.0067 - accuracy: 0.9990 - val_loss: 1.9967 - val_accuracy: 0.7836 - 10s/epoch - 80ms/step\n",
      "Epoch 54/100\n",
      "126/126 - 10s - loss: 0.0318 - accuracy: 0.9938 - val_loss: 1.8681 - val_accuracy: 0.7790 - 10s/epoch - 79ms/step\n",
      "Epoch 55/100\n",
      "126/126 - 10s - loss: 0.0220 - accuracy: 0.9938 - val_loss: 1.7472 - val_accuracy: 0.7836 - 10s/epoch - 79ms/step\n",
      "Epoch 56/100\n",
      "126/126 - 10s - loss: 0.0075 - accuracy: 0.9985 - val_loss: 1.8197 - val_accuracy: 0.7927 - 10s/epoch - 79ms/step\n",
      "Epoch 57/100\n",
      "126/126 - 10s - loss: 0.0069 - accuracy: 0.9985 - val_loss: 1.8386 - val_accuracy: 0.7950 - 10s/epoch - 79ms/step\n",
      "Epoch 58/100\n",
      "126/126 - 10s - loss: 0.0070 - accuracy: 0.9980 - val_loss: 1.8586 - val_accuracy: 0.7904 - 10s/epoch - 80ms/step\n",
      "Epoch 59/100\n",
      "126/126 - 10s - loss: 0.0067 - accuracy: 0.9978 - val_loss: 1.9506 - val_accuracy: 0.7882 - 10s/epoch - 79ms/step\n",
      "Epoch 60/100\n",
      "126/126 - 10s - loss: 0.0060 - accuracy: 0.9980 - val_loss: 1.9037 - val_accuracy: 0.7813 - 10s/epoch - 79ms/step\n",
      "Epoch 61/100\n",
      "126/126 - 10s - loss: 0.0059 - accuracy: 0.9978 - val_loss: 1.9771 - val_accuracy: 0.7859 - 10s/epoch - 80ms/step\n",
      "Epoch 62/100\n",
      "126/126 - 10s - loss: 0.0055 - accuracy: 0.9980 - val_loss: 1.9948 - val_accuracy: 0.7813 - 10s/epoch - 80ms/step\n",
      "Epoch 63/100\n",
      "126/126 - 10s - loss: 0.0051 - accuracy: 0.9985 - val_loss: 2.0802 - val_accuracy: 0.7904 - 10s/epoch - 80ms/step\n",
      "Epoch 64/100\n",
      "126/126 - 10s - loss: 0.0047 - accuracy: 0.9988 - val_loss: 2.0307 - val_accuracy: 0.7768 - 10s/epoch - 80ms/step\n",
      "Epoch 65/100\n",
      "126/126 - 10s - loss: 0.0048 - accuracy: 0.9983 - val_loss: 2.0448 - val_accuracy: 0.7745 - 10s/epoch - 79ms/step\n",
      "Epoch 66/100\n",
      "126/126 - 10s - loss: 0.0044 - accuracy: 0.9985 - val_loss: 2.0876 - val_accuracy: 0.7745 - 10s/epoch - 79ms/step\n",
      "Epoch 67/100\n",
      "126/126 - 10s - loss: 0.0039 - accuracy: 0.9995 - val_loss: 2.1206 - val_accuracy: 0.7768 - 10s/epoch - 80ms/step\n",
      "Epoch 68/100\n",
      "126/126 - 10s - loss: 0.0291 - accuracy: 0.9950 - val_loss: 2.0725 - val_accuracy: 0.7585 - 10s/epoch - 80ms/step\n",
      "Epoch 69/100\n",
      "126/126 - 10s - loss: 0.0343 - accuracy: 0.9935 - val_loss: 1.9458 - val_accuracy: 0.7540 - 10s/epoch - 80ms/step\n",
      "Epoch 70/100\n",
      "126/126 - 10s - loss: 0.0128 - accuracy: 0.9973 - val_loss: 1.7260 - val_accuracy: 0.7813 - 10s/epoch - 80ms/step\n",
      "Epoch 71/100\n",
      "126/126 - 10s - loss: 0.0070 - accuracy: 0.9983 - val_loss: 1.8337 - val_accuracy: 0.7768 - 10s/epoch - 79ms/step\n",
      "Epoch 72/100\n",
      "126/126 - 10s - loss: 0.0046 - accuracy: 0.9985 - val_loss: 1.8888 - val_accuracy: 0.7745 - 10s/epoch - 79ms/step\n",
      "Epoch 73/100\n",
      "126/126 - 10s - loss: 0.0040 - accuracy: 0.9985 - val_loss: 1.9604 - val_accuracy: 0.7768 - 10s/epoch - 80ms/step\n",
      "Epoch 74/100\n",
      "126/126 - 11s - loss: 0.0047 - accuracy: 0.9983 - val_loss: 2.0080 - val_accuracy: 0.7768 - 11s/epoch - 87ms/step\n",
      "Epoch 75/100\n",
      "126/126 - 10s - loss: 0.0039 - accuracy: 0.9990 - val_loss: 2.0140 - val_accuracy: 0.7722 - 10s/epoch - 79ms/step\n",
      "Epoch 76/100\n",
      "126/126 - 10s - loss: 0.0041 - accuracy: 0.9983 - val_loss: 2.0912 - val_accuracy: 0.7745 - 10s/epoch - 83ms/step\n",
      "Epoch 77/100\n",
      "126/126 - 10s - loss: 0.0041 - accuracy: 0.9980 - val_loss: 2.0869 - val_accuracy: 0.7699 - 10s/epoch - 82ms/step\n",
      "Epoch 78/100\n",
      "126/126 - 11s - loss: 0.0036 - accuracy: 0.9985 - val_loss: 2.1305 - val_accuracy: 0.7722 - 11s/epoch - 87ms/step\n",
      "Epoch 79/100\n",
      "126/126 - 12s - loss: 0.0035 - accuracy: 0.9985 - val_loss: 2.1607 - val_accuracy: 0.7722 - 12s/epoch - 92ms/step\n",
      "Epoch 80/100\n",
      "126/126 - 10s - loss: 0.0038 - accuracy: 0.9985 - val_loss: 2.1393 - val_accuracy: 0.7722 - 10s/epoch - 81ms/step\n",
      "Epoch 81/100\n",
      "126/126 - 10s - loss: 0.0035 - accuracy: 0.9988 - val_loss: 2.1402 - val_accuracy: 0.7699 - 10s/epoch - 80ms/step\n",
      "Epoch 82/100\n",
      "126/126 - 10s - loss: 0.0033 - accuracy: 0.9990 - val_loss: 2.1811 - val_accuracy: 0.7699 - 10s/epoch - 80ms/step\n",
      "Epoch 83/100\n",
      "126/126 - 10s - loss: 0.0032 - accuracy: 0.9985 - val_loss: 2.1895 - val_accuracy: 0.7699 - 10s/epoch - 80ms/step\n",
      "Epoch 84/100\n",
      "126/126 - 10s - loss: 0.0030 - accuracy: 0.9990 - val_loss: 2.2862 - val_accuracy: 0.7699 - 10s/epoch - 80ms/step\n",
      "Epoch 85/100\n",
      "126/126 - 10s - loss: 0.0036 - accuracy: 0.9985 - val_loss: 2.2810 - val_accuracy: 0.7699 - 10s/epoch - 81ms/step\n",
      "Epoch 86/100\n",
      "126/126 - 10s - loss: 0.0035 - accuracy: 0.9988 - val_loss: 2.2291 - val_accuracy: 0.7699 - 10s/epoch - 80ms/step\n",
      "Epoch 87/100\n",
      "126/126 - 10s - loss: 0.0027 - accuracy: 0.9995 - val_loss: 2.3028 - val_accuracy: 0.7677 - 10s/epoch - 81ms/step\n",
      "Epoch 88/100\n",
      "126/126 - 11s - loss: 0.0032 - accuracy: 0.9983 - val_loss: 2.3378 - val_accuracy: 0.7677 - 11s/epoch - 87ms/step\n",
      "Epoch 89/100\n",
      "126/126 - 10s - loss: 0.0027 - accuracy: 0.9988 - val_loss: 2.3115 - val_accuracy: 0.7677 - 10s/epoch - 77ms/step\n",
      "Epoch 90/100\n",
      "126/126 - 10s - loss: 0.0028 - accuracy: 0.9985 - val_loss: 2.3345 - val_accuracy: 0.7722 - 10s/epoch - 82ms/step\n",
      "Epoch 91/100\n",
      "126/126 - 10s - loss: 0.0032 - accuracy: 0.9988 - val_loss: 2.2836 - val_accuracy: 0.7768 - 10s/epoch - 79ms/step\n",
      "Epoch 92/100\n",
      "126/126 - 11s - loss: 0.0026 - accuracy: 0.9990 - val_loss: 2.4226 - val_accuracy: 0.7722 - 11s/epoch - 84ms/step\n",
      "Epoch 93/100\n",
      "126/126 - 11s - loss: 0.0023 - accuracy: 0.9990 - val_loss: 2.4282 - val_accuracy: 0.7768 - 11s/epoch - 84ms/step\n",
      "Epoch 94/100\n",
      "126/126 - 10s - loss: 0.0026 - accuracy: 0.9985 - val_loss: 2.4463 - val_accuracy: 0.7768 - 10s/epoch - 78ms/step\n",
      "Epoch 95/100\n",
      "126/126 - 10s - loss: 0.0028 - accuracy: 0.9985 - val_loss: 2.4499 - val_accuracy: 0.7790 - 10s/epoch - 78ms/step\n",
      "Epoch 96/100\n",
      "126/126 - 10s - loss: 0.0031 - accuracy: 0.9983 - val_loss: 2.4692 - val_accuracy: 0.7768 - 10s/epoch - 82ms/step\n",
      "Epoch 97/100\n",
      "126/126 - 11s - loss: 0.0030 - accuracy: 0.9985 - val_loss: 2.3850 - val_accuracy: 0.7768 - 11s/epoch - 84ms/step\n",
      "Epoch 98/100\n",
      "126/126 - 10s - loss: 0.0019 - accuracy: 0.9993 - val_loss: 2.5492 - val_accuracy: 0.7745 - 10s/epoch - 82ms/step\n",
      "Epoch 99/100\n",
      "126/126 - 11s - loss: 0.0022 - accuracy: 0.9993 - val_loss: 2.4315 - val_accuracy: 0.7813 - 11s/epoch - 86ms/step\n",
      "Epoch 100/100\n",
      "126/126 - 11s - loss: 0.0029 - accuracy: 0.9990 - val_loss: 2.1700 - val_accuracy: 0.7882 - 11s/epoch - 83ms/step\n"
     ]
    }
   ],
   "source": [
    "history_bilstm_learningrate_0_0001 = model_bilstm_learningrate_0_0001.fit(\n",
    "        X_train_resampled,\n",
    "        y_train_resampled,\n",
    "        epochs=100,\n",
    "        validation_data=(X_test_padded, y_test),\n",
    "        verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Train Model Bi-LSTM (Parameter Learning Rate = 0.01)</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_18 (Embedding)    (None, 100, 150)          978000    \n",
      "                                                                 \n",
      " bidirectional_9 (Bidirectio  (None, 200)              200800    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 200)               0         \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 64)                12864     \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,191,729\n",
      "Trainable params: 1,191,729\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_bilstm_learningrate_0_01 = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Embedding(embed_matrix_150D.shape[0], embed_matrix_150D.shape[1], input_length=maxlen, weights=[embed_matrix_150D], trainable=True),\n",
    "        tf.keras.layers.Bidirectional(LSTM(100)),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Create Optimizer\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "model_bilstm_learningrate_0_01.compile(\n",
    "        optimizer=opt,\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model_bilstm_learningrate_0_01.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "126/126 - 13s - loss: 0.6134 - accuracy: 0.6426 - val_loss: 0.5275 - val_accuracy: 0.7107 - 13s/epoch - 107ms/step\n",
      "Epoch 2/100\n",
      "126/126 - 10s - loss: 0.3524 - accuracy: 0.8479 - val_loss: 0.6054 - val_accuracy: 0.7335 - 10s/epoch - 79ms/step\n",
      "Epoch 3/100\n",
      "126/126 - 10s - loss: 0.1413 - accuracy: 0.9525 - val_loss: 0.6050 - val_accuracy: 0.7927 - 10s/epoch - 79ms/step\n",
      "Epoch 4/100\n",
      "126/126 - 10s - loss: 0.0498 - accuracy: 0.9833 - val_loss: 0.8117 - val_accuracy: 0.7995 - 10s/epoch - 79ms/step\n",
      "Epoch 5/100\n",
      "126/126 - 10s - loss: 0.0329 - accuracy: 0.9876 - val_loss: 1.0075 - val_accuracy: 0.7768 - 10s/epoch - 79ms/step\n",
      "Epoch 6/100\n",
      "126/126 - 10s - loss: 0.0166 - accuracy: 0.9940 - val_loss: 1.2391 - val_accuracy: 0.7790 - 10s/epoch - 79ms/step\n",
      "Epoch 7/100\n",
      "126/126 - 10s - loss: 0.0060 - accuracy: 0.9978 - val_loss: 1.4305 - val_accuracy: 0.7859 - 10s/epoch - 79ms/step\n",
      "Epoch 8/100\n",
      "126/126 - 10s - loss: 0.0034 - accuracy: 0.9985 - val_loss: 1.5401 - val_accuracy: 0.7836 - 10s/epoch - 79ms/step\n",
      "Epoch 9/100\n",
      "126/126 - 10s - loss: 0.0049 - accuracy: 0.9983 - val_loss: 1.6296 - val_accuracy: 0.7631 - 10s/epoch - 80ms/step\n",
      "Epoch 10/100\n",
      "126/126 - 10s - loss: 0.0032 - accuracy: 0.9983 - val_loss: 1.7460 - val_accuracy: 0.7768 - 10s/epoch - 80ms/step\n",
      "Epoch 11/100\n",
      "126/126 - 10s - loss: 0.0027 - accuracy: 0.9985 - val_loss: 1.7964 - val_accuracy: 0.7790 - 10s/epoch - 79ms/step\n",
      "Epoch 12/100\n",
      "126/126 - 10s - loss: 0.0015 - accuracy: 0.9990 - val_loss: 1.8908 - val_accuracy: 0.7768 - 10s/epoch - 83ms/step\n",
      "Epoch 13/100\n",
      "126/126 - 10s - loss: 0.0020 - accuracy: 0.9988 - val_loss: 2.0364 - val_accuracy: 0.7745 - 10s/epoch - 82ms/step\n",
      "Epoch 14/100\n",
      "126/126 - 10s - loss: 0.0023 - accuracy: 0.9985 - val_loss: 2.0989 - val_accuracy: 0.7790 - 10s/epoch - 80ms/step\n",
      "Epoch 15/100\n",
      "126/126 - 10s - loss: 0.0030 - accuracy: 0.9988 - val_loss: 1.8456 - val_accuracy: 0.7790 - 10s/epoch - 81ms/step\n",
      "Epoch 16/100\n",
      "126/126 - 10s - loss: 0.0024 - accuracy: 0.9983 - val_loss: 1.8567 - val_accuracy: 0.7768 - 10s/epoch - 79ms/step\n",
      "Epoch 17/100\n",
      "126/126 - 10s - loss: 0.0021 - accuracy: 0.9988 - val_loss: 1.7784 - val_accuracy: 0.7768 - 10s/epoch - 79ms/step\n",
      "Epoch 18/100\n",
      "126/126 - 10s - loss: 0.0022 - accuracy: 0.9983 - val_loss: 1.8129 - val_accuracy: 0.7768 - 10s/epoch - 80ms/step\n",
      "Epoch 19/100\n",
      "126/126 - 10s - loss: 0.0019 - accuracy: 0.9985 - val_loss: 1.8814 - val_accuracy: 0.7699 - 10s/epoch - 80ms/step\n",
      "Epoch 20/100\n",
      "126/126 - 10s - loss: 0.0015 - accuracy: 0.9990 - val_loss: 1.9337 - val_accuracy: 0.7768 - 10s/epoch - 79ms/step\n",
      "Epoch 21/100\n",
      "126/126 - 10s - loss: 0.0024 - accuracy: 0.9980 - val_loss: 1.9673 - val_accuracy: 0.7699 - 10s/epoch - 80ms/step\n",
      "Epoch 22/100\n",
      "126/126 - 10s - loss: 0.0017 - accuracy: 0.9990 - val_loss: 2.1096 - val_accuracy: 0.7677 - 10s/epoch - 80ms/step\n",
      "Epoch 23/100\n",
      "126/126 - 10s - loss: 0.0026 - accuracy: 0.9988 - val_loss: 1.6512 - val_accuracy: 0.7768 - 10s/epoch - 79ms/step\n",
      "Epoch 24/100\n",
      "126/126 - 10s - loss: 0.0015 - accuracy: 0.9990 - val_loss: 1.9329 - val_accuracy: 0.7699 - 10s/epoch - 79ms/step\n",
      "Epoch 25/100\n",
      "126/126 - 10s - loss: 0.0014 - accuracy: 0.9990 - val_loss: 1.9286 - val_accuracy: 0.7677 - 10s/epoch - 79ms/step\n",
      "Epoch 26/100\n",
      "126/126 - 10s - loss: 0.0015 - accuracy: 0.9990 - val_loss: 2.0726 - val_accuracy: 0.7699 - 10s/epoch - 79ms/step\n",
      "Epoch 27/100\n",
      "126/126 - 10s - loss: 0.0017 - accuracy: 0.9990 - val_loss: 2.0846 - val_accuracy: 0.7699 - 10s/epoch - 80ms/step\n",
      "Epoch 28/100\n",
      "126/126 - 10s - loss: 0.0016 - accuracy: 0.9988 - val_loss: 2.1903 - val_accuracy: 0.7677 - 10s/epoch - 80ms/step\n",
      "Epoch 29/100\n",
      "126/126 - 10s - loss: 0.0019 - accuracy: 0.9988 - val_loss: 2.1517 - val_accuracy: 0.7654 - 10s/epoch - 80ms/step\n",
      "Epoch 30/100\n",
      "126/126 - 10s - loss: 0.0016 - accuracy: 0.9990 - val_loss: 2.1795 - val_accuracy: 0.7631 - 10s/epoch - 80ms/step\n",
      "Epoch 31/100\n",
      "126/126 - 10s - loss: 0.0014 - accuracy: 0.9995 - val_loss: 2.2627 - val_accuracy: 0.7677 - 10s/epoch - 80ms/step\n",
      "Epoch 32/100\n",
      "126/126 - 10s - loss: 0.0022 - accuracy: 0.9988 - val_loss: 2.3034 - val_accuracy: 0.7654 - 10s/epoch - 79ms/step\n",
      "Epoch 33/100\n",
      "126/126 - 10s - loss: 0.0016 - accuracy: 0.9993 - val_loss: 2.2312 - val_accuracy: 0.7631 - 10s/epoch - 79ms/step\n",
      "Epoch 34/100\n",
      "126/126 - 10s - loss: 0.0021 - accuracy: 0.9990 - val_loss: 2.3402 - val_accuracy: 0.7608 - 10s/epoch - 79ms/step\n",
      "Epoch 35/100\n",
      "126/126 - 10s - loss: 0.0014 - accuracy: 0.9988 - val_loss: 2.4090 - val_accuracy: 0.7654 - 10s/epoch - 79ms/step\n",
      "Epoch 36/100\n",
      "126/126 - 10s - loss: 0.0014 - accuracy: 0.9990 - val_loss: 2.4579 - val_accuracy: 0.7654 - 10s/epoch - 79ms/step\n",
      "Epoch 37/100\n",
      "126/126 - 10s - loss: 0.0014 - accuracy: 0.9990 - val_loss: 2.4942 - val_accuracy: 0.7699 - 10s/epoch - 79ms/step\n",
      "Epoch 38/100\n",
      "126/126 - 10s - loss: 0.0015 - accuracy: 0.9988 - val_loss: 2.5149 - val_accuracy: 0.7722 - 10s/epoch - 79ms/step\n",
      "Epoch 39/100\n",
      "126/126 - 10s - loss: 0.0018 - accuracy: 0.9993 - val_loss: 2.5990 - val_accuracy: 0.7585 - 10s/epoch - 78ms/step\n",
      "Epoch 40/100\n",
      "126/126 - 10s - loss: 0.0017 - accuracy: 0.9988 - val_loss: 2.4734 - val_accuracy: 0.7699 - 10s/epoch - 79ms/step\n",
      "Epoch 41/100\n",
      "126/126 - 10s - loss: 0.0014 - accuracy: 0.9990 - val_loss: 2.5372 - val_accuracy: 0.7699 - 10s/epoch - 79ms/step\n",
      "Epoch 42/100\n",
      "126/126 - 10s - loss: 0.0014 - accuracy: 0.9990 - val_loss: 2.5558 - val_accuracy: 0.7722 - 10s/epoch - 79ms/step\n",
      "Epoch 43/100\n",
      "126/126 - 10s - loss: 0.0014 - accuracy: 0.9990 - val_loss: 2.5742 - val_accuracy: 0.7677 - 10s/epoch - 79ms/step\n",
      "Epoch 44/100\n",
      "126/126 - 10s - loss: 0.0014 - accuracy: 0.9990 - val_loss: 2.5961 - val_accuracy: 0.7699 - 10s/epoch - 79ms/step\n",
      "Epoch 45/100\n",
      "126/126 - 10s - loss: 0.0014 - accuracy: 0.9993 - val_loss: 2.6749 - val_accuracy: 0.7722 - 10s/epoch - 80ms/step\n",
      "Epoch 46/100\n",
      "126/126 - 10s - loss: 0.0016 - accuracy: 0.9988 - val_loss: 2.6491 - val_accuracy: 0.7699 - 10s/epoch - 79ms/step\n",
      "Epoch 47/100\n",
      "126/126 - 10s - loss: 0.0014 - accuracy: 0.9993 - val_loss: 2.6381 - val_accuracy: 0.7722 - 10s/epoch - 79ms/step\n",
      "Epoch 48/100\n",
      "126/126 - 10s - loss: 0.0019 - accuracy: 0.9988 - val_loss: 2.7775 - val_accuracy: 0.7722 - 10s/epoch - 80ms/step\n",
      "Epoch 49/100\n",
      "126/126 - 10s - loss: 0.0031 - accuracy: 0.9988 - val_loss: 4.1932 - val_accuracy: 0.7335 - 10s/epoch - 79ms/step\n",
      "Epoch 50/100\n",
      "126/126 - 10s - loss: 0.2682 - accuracy: 0.9130 - val_loss: 0.6333 - val_accuracy: 0.7039 - 10s/epoch - 80ms/step\n",
      "Epoch 51/100\n",
      "126/126 - 10s - loss: 0.1771 - accuracy: 0.9354 - val_loss: 0.6809 - val_accuracy: 0.7198 - 10s/epoch - 79ms/step\n",
      "Epoch 52/100\n",
      "126/126 - 10s - loss: 0.1394 - accuracy: 0.9466 - val_loss: 1.0411 - val_accuracy: 0.6970 - 10s/epoch - 79ms/step\n",
      "Epoch 53/100\n",
      "126/126 - 10s - loss: 0.0880 - accuracy: 0.9674 - val_loss: 1.2299 - val_accuracy: 0.7062 - 10s/epoch - 80ms/step\n",
      "Epoch 54/100\n",
      "126/126 - 10s - loss: 0.0463 - accuracy: 0.9831 - val_loss: 1.7005 - val_accuracy: 0.7267 - 10s/epoch - 80ms/step\n",
      "Epoch 55/100\n",
      "126/126 - 10s - loss: 0.0300 - accuracy: 0.9908 - val_loss: 1.1809 - val_accuracy: 0.7358 - 10s/epoch - 80ms/step\n",
      "Epoch 56/100\n",
      "126/126 - 10s - loss: 0.0366 - accuracy: 0.9856 - val_loss: 1.4085 - val_accuracy: 0.7380 - 10s/epoch - 79ms/step\n",
      "Epoch 57/100\n",
      "126/126 - 10s - loss: 0.0446 - accuracy: 0.9856 - val_loss: 1.0534 - val_accuracy: 0.7358 - 10s/epoch - 80ms/step\n",
      "Epoch 58/100\n",
      "126/126 - 10s - loss: 0.0419 - accuracy: 0.9856 - val_loss: 1.1491 - val_accuracy: 0.7494 - 10s/epoch - 80ms/step\n",
      "Epoch 59/100\n",
      "126/126 - 10s - loss: 0.0280 - accuracy: 0.9901 - val_loss: 1.4823 - val_accuracy: 0.7267 - 10s/epoch - 80ms/step\n",
      "Epoch 60/100\n",
      "126/126 - 10s - loss: 0.0165 - accuracy: 0.9935 - val_loss: 1.8474 - val_accuracy: 0.7358 - 10s/epoch - 79ms/step\n",
      "Epoch 61/100\n",
      "126/126 - 10s - loss: 0.0088 - accuracy: 0.9970 - val_loss: 1.8410 - val_accuracy: 0.7403 - 10s/epoch - 79ms/step\n",
      "Epoch 62/100\n",
      "126/126 - 10s - loss: 0.0086 - accuracy: 0.9960 - val_loss: 2.0845 - val_accuracy: 0.7449 - 10s/epoch - 80ms/step\n",
      "Epoch 63/100\n",
      "126/126 - 10s - loss: 0.0156 - accuracy: 0.9948 - val_loss: 1.8652 - val_accuracy: 0.7335 - 10s/epoch - 79ms/step\n",
      "Epoch 64/100\n",
      "126/126 - 10s - loss: 0.0114 - accuracy: 0.9955 - val_loss: 1.7338 - val_accuracy: 0.7335 - 10s/epoch - 80ms/step\n",
      "Epoch 65/100\n",
      "126/126 - 10s - loss: 0.0255 - accuracy: 0.9916 - val_loss: 1.8803 - val_accuracy: 0.7335 - 10s/epoch - 79ms/step\n",
      "Epoch 66/100\n",
      "126/126 - 10s - loss: 0.0286 - accuracy: 0.9911 - val_loss: 1.6888 - val_accuracy: 0.7267 - 10s/epoch - 79ms/step\n",
      "Epoch 67/100\n",
      "126/126 - 10s - loss: 0.0289 - accuracy: 0.9906 - val_loss: 1.3177 - val_accuracy: 0.7426 - 10s/epoch - 79ms/step\n",
      "Epoch 68/100\n",
      "126/126 - 10s - loss: 0.0360 - accuracy: 0.9878 - val_loss: 1.5390 - val_accuracy: 0.7449 - 10s/epoch - 79ms/step\n",
      "Epoch 69/100\n",
      "126/126 - 10s - loss: 0.0294 - accuracy: 0.9896 - val_loss: 1.2993 - val_accuracy: 0.7403 - 10s/epoch - 81ms/step\n",
      "Epoch 70/100\n",
      "126/126 - 10s - loss: 0.0513 - accuracy: 0.9846 - val_loss: 1.3508 - val_accuracy: 0.7107 - 10s/epoch - 80ms/step\n",
      "Epoch 71/100\n",
      "126/126 - 10s - loss: 0.0283 - accuracy: 0.9888 - val_loss: 1.8281 - val_accuracy: 0.7175 - 10s/epoch - 80ms/step\n",
      "Epoch 72/100\n",
      "126/126 - 10s - loss: 0.0198 - accuracy: 0.9928 - val_loss: 2.0990 - val_accuracy: 0.7153 - 10s/epoch - 80ms/step\n",
      "Epoch 73/100\n",
      "126/126 - 10s - loss: 0.0276 - accuracy: 0.9930 - val_loss: 1.6624 - val_accuracy: 0.7312 - 10s/epoch - 80ms/step\n",
      "Epoch 74/100\n",
      "126/126 - 10s - loss: 0.0144 - accuracy: 0.9953 - val_loss: 2.1666 - val_accuracy: 0.7107 - 10s/epoch - 80ms/step\n",
      "Epoch 75/100\n",
      "126/126 - 10s - loss: 0.0196 - accuracy: 0.9940 - val_loss: 2.0317 - val_accuracy: 0.7267 - 10s/epoch - 81ms/step\n",
      "Epoch 76/100\n",
      "126/126 - 10s - loss: 0.0202 - accuracy: 0.9935 - val_loss: 1.4750 - val_accuracy: 0.7472 - 10s/epoch - 81ms/step\n",
      "Epoch 77/100\n",
      "126/126 - 10s - loss: 0.0207 - accuracy: 0.9933 - val_loss: 1.7818 - val_accuracy: 0.7312 - 10s/epoch - 81ms/step\n",
      "Epoch 78/100\n",
      "126/126 - 10s - loss: 0.0173 - accuracy: 0.9945 - val_loss: 1.7352 - val_accuracy: 0.7380 - 10s/epoch - 81ms/step\n",
      "Epoch 79/100\n",
      "126/126 - 10s - loss: 0.0108 - accuracy: 0.9958 - val_loss: 1.7785 - val_accuracy: 0.7472 - 10s/epoch - 81ms/step\n",
      "Epoch 80/100\n",
      "126/126 - 10s - loss: 0.0142 - accuracy: 0.9950 - val_loss: 1.7135 - val_accuracy: 0.7403 - 10s/epoch - 81ms/step\n",
      "Epoch 81/100\n",
      "126/126 - 10s - loss: 0.0219 - accuracy: 0.9908 - val_loss: 1.8038 - val_accuracy: 0.7494 - 10s/epoch - 81ms/step\n",
      "Epoch 82/100\n",
      "126/126 - 10s - loss: 0.0266 - accuracy: 0.9916 - val_loss: 1.4456 - val_accuracy: 0.7449 - 10s/epoch - 81ms/step\n",
      "Epoch 83/100\n",
      "126/126 - 10s - loss: 0.0149 - accuracy: 0.9943 - val_loss: 1.6784 - val_accuracy: 0.7563 - 10s/epoch - 82ms/step\n",
      "Epoch 84/100\n",
      "126/126 - 10s - loss: 0.0231 - accuracy: 0.9933 - val_loss: 1.4226 - val_accuracy: 0.7494 - 10s/epoch - 81ms/step\n",
      "Epoch 85/100\n",
      "126/126 - 10s - loss: 0.0127 - accuracy: 0.9943 - val_loss: 1.6468 - val_accuracy: 0.7380 - 10s/epoch - 81ms/step\n",
      "Epoch 86/100\n",
      "126/126 - 10s - loss: 0.0140 - accuracy: 0.9945 - val_loss: 1.8756 - val_accuracy: 0.7403 - 10s/epoch - 81ms/step\n",
      "Epoch 87/100\n",
      "126/126 - 10s - loss: 0.0175 - accuracy: 0.9940 - val_loss: 1.5425 - val_accuracy: 0.7403 - 10s/epoch - 81ms/step\n",
      "Epoch 88/100\n",
      "126/126 - 10s - loss: 0.0183 - accuracy: 0.9928 - val_loss: 1.6819 - val_accuracy: 0.7244 - 10s/epoch - 82ms/step\n",
      "Epoch 89/100\n",
      "126/126 - 10s - loss: 0.0099 - accuracy: 0.9973 - val_loss: 1.8608 - val_accuracy: 0.7380 - 10s/epoch - 82ms/step\n",
      "Epoch 90/100\n",
      "126/126 - 10s - loss: 0.0073 - accuracy: 0.9975 - val_loss: 2.3371 - val_accuracy: 0.7358 - 10s/epoch - 82ms/step\n",
      "Epoch 91/100\n",
      "126/126 - 10s - loss: 0.0079 - accuracy: 0.9960 - val_loss: 2.2725 - val_accuracy: 0.7221 - 10s/epoch - 81ms/step\n",
      "Epoch 92/100\n",
      "126/126 - 10s - loss: 0.0082 - accuracy: 0.9950 - val_loss: 1.9169 - val_accuracy: 0.7403 - 10s/epoch - 81ms/step\n",
      "Epoch 93/100\n",
      "126/126 - 10s - loss: 0.0065 - accuracy: 0.9970 - val_loss: 1.8886 - val_accuracy: 0.7472 - 10s/epoch - 81ms/step\n",
      "Epoch 94/100\n",
      "126/126 - 10s - loss: 0.0032 - accuracy: 0.9980 - val_loss: 2.3443 - val_accuracy: 0.7426 - 10s/epoch - 81ms/step\n",
      "Epoch 95/100\n",
      "126/126 - 10s - loss: 0.0055 - accuracy: 0.9968 - val_loss: 2.1943 - val_accuracy: 0.7494 - 10s/epoch - 81ms/step\n",
      "Epoch 96/100\n",
      "126/126 - 10s - loss: 0.0191 - accuracy: 0.9945 - val_loss: 1.7983 - val_accuracy: 0.7426 - 10s/epoch - 81ms/step\n",
      "Epoch 97/100\n",
      "126/126 - 10s - loss: 0.0090 - accuracy: 0.9965 - val_loss: 2.1705 - val_accuracy: 0.7472 - 10s/epoch - 81ms/step\n",
      "Epoch 98/100\n",
      "126/126 - 10s - loss: 0.0158 - accuracy: 0.9940 - val_loss: 2.0937 - val_accuracy: 0.7403 - 10s/epoch - 82ms/step\n",
      "Epoch 99/100\n",
      "126/126 - 10s - loss: 0.0246 - accuracy: 0.9913 - val_loss: 1.3904 - val_accuracy: 0.7335 - 10s/epoch - 81ms/step\n",
      "Epoch 100/100\n",
      "126/126 - 10s - loss: 0.0231 - accuracy: 0.9930 - val_loss: 1.5833 - val_accuracy: 0.7267 - 10s/epoch - 81ms/step\n"
     ]
    }
   ],
   "source": [
    "history_bilstm_learningrate_0_01 = model_bilstm_learningrate_0_01.fit(\n",
    "        X_train_resampled,\n",
    "        y_train_resampled,\n",
    "        epochs=100,\n",
    "        validation_data=(X_test_padded, y_test),\n",
    "        verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Train Model Bi-LSTM (Parameter Hidden Size = 128)</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 100, 150)          978000    \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 256)              285696    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                16448     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,280,209\n",
      "Trainable params: 1,280,209\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_bilstm_hidden_128 = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Embedding(embed_matrix_150D.shape[0], embed_matrix_150D.shape[1], input_length=maxlen, weights=[embed_matrix_150D], trainable=True),\n",
    "        tf.keras.layers.Bidirectional(LSTM(128)),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Create Optimizer\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "model_bilstm_hidden_128.compile(\n",
    "        optimizer=opt,\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model_bilstm_hidden_128.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "126/126 - 16s - loss: 0.6613 - accuracy: 0.5962 - val_loss: 0.5540 - val_accuracy: 0.6993 - 16s/epoch - 130ms/step\n",
      "Epoch 2/100\n",
      "126/126 - 12s - loss: 0.4310 - accuracy: 0.8111 - val_loss: 0.4915 - val_accuracy: 0.7631 - 12s/epoch - 99ms/step\n",
      "Epoch 3/100\n",
      "126/126 - 12s - loss: 0.2116 - accuracy: 0.9187 - val_loss: 0.5903 - val_accuracy: 0.7608 - 12s/epoch - 99ms/step\n",
      "Epoch 4/100\n",
      "126/126 - 13s - loss: 0.0896 - accuracy: 0.9719 - val_loss: 0.6583 - val_accuracy: 0.7517 - 13s/epoch - 100ms/step\n",
      "Epoch 5/100\n",
      "126/126 - 13s - loss: 0.0392 - accuracy: 0.9886 - val_loss: 1.2619 - val_accuracy: 0.7198 - 13s/epoch - 104ms/step\n",
      "Epoch 6/100\n",
      "126/126 - 13s - loss: 0.0239 - accuracy: 0.9925 - val_loss: 1.3575 - val_accuracy: 0.7426 - 13s/epoch - 104ms/step\n",
      "Epoch 7/100\n",
      "126/126 - 14s - loss: 0.0114 - accuracy: 0.9960 - val_loss: 1.4268 - val_accuracy: 0.7608 - 14s/epoch - 113ms/step\n",
      "Epoch 8/100\n",
      "126/126 - 14s - loss: 0.0069 - accuracy: 0.9978 - val_loss: 1.6780 - val_accuracy: 0.7494 - 14s/epoch - 108ms/step\n",
      "Epoch 9/100\n",
      "126/126 - 13s - loss: 0.0049 - accuracy: 0.9973 - val_loss: 1.7184 - val_accuracy: 0.7608 - 13s/epoch - 104ms/step\n",
      "Epoch 10/100\n",
      "126/126 - 13s - loss: 0.0072 - accuracy: 0.9970 - val_loss: 1.4243 - val_accuracy: 0.7699 - 13s/epoch - 104ms/step\n",
      "Epoch 11/100\n",
      "126/126 - 14s - loss: 0.0090 - accuracy: 0.9970 - val_loss: 1.6078 - val_accuracy: 0.7699 - 14s/epoch - 107ms/step\n",
      "Epoch 12/100\n",
      "126/126 - 13s - loss: 0.0109 - accuracy: 0.9958 - val_loss: 1.4247 - val_accuracy: 0.7631 - 13s/epoch - 101ms/step\n",
      "Epoch 13/100\n",
      "126/126 - 12s - loss: 0.0198 - accuracy: 0.9933 - val_loss: 1.4331 - val_accuracy: 0.7745 - 12s/epoch - 95ms/step\n",
      "Epoch 14/100\n",
      "126/126 - 12s - loss: 0.0211 - accuracy: 0.9925 - val_loss: 1.2372 - val_accuracy: 0.7790 - 12s/epoch - 94ms/step\n",
      "Epoch 15/100\n",
      "126/126 - 12s - loss: 0.0221 - accuracy: 0.9925 - val_loss: 1.6228 - val_accuracy: 0.7426 - 12s/epoch - 96ms/step\n",
      "Epoch 16/100\n",
      "126/126 - 13s - loss: 0.0105 - accuracy: 0.9960 - val_loss: 1.5994 - val_accuracy: 0.7494 - 13s/epoch - 101ms/step\n",
      "Epoch 17/100\n",
      "126/126 - 12s - loss: 0.0038 - accuracy: 0.9978 - val_loss: 2.1908 - val_accuracy: 0.7244 - 12s/epoch - 96ms/step\n",
      "Epoch 18/100\n",
      "126/126 - 12s - loss: 0.0055 - accuracy: 0.9980 - val_loss: 1.8323 - val_accuracy: 0.7472 - 12s/epoch - 96ms/step\n",
      "Epoch 19/100\n",
      "126/126 - 12s - loss: 0.0021 - accuracy: 0.9983 - val_loss: 2.1920 - val_accuracy: 0.7403 - 12s/epoch - 97ms/step\n",
      "Epoch 20/100\n",
      "126/126 - 12s - loss: 0.0021 - accuracy: 0.9983 - val_loss: 2.1426 - val_accuracy: 0.7494 - 12s/epoch - 96ms/step\n",
      "Epoch 21/100\n",
      "126/126 - 12s - loss: 0.0015 - accuracy: 0.9993 - val_loss: 2.2737 - val_accuracy: 0.7494 - 12s/epoch - 96ms/step\n",
      "Epoch 22/100\n",
      "126/126 - 12s - loss: 0.0017 - accuracy: 0.9985 - val_loss: 2.3316 - val_accuracy: 0.7472 - 12s/epoch - 96ms/step\n",
      "Epoch 23/100\n",
      "126/126 - 12s - loss: 0.0020 - accuracy: 0.9990 - val_loss: 2.1960 - val_accuracy: 0.7494 - 12s/epoch - 96ms/step\n",
      "Epoch 24/100\n",
      "126/126 - 12s - loss: 0.0017 - accuracy: 0.9985 - val_loss: 2.3440 - val_accuracy: 0.7494 - 12s/epoch - 98ms/step\n",
      "Epoch 25/100\n",
      "126/126 - 12s - loss: 0.0016 - accuracy: 0.9988 - val_loss: 2.3430 - val_accuracy: 0.7494 - 12s/epoch - 98ms/step\n",
      "Epoch 26/100\n",
      "126/126 - 12s - loss: 0.0018 - accuracy: 0.9990 - val_loss: 2.4748 - val_accuracy: 0.7472 - 12s/epoch - 98ms/step\n",
      "Epoch 27/100\n",
      "126/126 - 12s - loss: 0.0016 - accuracy: 0.9985 - val_loss: 2.5085 - val_accuracy: 0.7494 - 12s/epoch - 97ms/step\n",
      "Epoch 28/100\n",
      "126/126 - 12s - loss: 0.0016 - accuracy: 0.9988 - val_loss: 2.5087 - val_accuracy: 0.7517 - 12s/epoch - 98ms/step\n",
      "Epoch 29/100\n",
      "126/126 - 12s - loss: 0.0019 - accuracy: 0.9988 - val_loss: 2.5055 - val_accuracy: 0.7517 - 12s/epoch - 98ms/step\n",
      "Epoch 30/100\n",
      "126/126 - 12s - loss: 0.0018 - accuracy: 0.9988 - val_loss: 2.4528 - val_accuracy: 0.7494 - 12s/epoch - 97ms/step\n",
      "Epoch 31/100\n",
      "126/126 - 12s - loss: 0.0016 - accuracy: 0.9990 - val_loss: 2.5633 - val_accuracy: 0.7517 - 12s/epoch - 97ms/step\n",
      "Epoch 32/100\n",
      "126/126 - 13s - loss: 0.0018 - accuracy: 0.9990 - val_loss: 2.4896 - val_accuracy: 0.7540 - 13s/epoch - 101ms/step\n",
      "Epoch 33/100\n",
      "126/126 - 12s - loss: 0.0015 - accuracy: 0.9988 - val_loss: 2.5173 - val_accuracy: 0.7517 - 12s/epoch - 99ms/step\n",
      "Epoch 34/100\n",
      "126/126 - 12s - loss: 0.0014 - accuracy: 0.9988 - val_loss: 2.6186 - val_accuracy: 0.7472 - 12s/epoch - 99ms/step\n",
      "Epoch 35/100\n",
      "126/126 - 12s - loss: 0.0014 - accuracy: 0.9988 - val_loss: 2.7015 - val_accuracy: 0.7449 - 12s/epoch - 99ms/step\n",
      "Epoch 36/100\n",
      "126/126 - 13s - loss: 0.0016 - accuracy: 0.9985 - val_loss: 2.7029 - val_accuracy: 0.7472 - 13s/epoch - 100ms/step\n",
      "Epoch 37/100\n",
      "126/126 - 12s - loss: 0.0014 - accuracy: 0.9990 - val_loss: 2.7528 - val_accuracy: 0.7449 - 12s/epoch - 99ms/step\n",
      "Epoch 38/100\n",
      "126/126 - 13s - loss: 0.0015 - accuracy: 0.9985 - val_loss: 2.7384 - val_accuracy: 0.7449 - 13s/epoch - 101ms/step\n",
      "Epoch 39/100\n",
      "126/126 - 13s - loss: 0.0013 - accuracy: 0.9993 - val_loss: 2.8541 - val_accuracy: 0.7449 - 13s/epoch - 99ms/step\n",
      "Epoch 40/100\n",
      "126/126 - 12s - loss: 0.0024 - accuracy: 0.9988 - val_loss: 2.7530 - val_accuracy: 0.7472 - 12s/epoch - 99ms/step\n",
      "Epoch 41/100\n",
      "126/126 - 13s - loss: 0.0017 - accuracy: 0.9990 - val_loss: 2.7734 - val_accuracy: 0.7494 - 13s/epoch - 99ms/step\n",
      "Epoch 42/100\n",
      "126/126 - 13s - loss: 0.0017 - accuracy: 0.9988 - val_loss: 2.7696 - val_accuracy: 0.7472 - 13s/epoch - 99ms/step\n",
      "Epoch 43/100\n",
      "126/126 - 13s - loss: 0.0015 - accuracy: 0.9988 - val_loss: 2.7302 - val_accuracy: 0.7380 - 13s/epoch - 101ms/step\n",
      "Epoch 44/100\n",
      "126/126 - 13s - loss: 0.0014 - accuracy: 0.9988 - val_loss: 2.8034 - val_accuracy: 0.7380 - 13s/epoch - 100ms/step\n",
      "Epoch 45/100\n",
      "126/126 - 12s - loss: 0.0015 - accuracy: 0.9988 - val_loss: 2.8988 - val_accuracy: 0.7358 - 12s/epoch - 99ms/step\n",
      "Epoch 46/100\n",
      "126/126 - 13s - loss: 0.0013 - accuracy: 0.9993 - val_loss: 3.0059 - val_accuracy: 0.7380 - 13s/epoch - 99ms/step\n",
      "Epoch 47/100\n",
      "126/126 - 13s - loss: 0.0023 - accuracy: 0.9993 - val_loss: 3.1841 - val_accuracy: 0.7380 - 13s/epoch - 101ms/step\n",
      "Epoch 48/100\n",
      "126/126 - 12s - loss: 0.0026 - accuracy: 0.9988 - val_loss: 3.1943 - val_accuracy: 0.7449 - 12s/epoch - 98ms/step\n",
      "Epoch 49/100\n",
      "126/126 - 13s - loss: 0.0015 - accuracy: 0.9990 - val_loss: 3.3124 - val_accuracy: 0.7403 - 13s/epoch - 101ms/step\n",
      "Epoch 50/100\n",
      "126/126 - 13s - loss: 0.0039 - accuracy: 0.9990 - val_loss: 2.9747 - val_accuracy: 0.7380 - 13s/epoch - 104ms/step\n",
      "Epoch 51/100\n",
      "126/126 - 13s - loss: 0.0022 - accuracy: 0.9990 - val_loss: 2.7298 - val_accuracy: 0.7380 - 13s/epoch - 105ms/step\n",
      "Epoch 52/100\n",
      "126/126 - 13s - loss: 0.0024 - accuracy: 0.9990 - val_loss: 2.8870 - val_accuracy: 0.7472 - 13s/epoch - 102ms/step\n",
      "Epoch 53/100\n",
      "126/126 - 13s - loss: 0.0025 - accuracy: 0.9990 - val_loss: 3.0167 - val_accuracy: 0.7540 - 13s/epoch - 105ms/step\n",
      "Epoch 54/100\n",
      "126/126 - 14s - loss: 0.0037 - accuracy: 0.9985 - val_loss: 3.2593 - val_accuracy: 0.7426 - 14s/epoch - 111ms/step\n",
      "Epoch 55/100\n",
      "126/126 - 12s - loss: 0.0017 - accuracy: 0.9990 - val_loss: 3.0459 - val_accuracy: 0.7494 - 12s/epoch - 99ms/step\n",
      "Epoch 56/100\n",
      "126/126 - 13s - loss: 0.0014 - accuracy: 0.9988 - val_loss: 3.4237 - val_accuracy: 0.7540 - 13s/epoch - 99ms/step\n",
      "Epoch 57/100\n",
      "126/126 - 12s - loss: 0.0024 - accuracy: 0.9985 - val_loss: 3.2552 - val_accuracy: 0.7449 - 12s/epoch - 98ms/step\n",
      "Epoch 58/100\n",
      "126/126 - 12s - loss: 0.0837 - accuracy: 0.9712 - val_loss: 1.0610 - val_accuracy: 0.7039 - 12s/epoch - 98ms/step\n",
      "Epoch 59/100\n",
      "126/126 - 12s - loss: 0.2027 - accuracy: 0.9235 - val_loss: 0.8307 - val_accuracy: 0.7175 - 12s/epoch - 98ms/step\n",
      "Epoch 60/100\n",
      "126/126 - 12s - loss: 0.1216 - accuracy: 0.9585 - val_loss: 0.8300 - val_accuracy: 0.7130 - 12s/epoch - 99ms/step\n",
      "Epoch 61/100\n",
      "126/126 - 12s - loss: 0.0585 - accuracy: 0.9794 - val_loss: 1.1149 - val_accuracy: 0.7380 - 12s/epoch - 99ms/step\n",
      "Epoch 62/100\n",
      "126/126 - 13s - loss: 0.0427 - accuracy: 0.9836 - val_loss: 1.4027 - val_accuracy: 0.7312 - 13s/epoch - 100ms/step\n",
      "Epoch 63/100\n",
      "126/126 - 12s - loss: 0.0417 - accuracy: 0.9836 - val_loss: 1.3419 - val_accuracy: 0.7221 - 12s/epoch - 99ms/step\n",
      "Epoch 64/100\n",
      "126/126 - 13s - loss: 0.0426 - accuracy: 0.9841 - val_loss: 1.2303 - val_accuracy: 0.7380 - 13s/epoch - 100ms/step\n",
      "Epoch 65/100\n",
      "126/126 - 13s - loss: 0.0299 - accuracy: 0.9901 - val_loss: 1.4334 - val_accuracy: 0.7380 - 13s/epoch - 100ms/step\n",
      "Epoch 66/100\n",
      "126/126 - 13s - loss: 0.0406 - accuracy: 0.9873 - val_loss: 1.2017 - val_accuracy: 0.7289 - 13s/epoch - 100ms/step\n",
      "Epoch 67/100\n",
      "126/126 - 13s - loss: 0.0251 - accuracy: 0.9911 - val_loss: 1.4173 - val_accuracy: 0.7380 - 13s/epoch - 100ms/step\n",
      "Epoch 68/100\n",
      "126/126 - 13s - loss: 0.0167 - accuracy: 0.9913 - val_loss: 1.6595 - val_accuracy: 0.7608 - 13s/epoch - 100ms/step\n",
      "Epoch 69/100\n",
      "126/126 - 13s - loss: 0.0244 - accuracy: 0.9913 - val_loss: 1.5059 - val_accuracy: 0.7267 - 13s/epoch - 100ms/step\n",
      "Epoch 70/100\n",
      "126/126 - 13s - loss: 0.0155 - accuracy: 0.9940 - val_loss: 1.7267 - val_accuracy: 0.7267 - 13s/epoch - 100ms/step\n",
      "Epoch 71/100\n",
      "126/126 - 13s - loss: 0.0165 - accuracy: 0.9935 - val_loss: 1.5228 - val_accuracy: 0.7472 - 13s/epoch - 100ms/step\n",
      "Epoch 72/100\n",
      "126/126 - 13s - loss: 0.0271 - accuracy: 0.9908 - val_loss: 1.5651 - val_accuracy: 0.7380 - 13s/epoch - 100ms/step\n",
      "Epoch 73/100\n",
      "126/126 - 13s - loss: 0.0125 - accuracy: 0.9958 - val_loss: 1.9749 - val_accuracy: 0.7335 - 13s/epoch - 100ms/step\n",
      "Epoch 74/100\n",
      "126/126 - 13s - loss: 0.0203 - accuracy: 0.9940 - val_loss: 2.0430 - val_accuracy: 0.7153 - 13s/epoch - 106ms/step\n",
      "Epoch 75/100\n",
      "126/126 - 13s - loss: 0.0256 - accuracy: 0.9893 - val_loss: 1.7560 - val_accuracy: 0.7267 - 13s/epoch - 103ms/step\n",
      "Epoch 76/100\n",
      "126/126 - 13s - loss: 0.0175 - accuracy: 0.9933 - val_loss: 2.0836 - val_accuracy: 0.7175 - 13s/epoch - 101ms/step\n",
      "Epoch 77/100\n",
      "126/126 - 13s - loss: 0.0231 - accuracy: 0.9911 - val_loss: 1.7432 - val_accuracy: 0.7312 - 13s/epoch - 100ms/step\n",
      "Epoch 78/100\n",
      "126/126 - 13s - loss: 0.0213 - accuracy: 0.9928 - val_loss: 1.5980 - val_accuracy: 0.7358 - 13s/epoch - 100ms/step\n",
      "Epoch 79/100\n",
      "126/126 - 13s - loss: 0.0191 - accuracy: 0.9930 - val_loss: 1.8414 - val_accuracy: 0.7244 - 13s/epoch - 101ms/step\n",
      "Epoch 80/100\n",
      "126/126 - 13s - loss: 0.0117 - accuracy: 0.9960 - val_loss: 1.9729 - val_accuracy: 0.7130 - 13s/epoch - 101ms/step\n",
      "Epoch 81/100\n",
      "126/126 - 13s - loss: 0.0124 - accuracy: 0.9948 - val_loss: 1.9205 - val_accuracy: 0.7175 - 13s/epoch - 100ms/step\n",
      "Epoch 82/100\n",
      "126/126 - 13s - loss: 0.0064 - accuracy: 0.9983 - val_loss: 2.0668 - val_accuracy: 0.7198 - 13s/epoch - 100ms/step\n",
      "Epoch 83/100\n",
      "126/126 - 13s - loss: 0.0058 - accuracy: 0.9975 - val_loss: 2.2897 - val_accuracy: 0.7084 - 13s/epoch - 100ms/step\n",
      "Epoch 84/100\n",
      "126/126 - 13s - loss: 0.0066 - accuracy: 0.9975 - val_loss: 2.3363 - val_accuracy: 0.7153 - 13s/epoch - 100ms/step\n",
      "Epoch 85/100\n",
      "126/126 - 13s - loss: 0.0120 - accuracy: 0.9958 - val_loss: 2.1858 - val_accuracy: 0.7312 - 13s/epoch - 100ms/step\n",
      "Epoch 86/100\n",
      "126/126 - 13s - loss: 0.0150 - accuracy: 0.9958 - val_loss: 2.0462 - val_accuracy: 0.7289 - 13s/epoch - 100ms/step\n",
      "Epoch 87/100\n",
      "126/126 - 12s - loss: 0.0274 - accuracy: 0.9906 - val_loss: 1.5055 - val_accuracy: 0.7153 - 12s/epoch - 99ms/step\n",
      "Epoch 88/100\n",
      "126/126 - 12s - loss: 0.0202 - accuracy: 0.9923 - val_loss: 2.1743 - val_accuracy: 0.7153 - 12s/epoch - 99ms/step\n",
      "Epoch 89/100\n",
      "126/126 - 13s - loss: 0.0378 - accuracy: 0.9891 - val_loss: 1.3937 - val_accuracy: 0.7039 - 13s/epoch - 100ms/step\n",
      "Epoch 90/100\n",
      "126/126 - 13s - loss: 0.0581 - accuracy: 0.9811 - val_loss: 1.6079 - val_accuracy: 0.6811 - 13s/epoch - 100ms/step\n",
      "Epoch 91/100\n",
      "126/126 - 13s - loss: 0.0618 - accuracy: 0.9781 - val_loss: 1.4522 - val_accuracy: 0.7426 - 13s/epoch - 100ms/step\n",
      "Epoch 92/100\n",
      "126/126 - 13s - loss: 0.0442 - accuracy: 0.9838 - val_loss: 1.4079 - val_accuracy: 0.7312 - 13s/epoch - 100ms/step\n",
      "Epoch 93/100\n",
      "126/126 - 13s - loss: 0.0366 - accuracy: 0.9871 - val_loss: 1.6326 - val_accuracy: 0.7084 - 13s/epoch - 99ms/step\n",
      "Epoch 94/100\n",
      "126/126 - 13s - loss: 0.0285 - accuracy: 0.9908 - val_loss: 1.7904 - val_accuracy: 0.7062 - 13s/epoch - 102ms/step\n",
      "Epoch 95/100\n",
      "126/126 - 14s - loss: 0.0204 - accuracy: 0.9923 - val_loss: 2.1811 - val_accuracy: 0.7312 - 14s/epoch - 107ms/step\n",
      "Epoch 96/100\n",
      "126/126 - 13s - loss: 0.0200 - accuracy: 0.9923 - val_loss: 2.1384 - val_accuracy: 0.7175 - 13s/epoch - 106ms/step\n",
      "Epoch 97/100\n",
      "126/126 - 13s - loss: 0.0236 - accuracy: 0.9916 - val_loss: 1.9791 - val_accuracy: 0.7244 - 13s/epoch - 103ms/step\n",
      "Epoch 98/100\n",
      "126/126 - 13s - loss: 0.0271 - accuracy: 0.9918 - val_loss: 1.9636 - val_accuracy: 0.7039 - 13s/epoch - 104ms/step\n",
      "Epoch 99/100\n",
      "126/126 - 13s - loss: 0.0158 - accuracy: 0.9950 - val_loss: 2.2176 - val_accuracy: 0.7244 - 13s/epoch - 105ms/step\n",
      "Epoch 100/100\n",
      "126/126 - 12s - loss: 0.0150 - accuracy: 0.9948 - val_loss: 2.4025 - val_accuracy: 0.7016 - 12s/epoch - 99ms/step\n"
     ]
    }
   ],
   "source": [
    "history_bilstm_hidden_128 = model_bilstm_hidden_128.fit(\n",
    "        X_train_resampled,\n",
    "        y_train_resampled,\n",
    "        epochs=100,\n",
    "        validation_data=(X_test_padded, y_test),\n",
    "        verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Train Model Bi-LSTM (Parameter Hidden Size = 200)</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 100, 150)          978000    \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 400)              561600    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 400)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                25664     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,565,329\n",
      "Trainable params: 1,565,329\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_bilstm_hidden_200 = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Embedding(embed_matrix_150D.shape[0], embed_matrix_150D.shape[1], input_length=maxlen, weights=[embed_matrix_150D], trainable=True),\n",
    "        tf.keras.layers.Bidirectional(LSTM(200)),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Create Optimizer\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "model_bilstm_hidden_200.compile(\n",
    "        optimizer=opt,\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model_bilstm_hidden_200.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "126/126 - 27s - loss: 0.7066 - accuracy: 0.5082 - val_loss: 0.6927 - val_accuracy: 0.5285 - 27s/epoch - 210ms/step\n",
      "Epoch 2/100\n",
      "126/126 - 20s - loss: 0.6615 - accuracy: 0.5979 - val_loss: 0.6070 - val_accuracy: 0.6651 - 20s/epoch - 159ms/step\n",
      "Epoch 3/100\n",
      "126/126 - 19s - loss: 0.4675 - accuracy: 0.7858 - val_loss: 0.5704 - val_accuracy: 0.6948 - 19s/epoch - 151ms/step\n",
      "Epoch 4/100\n",
      "126/126 - 22s - loss: 0.2588 - accuracy: 0.8882 - val_loss: 0.6355 - val_accuracy: 0.7426 - 22s/epoch - 174ms/step\n",
      "Epoch 5/100\n",
      "126/126 - 21s - loss: 0.1054 - accuracy: 0.9632 - val_loss: 0.5988 - val_accuracy: 0.7631 - 21s/epoch - 163ms/step\n",
      "Epoch 6/100\n",
      "126/126 - 21s - loss: 0.0618 - accuracy: 0.9806 - val_loss: 0.7959 - val_accuracy: 0.8200 - 21s/epoch - 163ms/step\n",
      "Epoch 7/100\n",
      "126/126 - 21s - loss: 0.0328 - accuracy: 0.9898 - val_loss: 1.1389 - val_accuracy: 0.7677 - 21s/epoch - 165ms/step\n",
      "Epoch 8/100\n",
      "126/126 - 21s - loss: 0.0311 - accuracy: 0.9893 - val_loss: 1.0418 - val_accuracy: 0.7358 - 21s/epoch - 165ms/step\n",
      "Epoch 9/100\n",
      "126/126 - 21s - loss: 0.0237 - accuracy: 0.9913 - val_loss: 1.2058 - val_accuracy: 0.7608 - 21s/epoch - 165ms/step\n",
      "Epoch 10/100\n",
      "126/126 - 21s - loss: 0.0152 - accuracy: 0.9948 - val_loss: 1.4132 - val_accuracy: 0.7358 - 21s/epoch - 165ms/step\n",
      "Epoch 11/100\n",
      "126/126 - 21s - loss: 0.0148 - accuracy: 0.9960 - val_loss: 1.3472 - val_accuracy: 0.7517 - 21s/epoch - 164ms/step\n",
      "Epoch 12/100\n",
      "126/126 - 21s - loss: 0.0032 - accuracy: 0.9985 - val_loss: 1.5981 - val_accuracy: 0.7494 - 21s/epoch - 164ms/step\n",
      "Epoch 13/100\n",
      "126/126 - 21s - loss: 0.0023 - accuracy: 0.9988 - val_loss: 1.6036 - val_accuracy: 0.7472 - 21s/epoch - 165ms/step\n",
      "Epoch 14/100\n",
      "126/126 - 21s - loss: 0.0015 - accuracy: 0.9993 - val_loss: 1.7126 - val_accuracy: 0.7472 - 21s/epoch - 165ms/step\n",
      "Epoch 15/100\n",
      "126/126 - 21s - loss: 0.0020 - accuracy: 0.9988 - val_loss: 1.7331 - val_accuracy: 0.7563 - 21s/epoch - 164ms/step\n",
      "Epoch 16/100\n",
      "126/126 - 21s - loss: 0.0023 - accuracy: 0.9990 - val_loss: 1.7757 - val_accuracy: 0.7563 - 21s/epoch - 169ms/step\n",
      "Epoch 17/100\n",
      "126/126 - 21s - loss: 0.0016 - accuracy: 0.9988 - val_loss: 1.8332 - val_accuracy: 0.7563 - 21s/epoch - 167ms/step\n",
      "Epoch 18/100\n",
      "126/126 - 21s - loss: 0.0014 - accuracy: 0.9993 - val_loss: 1.8705 - val_accuracy: 0.7563 - 21s/epoch - 166ms/step\n",
      "Epoch 19/100\n",
      "126/126 - 21s - loss: 0.0015 - accuracy: 0.9993 - val_loss: 1.8990 - val_accuracy: 0.7517 - 21s/epoch - 168ms/step\n",
      "Epoch 20/100\n",
      "126/126 - 21s - loss: 0.0015 - accuracy: 0.9990 - val_loss: 1.9366 - val_accuracy: 0.7540 - 21s/epoch - 165ms/step\n",
      "Epoch 21/100\n",
      "126/126 - 21s - loss: 0.0015 - accuracy: 0.9988 - val_loss: 1.9332 - val_accuracy: 0.7540 - 21s/epoch - 165ms/step\n",
      "Epoch 22/100\n",
      "126/126 - 21s - loss: 0.0022 - accuracy: 0.9990 - val_loss: 1.9819 - val_accuracy: 0.7608 - 21s/epoch - 165ms/step\n",
      "Epoch 23/100\n",
      "126/126 - 21s - loss: 0.0024 - accuracy: 0.9983 - val_loss: 2.0933 - val_accuracy: 0.7517 - 21s/epoch - 167ms/step\n",
      "Epoch 24/100\n",
      "126/126 - 21s - loss: 0.0016 - accuracy: 0.9990 - val_loss: 2.0588 - val_accuracy: 0.7585 - 21s/epoch - 166ms/step\n",
      "Epoch 25/100\n",
      "126/126 - 21s - loss: 0.0022 - accuracy: 0.9988 - val_loss: 2.1217 - val_accuracy: 0.7585 - 21s/epoch - 166ms/step\n",
      "Epoch 26/100\n",
      "126/126 - 21s - loss: 0.0015 - accuracy: 0.9990 - val_loss: 2.1171 - val_accuracy: 0.7608 - 21s/epoch - 167ms/step\n",
      "Epoch 27/100\n",
      "126/126 - 21s - loss: 0.0016 - accuracy: 0.9988 - val_loss: 2.1531 - val_accuracy: 0.7585 - 21s/epoch - 167ms/step\n",
      "Epoch 28/100\n",
      "126/126 - 21s - loss: 0.0017 - accuracy: 0.9988 - val_loss: 2.1104 - val_accuracy: 0.7631 - 21s/epoch - 168ms/step\n",
      "Epoch 29/100\n",
      "126/126 - 21s - loss: 0.0014 - accuracy: 0.9988 - val_loss: 2.1772 - val_accuracy: 0.7631 - 21s/epoch - 168ms/step\n",
      "Epoch 30/100\n",
      "126/126 - 21s - loss: 0.0015 - accuracy: 0.9990 - val_loss: 2.1542 - val_accuracy: 0.7631 - 21s/epoch - 168ms/step\n",
      "Epoch 31/100\n",
      "126/126 - 21s - loss: 0.0014 - accuracy: 0.9988 - val_loss: 2.1860 - val_accuracy: 0.7608 - 21s/epoch - 167ms/step\n",
      "Epoch 32/100\n",
      "126/126 - 21s - loss: 0.0017 - accuracy: 0.9990 - val_loss: 2.1130 - val_accuracy: 0.7699 - 21s/epoch - 168ms/step\n",
      "Epoch 33/100\n",
      "126/126 - 21s - loss: 0.0014 - accuracy: 0.9990 - val_loss: 2.1823 - val_accuracy: 0.7722 - 21s/epoch - 168ms/step\n",
      "Epoch 34/100\n",
      "126/126 - 21s - loss: 0.0016 - accuracy: 0.9988 - val_loss: 2.1762 - val_accuracy: 0.7677 - 21s/epoch - 168ms/step\n",
      "Epoch 35/100\n",
      "126/126 - 21s - loss: 0.0013 - accuracy: 0.9993 - val_loss: 2.2237 - val_accuracy: 0.7699 - 21s/epoch - 168ms/step\n",
      "Epoch 36/100\n",
      "126/126 - 21s - loss: 0.0025 - accuracy: 0.9988 - val_loss: 2.2154 - val_accuracy: 0.7677 - 21s/epoch - 167ms/step\n",
      "Epoch 37/100\n",
      "126/126 - 21s - loss: 0.0042 - accuracy: 0.9985 - val_loss: 2.3874 - val_accuracy: 0.7631 - 21s/epoch - 168ms/step\n",
      "Epoch 38/100\n",
      "126/126 - 21s - loss: 0.0016 - accuracy: 0.9990 - val_loss: 2.2484 - val_accuracy: 0.7699 - 21s/epoch - 167ms/step\n",
      "Epoch 39/100\n",
      "126/126 - 21s - loss: 0.0020 - accuracy: 0.9988 - val_loss: 2.2404 - val_accuracy: 0.7631 - 21s/epoch - 169ms/step\n",
      "Epoch 40/100\n",
      "126/126 - 21s - loss: 0.0038 - accuracy: 0.9988 - val_loss: 2.2998 - val_accuracy: 0.7563 - 21s/epoch - 167ms/step\n",
      "Epoch 41/100\n",
      "126/126 - 21s - loss: 0.0037 - accuracy: 0.9985 - val_loss: 2.3231 - val_accuracy: 0.7585 - 21s/epoch - 167ms/step\n",
      "Epoch 42/100\n",
      "126/126 - 21s - loss: 0.0024 - accuracy: 0.9988 - val_loss: 2.7284 - val_accuracy: 0.7585 - 21s/epoch - 168ms/step\n",
      "Epoch 43/100\n",
      "126/126 - 21s - loss: 0.0030 - accuracy: 0.9993 - val_loss: 3.4430 - val_accuracy: 0.7540 - 21s/epoch - 168ms/step\n",
      "Epoch 44/100\n",
      "126/126 - 21s - loss: 0.0888 - accuracy: 0.9744 - val_loss: 1.0591 - val_accuracy: 0.7494 - 21s/epoch - 167ms/step\n",
      "Epoch 45/100\n",
      "126/126 - 21s - loss: 0.1063 - accuracy: 0.9605 - val_loss: 0.6919 - val_accuracy: 0.7472 - 21s/epoch - 169ms/step\n",
      "Epoch 46/100\n",
      "126/126 - 22s - loss: 0.0996 - accuracy: 0.9689 - val_loss: 1.0212 - val_accuracy: 0.7175 - 22s/epoch - 172ms/step\n",
      "Epoch 47/100\n",
      "126/126 - 21s - loss: 0.0843 - accuracy: 0.9719 - val_loss: 1.1442 - val_accuracy: 0.7244 - 21s/epoch - 169ms/step\n",
      "Epoch 48/100\n",
      "126/126 - 21s - loss: 0.0602 - accuracy: 0.9781 - val_loss: 1.1168 - val_accuracy: 0.7449 - 21s/epoch - 168ms/step\n",
      "Epoch 49/100\n",
      "126/126 - 21s - loss: 0.0676 - accuracy: 0.9764 - val_loss: 1.1196 - val_accuracy: 0.7153 - 21s/epoch - 167ms/step\n",
      "Epoch 50/100\n",
      "126/126 - 21s - loss: 0.0511 - accuracy: 0.9816 - val_loss: 1.5729 - val_accuracy: 0.7062 - 21s/epoch - 167ms/step\n",
      "Epoch 51/100\n",
      "126/126 - 21s - loss: 0.0619 - accuracy: 0.9766 - val_loss: 1.4989 - val_accuracy: 0.6834 - 21s/epoch - 167ms/step\n",
      "Epoch 52/100\n",
      "126/126 - 21s - loss: 0.0380 - accuracy: 0.9873 - val_loss: 1.5804 - val_accuracy: 0.7175 - 21s/epoch - 167ms/step\n",
      "Epoch 53/100\n",
      "126/126 - 21s - loss: 0.0273 - accuracy: 0.9911 - val_loss: 1.5698 - val_accuracy: 0.6970 - 21s/epoch - 167ms/step\n",
      "Epoch 54/100\n",
      "126/126 - 21s - loss: 0.0360 - accuracy: 0.9863 - val_loss: 1.6208 - val_accuracy: 0.6970 - 21s/epoch - 167ms/step\n",
      "Epoch 55/100\n",
      "126/126 - 21s - loss: 0.0238 - accuracy: 0.9911 - val_loss: 2.0955 - val_accuracy: 0.7107 - 21s/epoch - 166ms/step\n",
      "Epoch 56/100\n",
      "126/126 - 21s - loss: 0.0103 - accuracy: 0.9968 - val_loss: 2.1990 - val_accuracy: 0.6902 - 21s/epoch - 165ms/step\n",
      "Epoch 57/100\n",
      "126/126 - 21s - loss: 0.0093 - accuracy: 0.9958 - val_loss: 2.3379 - val_accuracy: 0.7062 - 21s/epoch - 167ms/step\n",
      "Epoch 58/100\n",
      "126/126 - 21s - loss: 0.0142 - accuracy: 0.9945 - val_loss: 2.5378 - val_accuracy: 0.7039 - 21s/epoch - 168ms/step\n",
      "Epoch 59/100\n",
      "126/126 - 21s - loss: 0.0270 - accuracy: 0.9923 - val_loss: 1.9531 - val_accuracy: 0.7107 - 21s/epoch - 166ms/step\n",
      "Epoch 60/100\n",
      "126/126 - 21s - loss: 0.0117 - accuracy: 0.9965 - val_loss: 2.0313 - val_accuracy: 0.7198 - 21s/epoch - 167ms/step\n",
      "Epoch 61/100\n",
      "126/126 - 21s - loss: 0.0081 - accuracy: 0.9975 - val_loss: 2.0603 - val_accuracy: 0.7267 - 21s/epoch - 168ms/step\n",
      "Epoch 62/100\n",
      "126/126 - 21s - loss: 0.0061 - accuracy: 0.9975 - val_loss: 2.1297 - val_accuracy: 0.7289 - 21s/epoch - 167ms/step\n",
      "Epoch 63/100\n",
      "126/126 - 21s - loss: 0.0035 - accuracy: 0.9985 - val_loss: 2.2574 - val_accuracy: 0.7153 - 21s/epoch - 167ms/step\n",
      "Epoch 64/100\n",
      "126/126 - 21s - loss: 0.0047 - accuracy: 0.9980 - val_loss: 2.1288 - val_accuracy: 0.7267 - 21s/epoch - 167ms/step\n",
      "Epoch 65/100\n",
      "126/126 - 22s - loss: 0.0029 - accuracy: 0.9985 - val_loss: 2.2269 - val_accuracy: 0.7198 - 22s/epoch - 173ms/step\n",
      "Epoch 66/100\n",
      "126/126 - 21s - loss: 0.0026 - accuracy: 0.9993 - val_loss: 2.4863 - val_accuracy: 0.7153 - 21s/epoch - 170ms/step\n",
      "Epoch 67/100\n",
      "126/126 - 21s - loss: 0.0039 - accuracy: 0.9990 - val_loss: 2.1858 - val_accuracy: 0.7198 - 21s/epoch - 167ms/step\n",
      "Epoch 68/100\n",
      "126/126 - 21s - loss: 0.0025 - accuracy: 0.9988 - val_loss: 2.3619 - val_accuracy: 0.7244 - 21s/epoch - 167ms/step\n",
      "Epoch 69/100\n",
      "126/126 - 21s - loss: 0.0030 - accuracy: 0.9988 - val_loss: 2.2033 - val_accuracy: 0.7175 - 21s/epoch - 167ms/step\n",
      "Epoch 70/100\n",
      "126/126 - 21s - loss: 0.0031 - accuracy: 0.9985 - val_loss: 2.0962 - val_accuracy: 0.7039 - 21s/epoch - 166ms/step\n",
      "Epoch 71/100\n",
      "126/126 - 21s - loss: 0.0023 - accuracy: 0.9985 - val_loss: 2.3908 - val_accuracy: 0.7130 - 21s/epoch - 166ms/step\n",
      "Epoch 72/100\n",
      "126/126 - 21s - loss: 0.0014 - accuracy: 0.9993 - val_loss: 2.4429 - val_accuracy: 0.7039 - 21s/epoch - 166ms/step\n",
      "Epoch 73/100\n",
      "126/126 - 21s - loss: 0.0027 - accuracy: 0.9988 - val_loss: 2.3869 - val_accuracy: 0.7175 - 21s/epoch - 166ms/step\n",
      "Epoch 74/100\n",
      "126/126 - 21s - loss: 0.0031 - accuracy: 0.9985 - val_loss: 2.3783 - val_accuracy: 0.7198 - 21s/epoch - 166ms/step\n",
      "Epoch 75/100\n",
      "126/126 - 21s - loss: 0.0021 - accuracy: 0.9988 - val_loss: 2.3989 - val_accuracy: 0.7244 - 21s/epoch - 166ms/step\n",
      "Epoch 76/100\n",
      "126/126 - 21s - loss: 0.0022 - accuracy: 0.9988 - val_loss: 2.4476 - val_accuracy: 0.7153 - 21s/epoch - 168ms/step\n",
      "Epoch 77/100\n",
      "126/126 - 21s - loss: 0.0019 - accuracy: 0.9993 - val_loss: 2.4504 - val_accuracy: 0.7289 - 21s/epoch - 170ms/step\n",
      "Epoch 78/100\n",
      "126/126 - 21s - loss: 0.0021 - accuracy: 0.9983 - val_loss: 2.5565 - val_accuracy: 0.7358 - 21s/epoch - 167ms/step\n",
      "Epoch 79/100\n",
      "126/126 - 21s - loss: 0.0151 - accuracy: 0.9948 - val_loss: 1.9038 - val_accuracy: 0.7312 - 21s/epoch - 168ms/step\n",
      "Epoch 80/100\n",
      "126/126 - 21s - loss: 0.0385 - accuracy: 0.9866 - val_loss: 1.8812 - val_accuracy: 0.6720 - 21s/epoch - 166ms/step\n",
      "Epoch 81/100\n",
      "126/126 - 21s - loss: 0.0797 - accuracy: 0.9722 - val_loss: 1.7777 - val_accuracy: 0.6560 - 21s/epoch - 167ms/step\n",
      "Epoch 82/100\n",
      "126/126 - 21s - loss: 0.1042 - accuracy: 0.9607 - val_loss: 1.3819 - val_accuracy: 0.6902 - 21s/epoch - 167ms/step\n",
      "Epoch 83/100\n",
      "126/126 - 21s - loss: 0.0856 - accuracy: 0.9667 - val_loss: 1.5744 - val_accuracy: 0.6948 - 21s/epoch - 168ms/step\n",
      "Epoch 84/100\n",
      "126/126 - 21s - loss: 0.0671 - accuracy: 0.9749 - val_loss: 1.3864 - val_accuracy: 0.6765 - 21s/epoch - 168ms/step\n",
      "Epoch 85/100\n",
      "126/126 - 21s - loss: 0.0562 - accuracy: 0.9784 - val_loss: 2.0515 - val_accuracy: 0.6424 - 21s/epoch - 169ms/step\n",
      "Epoch 86/100\n",
      "126/126 - 21s - loss: 0.0934 - accuracy: 0.9652 - val_loss: 1.4293 - val_accuracy: 0.6583 - 21s/epoch - 170ms/step\n",
      "Epoch 87/100\n",
      "126/126 - 21s - loss: 0.1066 - accuracy: 0.9595 - val_loss: 1.6962 - val_accuracy: 0.6538 - 21s/epoch - 169ms/step\n",
      "Epoch 88/100\n",
      "126/126 - 21s - loss: 0.0813 - accuracy: 0.9672 - val_loss: 1.7074 - val_accuracy: 0.6401 - 21s/epoch - 168ms/step\n",
      "Epoch 89/100\n",
      "126/126 - 21s - loss: 0.1578 - accuracy: 0.9376 - val_loss: 1.4440 - val_accuracy: 0.6469 - 21s/epoch - 167ms/step\n",
      "Epoch 90/100\n",
      "126/126 - 21s - loss: 0.1222 - accuracy: 0.9570 - val_loss: 1.1865 - val_accuracy: 0.6583 - 21s/epoch - 167ms/step\n",
      "Epoch 91/100\n",
      "126/126 - 22s - loss: 0.0857 - accuracy: 0.9674 - val_loss: 1.4747 - val_accuracy: 0.6811 - 22s/epoch - 172ms/step\n",
      "Epoch 92/100\n",
      "126/126 - 22s - loss: 0.0978 - accuracy: 0.9632 - val_loss: 1.2756 - val_accuracy: 0.6765 - 22s/epoch - 172ms/step\n",
      "Epoch 93/100\n",
      "126/126 - 23s - loss: 0.0818 - accuracy: 0.9697 - val_loss: 1.4018 - val_accuracy: 0.6697 - 23s/epoch - 183ms/step\n",
      "Epoch 94/100\n",
      "126/126 - 23s - loss: 0.0679 - accuracy: 0.9732 - val_loss: 1.8226 - val_accuracy: 0.6606 - 23s/epoch - 182ms/step\n",
      "Epoch 95/100\n",
      "126/126 - 23s - loss: 0.0689 - accuracy: 0.9759 - val_loss: 1.4330 - val_accuracy: 0.6697 - 23s/epoch - 179ms/step\n",
      "Epoch 96/100\n",
      "126/126 - 21s - loss: 0.0981 - accuracy: 0.9647 - val_loss: 1.1701 - val_accuracy: 0.6948 - 21s/epoch - 165ms/step\n",
      "Epoch 97/100\n",
      "126/126 - 21s - loss: 0.0827 - accuracy: 0.9699 - val_loss: 1.6777 - val_accuracy: 0.6560 - 21s/epoch - 164ms/step\n",
      "Epoch 98/100\n",
      "126/126 - 21s - loss: 0.0776 - accuracy: 0.9704 - val_loss: 1.4068 - val_accuracy: 0.6993 - 21s/epoch - 167ms/step\n",
      "Epoch 99/100\n",
      "126/126 - 22s - loss: 0.0599 - accuracy: 0.9794 - val_loss: 1.7951 - val_accuracy: 0.6948 - 22s/epoch - 176ms/step\n",
      "Epoch 100/100\n",
      "126/126 - 22s - loss: 0.0574 - accuracy: 0.9791 - val_loss: 1.7185 - val_accuracy: 0.6970 - 22s/epoch - 174ms/step\n"
     ]
    }
   ],
   "source": [
    "history_bilstm_hidden_128 = model_bilstm_hidden_200.fit(\n",
    "        X_train_resampled,\n",
    "        y_train_resampled,\n",
    "        epochs=100,\n",
    "        validation_data=(X_test_padded, y_test),\n",
    "        verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Create LSTM Architecture</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Train Model LSTM (Parameter embedding_size = 50)</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_5 (Embedding)     (None, 100, 50)           326000    \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 100)               60400     \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 64)                6464      \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 392,929\n",
      "Trainable params: 66,929\n",
      "Non-trainable params: 326,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_lstm_embedsize_50 = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Embedding(embed_matrix_50D.shape[0], embed_matrix_50D.shape[1], input_length=maxlen, weights=[embed_matrix_50D], trainable=False),\n",
    "        tf.keras.layers.LSTM(100),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Create Optimizer\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model_lstm_embedsize_50.compile(\n",
    "        optimizer='adam',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model_lstm_embedsize_50.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "126/126 - 6s - loss: 0.6936 - accuracy: 0.5037 - val_loss: 0.6929 - val_accuracy: 0.5285 - 6s/epoch - 48ms/step\n",
      "Epoch 2/10\n",
      "126/126 - 4s - loss: 0.6934 - accuracy: 0.4928 - val_loss: 0.6934 - val_accuracy: 0.4715 - 4s/epoch - 31ms/step\n",
      "Epoch 3/10\n",
      "126/126 - 4s - loss: 0.6934 - accuracy: 0.5032 - val_loss: 0.6939 - val_accuracy: 0.4715 - 4s/epoch - 32ms/step\n",
      "Epoch 4/10\n",
      "126/126 - 4s - loss: 0.6935 - accuracy: 0.4943 - val_loss: 0.6916 - val_accuracy: 0.5285 - 4s/epoch - 31ms/step\n",
      "Epoch 5/10\n",
      "126/126 - 4s - loss: 0.6935 - accuracy: 0.4955 - val_loss: 0.6930 - val_accuracy: 0.5285 - 4s/epoch - 31ms/step\n",
      "Epoch 6/10\n",
      "126/126 - 4s - loss: 0.6933 - accuracy: 0.4856 - val_loss: 0.6929 - val_accuracy: 0.5285 - 4s/epoch - 31ms/step\n",
      "Epoch 7/10\n",
      "126/126 - 4s - loss: 0.6932 - accuracy: 0.4985 - val_loss: 0.6933 - val_accuracy: 0.4715 - 4s/epoch - 32ms/step\n",
      "Epoch 8/10\n",
      "126/126 - 4s - loss: 0.6933 - accuracy: 0.4943 - val_loss: 0.6935 - val_accuracy: 0.4715 - 4s/epoch - 31ms/step\n",
      "Epoch 9/10\n",
      "126/126 - 4s - loss: 0.6933 - accuracy: 0.4943 - val_loss: 0.6935 - val_accuracy: 0.4715 - 4s/epoch - 30ms/step\n",
      "Epoch 10/10\n",
      "126/126 - 4s - loss: 0.6934 - accuracy: 0.4930 - val_loss: 0.6932 - val_accuracy: 0.4715 - 4s/epoch - 31ms/step\n"
     ]
    }
   ],
   "source": [
    "history_lstm_embedsize_50 = model_lstm_embedsize_50.fit(\n",
    "        X_train_resampled,\n",
    "        y_train_resampled,\n",
    "        epochs=10,\n",
    "        validation_data=(X_test_padded, y_test),\n",
    "        verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Train Model LSTM (Parameter embedding_size = 100)</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_6 (Embedding)     (None, 100, 100)          652000    \n",
      "                                                                 \n",
      " lstm_6 (LSTM)               (None, 100)               80400     \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 64)                6464      \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 738,929\n",
      "Trainable params: 86,929\n",
      "Non-trainable params: 652,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_lstm_embedsize_100 = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Embedding(embed_matrix_100D.shape[0], embed_matrix_100D.shape[1], input_length=maxlen, weights=[embed_matrix_100D], trainable=False),\n",
    "        tf.keras.layers.LSTM(100),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Create Optimizer\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model_lstm_embedsize_100.compile(\n",
    "        optimizer='adam',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model_lstm_embedsize_100.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 - 6s - loss: 0.6936 - accuracy: 0.5010 - val_loss: 0.6932 - val_accuracy: 0.4715 - 6s/epoch - 50ms/step\n",
      "Epoch 2/10\n",
      "126/126 - 4s - loss: 0.6934 - accuracy: 0.4995 - val_loss: 0.6936 - val_accuracy: 0.4715 - 4s/epoch - 32ms/step\n",
      "Epoch 3/10\n",
      "126/126 - 4s - loss: 0.6932 - accuracy: 0.5055 - val_loss: 0.6930 - val_accuracy: 0.5285 - 4s/epoch - 32ms/step\n",
      "Epoch 4/10\n",
      "126/126 - 4s - loss: 0.6933 - accuracy: 0.4990 - val_loss: 0.6934 - val_accuracy: 0.4715 - 4s/epoch - 32ms/step\n",
      "Epoch 5/10\n",
      "126/126 - 4s - loss: 0.6933 - accuracy: 0.4948 - val_loss: 0.6929 - val_accuracy: 0.5285 - 4s/epoch - 32ms/step\n",
      "Epoch 6/10\n",
      "126/126 - 4s - loss: 0.6933 - accuracy: 0.4893 - val_loss: 0.6935 - val_accuracy: 0.4715 - 4s/epoch - 32ms/step\n",
      "Epoch 7/10\n",
      "126/126 - 4s - loss: 0.6932 - accuracy: 0.4978 - val_loss: 0.6931 - val_accuracy: 0.5285 - 4s/epoch - 32ms/step\n",
      "Epoch 8/10\n",
      "126/126 - 4s - loss: 0.6932 - accuracy: 0.4943 - val_loss: 0.6932 - val_accuracy: 0.4715 - 4s/epoch - 32ms/step\n",
      "Epoch 9/10\n",
      "126/126 - 4s - loss: 0.6932 - accuracy: 0.4990 - val_loss: 0.6931 - val_accuracy: 0.5285 - 4s/epoch - 32ms/step\n",
      "Epoch 10/10\n",
      "126/126 - 4s - loss: 0.6932 - accuracy: 0.4856 - val_loss: 0.6932 - val_accuracy: 0.4715 - 4s/epoch - 32ms/step\n"
     ]
    }
   ],
   "source": [
    "history_lstm_embedsize_100 = model_lstm_embedsize_100.fit(\n",
    "        X_train_resampled,\n",
    "        y_train_resampled,\n",
    "        epochs=10,\n",
    "        validation_data=(X_test_padded, y_test),\n",
    "        verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Train Model LSTM (Parameter embedding_size = 150)</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_7 (Embedding)     (None, 100, 150)          978000    \n",
      "                                                                 \n",
      " lstm_7 (LSTM)               (None, 100)               100400    \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 64)                6464      \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,084,929\n",
      "Trainable params: 106,929\n",
      "Non-trainable params: 978,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_lstm_embedsize_150 = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Embedding(embed_matrix_150D.shape[0], embed_matrix_150D.shape[1], input_length=maxlen, weights=[embed_matrix_150D], trainable=False),\n",
    "        tf.keras.layers.LSTM(100),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Create Optimizer\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model_lstm_embedsize_150.compile(\n",
    "        optimizer='adam',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model_lstm_embedsize_150.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "126/126 - 7s - loss: 0.6935 - accuracy: 0.4958 - val_loss: 0.6932 - val_accuracy: 0.4715 - 7s/epoch - 57ms/step\n",
      "Epoch 2/10\n",
      "126/126 - 5s - loss: 0.6933 - accuracy: 0.4893 - val_loss: 0.6940 - val_accuracy: 0.4715 - 5s/epoch - 38ms/step\n",
      "Epoch 3/10\n",
      "126/126 - 5s - loss: 0.6936 - accuracy: 0.4928 - val_loss: 0.6931 - val_accuracy: 0.5285 - 5s/epoch - 38ms/step\n",
      "Epoch 4/10\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.4898 - val_loss: 0.6932 - val_accuracy: 0.4715 - 5s/epoch - 38ms/step\n",
      "Epoch 5/10\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.4804 - val_loss: 0.6933 - val_accuracy: 0.4715 - 5s/epoch - 38ms/step\n",
      "Epoch 6/10\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.4918 - val_loss: 0.6932 - val_accuracy: 0.4715 - 5s/epoch - 39ms/step\n",
      "Epoch 7/10\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.4876 - val_loss: 0.6931 - val_accuracy: 0.5285 - 5s/epoch - 40ms/step\n",
      "Epoch 8/10\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.4881 - val_loss: 0.6931 - val_accuracy: 0.5285 - 5s/epoch - 39ms/step\n",
      "Epoch 9/10\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.4983 - val_loss: 0.6931 - val_accuracy: 0.5285 - 5s/epoch - 39ms/step\n",
      "Epoch 10/10\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.4796 - val_loss: 0.6931 - val_accuracy: 0.5285 - 5s/epoch - 39ms/step\n"
     ]
    }
   ],
   "source": [
    "history_lstm_embedsize_150 = model_lstm_embedsize_150.fit(\n",
    "        X_train_resampled,\n",
    "        y_train_resampled,\n",
    "        epochs=10,\n",
    "        validation_data=(X_test_padded, y_test),\n",
    "        verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Train Model LSTM (Parameter epochs = 10)</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_12 (Embedding)    (None, 100, 100)          652000    \n",
      "                                                                 \n",
      " lstm_12 (LSTM)              (None, 100)               80400     \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 100)               0         \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 64)                6464      \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 738,929\n",
      "Trainable params: 86,929\n",
      "Non-trainable params: 652,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_lstm_epochs_10 = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Embedding(embed_matrix_100D.shape[0], embed_matrix_100D.shape[1], input_length=maxlen, weights=[embed_matrix_100D], trainable=False),\n",
    "        tf.keras.layers.LSTM(100),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Create Optimizer\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model_lstm_epochs_10.compile(\n",
    "        optimizer=opt,\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model_lstm_epochs_10.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "126/126 - 7s - loss: 0.6935 - accuracy: 0.4853 - val_loss: 0.6933 - val_accuracy: 0.4715 - 7s/epoch - 54ms/step\n",
      "Epoch 2/10\n",
      "126/126 - 5s - loss: 0.6944 - accuracy: 0.5129 - val_loss: 0.6926 - val_accuracy: 0.5285 - 5s/epoch - 37ms/step\n",
      "Epoch 3/10\n",
      "126/126 - 5s - loss: 0.6935 - accuracy: 0.4918 - val_loss: 0.6932 - val_accuracy: 0.4715 - 5s/epoch - 36ms/step\n",
      "Epoch 4/10\n",
      "126/126 - 5s - loss: 0.6933 - accuracy: 0.4990 - val_loss: 0.6940 - val_accuracy: 0.4715 - 5s/epoch - 37ms/step\n",
      "Epoch 5/10\n",
      "126/126 - 5s - loss: 0.6933 - accuracy: 0.4983 - val_loss: 0.6934 - val_accuracy: 0.4715 - 5s/epoch - 36ms/step\n",
      "Epoch 6/10\n",
      "126/126 - 5s - loss: 0.6934 - accuracy: 0.5017 - val_loss: 0.6935 - val_accuracy: 0.4715 - 5s/epoch - 37ms/step\n",
      "Epoch 7/10\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.4973 - val_loss: 0.6923 - val_accuracy: 0.5285 - 5s/epoch - 37ms/step\n",
      "Epoch 8/10\n",
      "126/126 - 5s - loss: 0.6935 - accuracy: 0.4958 - val_loss: 0.6933 - val_accuracy: 0.4715 - 5s/epoch - 37ms/step\n",
      "Epoch 9/10\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.4906 - val_loss: 0.6932 - val_accuracy: 0.4715 - 5s/epoch - 36ms/step\n",
      "Epoch 10/10\n",
      "126/126 - 5s - loss: 0.6933 - accuracy: 0.4848 - val_loss: 0.6932 - val_accuracy: 0.4715 - 5s/epoch - 36ms/step\n"
     ]
    }
   ],
   "source": [
    "history_lstm_epochs_10 = model_lstm_epochs_10.fit(\n",
    "        X_train_resampled,\n",
    "        y_train_resampled,\n",
    "        epochs=10,\n",
    "        validation_data=(X_test_padded, y_test),\n",
    "        verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Train Model LSTM (Parameter epochs = 50)</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_13 (Embedding)    (None, 100, 100)          652000    \n",
      "                                                                 \n",
      " lstm_13 (LSTM)              (None, 100)               80400     \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 100)               0         \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 64)                6464      \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 738,929\n",
      "Trainable params: 86,929\n",
      "Non-trainable params: 652,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_lstm_epochs_50 = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Embedding(embed_matrix_100D.shape[0], embed_matrix_100D.shape[1], input_length=maxlen, weights=[embed_matrix_100D], trainable=False),\n",
    "        tf.keras.layers.LSTM(100),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Create Optimizer\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model_lstm_epochs_50.compile(\n",
    "        optimizer=opt,\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model_lstm_epochs_50.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "126/126 - 7s - loss: 0.6936 - accuracy: 0.4896 - val_loss: 0.6922 - val_accuracy: 0.5285 - 7s/epoch - 53ms/step\n",
      "Epoch 2/50\n",
      "126/126 - 4s - loss: 0.6932 - accuracy: 0.5025 - val_loss: 0.6961 - val_accuracy: 0.4715 - 4s/epoch - 36ms/step\n",
      "Epoch 3/50\n",
      "126/126 - 5s - loss: 0.6935 - accuracy: 0.4960 - val_loss: 0.6937 - val_accuracy: 0.4715 - 5s/epoch - 36ms/step\n",
      "Epoch 4/50\n",
      "126/126 - 5s - loss: 0.6933 - accuracy: 0.4975 - val_loss: 0.6937 - val_accuracy: 0.4715 - 5s/epoch - 37ms/step\n",
      "Epoch 5/50\n",
      "126/126 - 5s - loss: 0.6933 - accuracy: 0.4933 - val_loss: 0.6931 - val_accuracy: 0.5285 - 5s/epoch - 37ms/step\n",
      "Epoch 6/50\n",
      "126/126 - 5s - loss: 0.6934 - accuracy: 0.4911 - val_loss: 0.6937 - val_accuracy: 0.4715 - 5s/epoch - 36ms/step\n",
      "Epoch 7/50\n",
      "126/126 - 4s - loss: 0.6934 - accuracy: 0.4938 - val_loss: 0.6929 - val_accuracy: 0.5285 - 4s/epoch - 36ms/step\n",
      "Epoch 8/50\n",
      "126/126 - 5s - loss: 0.6935 - accuracy: 0.4945 - val_loss: 0.6937 - val_accuracy: 0.4715 - 5s/epoch - 36ms/step\n",
      "Epoch 9/50\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.4963 - val_loss: 0.6934 - val_accuracy: 0.4715 - 5s/epoch - 36ms/step\n",
      "Epoch 10/50\n",
      "126/126 - 5s - loss: 0.6933 - accuracy: 0.4878 - val_loss: 0.6931 - val_accuracy: 0.5285 - 5s/epoch - 36ms/step\n",
      "Epoch 11/50\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.4945 - val_loss: 0.6930 - val_accuracy: 0.5285 - 5s/epoch - 36ms/step\n",
      "Epoch 12/50\n",
      "126/126 - 5s - loss: 0.6933 - accuracy: 0.4888 - val_loss: 0.6931 - val_accuracy: 0.5285 - 5s/epoch - 36ms/step\n",
      "Epoch 13/50\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.4903 - val_loss: 0.6929 - val_accuracy: 0.5285 - 5s/epoch - 36ms/step\n",
      "Epoch 14/50\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.4950 - val_loss: 0.6931 - val_accuracy: 0.5285 - 5s/epoch - 36ms/step\n",
      "Epoch 15/50\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.4925 - val_loss: 0.6931 - val_accuracy: 0.5285 - 5s/epoch - 36ms/step\n",
      "Epoch 16/50\n",
      "126/126 - 5s - loss: 0.6933 - accuracy: 0.4930 - val_loss: 0.6932 - val_accuracy: 0.4715 - 5s/epoch - 36ms/step\n",
      "Epoch 17/50\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.4953 - val_loss: 0.6932 - val_accuracy: 0.4715 - 5s/epoch - 36ms/step\n",
      "Epoch 18/50\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.4943 - val_loss: 0.6931 - val_accuracy: 0.5285 - 5s/epoch - 36ms/step\n",
      "Epoch 19/50\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.4950 - val_loss: 0.6930 - val_accuracy: 0.5285 - 5s/epoch - 36ms/step\n",
      "Epoch 20/50\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.4973 - val_loss: 0.6932 - val_accuracy: 0.4715 - 5s/epoch - 37ms/step\n",
      "Epoch 21/50\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.4868 - val_loss: 0.6931 - val_accuracy: 0.5285 - 5s/epoch - 37ms/step\n",
      "Epoch 22/50\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.4995 - val_loss: 0.6931 - val_accuracy: 0.5285 - 5s/epoch - 36ms/step\n",
      "Epoch 23/50\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.4873 - val_loss: 0.6932 - val_accuracy: 0.4715 - 5s/epoch - 36ms/step\n",
      "Epoch 24/50\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.4935 - val_loss: 0.6932 - val_accuracy: 0.4715 - 5s/epoch - 36ms/step\n",
      "Epoch 25/50\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.4791 - val_loss: 0.6932 - val_accuracy: 0.4715 - 5s/epoch - 36ms/step\n",
      "Epoch 26/50\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.4913 - val_loss: 0.6932 - val_accuracy: 0.4715 - 5s/epoch - 37ms/step\n",
      "Epoch 27/50\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.4950 - val_loss: 0.6931 - val_accuracy: 0.5285 - 5s/epoch - 36ms/step\n",
      "Epoch 28/50\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.4836 - val_loss: 0.6932 - val_accuracy: 0.4715 - 5s/epoch - 36ms/step\n",
      "Epoch 29/50\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.4953 - val_loss: 0.6932 - val_accuracy: 0.4715 - 5s/epoch - 36ms/step\n",
      "Epoch 30/50\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.4843 - val_loss: 0.6931 - val_accuracy: 0.5285 - 5s/epoch - 36ms/step\n",
      "Epoch 31/50\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.4973 - val_loss: 0.6932 - val_accuracy: 0.4715 - 5s/epoch - 36ms/step\n",
      "Epoch 32/50\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.4901 - val_loss: 0.6931 - val_accuracy: 0.5285 - 5s/epoch - 36ms/step\n",
      "Epoch 33/50\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.4945 - val_loss: 0.6931 - val_accuracy: 0.5285 - 5s/epoch - 37ms/step\n",
      "Epoch 34/50\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.4968 - val_loss: 0.6931 - val_accuracy: 0.5285 - 5s/epoch - 37ms/step\n",
      "Epoch 35/50\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5285 - 5s/epoch - 36ms/step\n",
      "Epoch 36/50\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.4988 - val_loss: 0.6932 - val_accuracy: 0.4715 - 5s/epoch - 36ms/step\n",
      "Epoch 37/50\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.4970 - val_loss: 0.6931 - val_accuracy: 0.5285 - 5s/epoch - 37ms/step\n",
      "Epoch 38/50\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5285 - 5s/epoch - 37ms/step\n",
      "Epoch 39/50\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.4916 - val_loss: 0.6932 - val_accuracy: 0.4715 - 5s/epoch - 37ms/step\n",
      "Epoch 40/50\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.4955 - val_loss: 0.6931 - val_accuracy: 0.4715 - 5s/epoch - 36ms/step\n",
      "Epoch 41/50\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.4891 - val_loss: 0.6932 - val_accuracy: 0.4715 - 5s/epoch - 37ms/step\n",
      "Epoch 42/50\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.4920 - val_loss: 0.6933 - val_accuracy: 0.4715 - 5s/epoch - 36ms/step\n",
      "Epoch 43/50\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.4851 - val_loss: 0.6932 - val_accuracy: 0.4715 - 5s/epoch - 37ms/step\n",
      "Epoch 44/50\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6933 - val_accuracy: 0.4715 - 5s/epoch - 36ms/step\n",
      "Epoch 45/50\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.4960 - val_loss: 0.6931 - val_accuracy: 0.5285 - 5s/epoch - 36ms/step\n",
      "Epoch 46/50\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5285 - 5s/epoch - 36ms/step\n",
      "Epoch 47/50\n",
      "126/126 - 5s - loss: 0.6935 - accuracy: 0.4881 - val_loss: 0.6928 - val_accuracy: 0.5285 - 5s/epoch - 36ms/step\n",
      "Epoch 48/50\n",
      "126/126 - 5s - loss: 0.6934 - accuracy: 0.4948 - val_loss: 0.6931 - val_accuracy: 0.5285 - 5s/epoch - 37ms/step\n",
      "Epoch 49/50\n",
      "126/126 - 5s - loss: 0.6933 - accuracy: 0.5000 - val_loss: 0.6927 - val_accuracy: 0.5285 - 5s/epoch - 37ms/step\n",
      "Epoch 50/50\n",
      "126/126 - 5s - loss: 0.6935 - accuracy: 0.4948 - val_loss: 0.6933 - val_accuracy: 0.4715 - 5s/epoch - 37ms/step\n"
     ]
    }
   ],
   "source": [
    "history_lstm_epochs_50 = model_lstm_epochs_50.fit(\n",
    "        X_train_resampled,\n",
    "        y_train_resampled,\n",
    "        epochs=50,\n",
    "        validation_data=(X_test_padded, y_test),\n",
    "        verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Train Model LSTM (Parameter epochs = 100)</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_14 (Embedding)    (None, 100, 100)          652000    \n",
      "                                                                 \n",
      " lstm_14 (LSTM)              (None, 100)               80400     \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 100)               0         \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 64)                6464      \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 738,929\n",
      "Trainable params: 86,929\n",
      "Non-trainable params: 652,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_lstm_epochs_100 = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Embedding(embed_matrix_100D.shape[0], embed_matrix_100D.shape[1], input_length=maxlen, weights=[embed_matrix_100D], trainable=False),\n",
    "        tf.keras.layers.LSTM(100),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Create Optimizer\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model_lstm_epochs_100.compile(\n",
    "        optimizer=opt,\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model_lstm_epochs_100.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "126/126 - 7s - loss: 0.6934 - accuracy: 0.4871 - val_loss: 0.6936 - val_accuracy: 0.4715 - 7s/epoch - 52ms/step\n",
      "Epoch 2/100\n",
      "126/126 - 4s - loss: 0.6935 - accuracy: 0.4953 - val_loss: 0.6933 - val_accuracy: 0.4715 - 4s/epoch - 36ms/step\n",
      "Epoch 3/100\n",
      "126/126 - 5s - loss: 0.6934 - accuracy: 0.4968 - val_loss: 0.6937 - val_accuracy: 0.4715 - 5s/epoch - 38ms/step\n",
      "Epoch 4/100\n",
      "126/126 - 5s - loss: 0.6934 - accuracy: 0.4841 - val_loss: 0.6938 - val_accuracy: 0.4715 - 5s/epoch - 37ms/step\n",
      "Epoch 5/100\n",
      "126/126 - 5s - loss: 0.6934 - accuracy: 0.4943 - val_loss: 0.6932 - val_accuracy: 0.4715 - 5s/epoch - 36ms/step\n",
      "Epoch 6/100\n",
      "126/126 - 5s - loss: 0.6933 - accuracy: 0.4920 - val_loss: 0.6930 - val_accuracy: 0.5285 - 5s/epoch - 36ms/step\n",
      "Epoch 7/100\n",
      "126/126 - 4s - loss: 0.6932 - accuracy: 0.4893 - val_loss: 0.6930 - val_accuracy: 0.5285 - 4s/epoch - 35ms/step\n",
      "Epoch 8/100\n",
      "126/126 - 4s - loss: 0.6932 - accuracy: 0.4933 - val_loss: 0.6931 - val_accuracy: 0.5285 - 4s/epoch - 35ms/step\n",
      "Epoch 9/100\n",
      "126/126 - 4s - loss: 0.6932 - accuracy: 0.4923 - val_loss: 0.6931 - val_accuracy: 0.5285 - 4s/epoch - 35ms/step\n",
      "Epoch 10/100\n",
      "126/126 - 4s - loss: 0.6932 - accuracy: 0.4930 - val_loss: 0.6932 - val_accuracy: 0.4715 - 4s/epoch - 35ms/step\n",
      "Epoch 11/100\n",
      "126/126 - 4s - loss: 0.6932 - accuracy: 0.4990 - val_loss: 0.6930 - val_accuracy: 0.5285 - 4s/epoch - 35ms/step\n",
      "Epoch 12/100\n",
      "126/126 - 4s - loss: 0.6932 - accuracy: 0.4940 - val_loss: 0.6931 - val_accuracy: 0.5285 - 4s/epoch - 34ms/step\n",
      "Epoch 13/100\n",
      "126/126 - 4s - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6930 - val_accuracy: 0.5285 - 4s/epoch - 34ms/step\n",
      "Epoch 14/100\n",
      "126/126 - 4s - loss: 0.6932 - accuracy: 0.4925 - val_loss: 0.6932 - val_accuracy: 0.4715 - 4s/epoch - 35ms/step\n",
      "Epoch 15/100\n",
      "126/126 - 4s - loss: 0.6932 - accuracy: 0.4965 - val_loss: 0.6932 - val_accuracy: 0.4715 - 4s/epoch - 35ms/step\n",
      "Epoch 16/100\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.4715 - 5s/epoch - 37ms/step\n",
      "Epoch 17/100\n",
      "126/126 - 4s - loss: 0.6932 - accuracy: 0.4930 - val_loss: 0.6931 - val_accuracy: 0.5285 - 4s/epoch - 35ms/step\n",
      "Epoch 18/100\n",
      "126/126 - 4s - loss: 0.6932 - accuracy: 0.4935 - val_loss: 0.6931 - val_accuracy: 0.5285 - 4s/epoch - 35ms/step\n",
      "Epoch 19/100\n",
      "126/126 - 4s - loss: 0.6932 - accuracy: 0.4908 - val_loss: 0.6931 - val_accuracy: 0.5285 - 4s/epoch - 36ms/step\n",
      "Epoch 20/100\n",
      "126/126 - 4s - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5285 - 4s/epoch - 35ms/step\n",
      "Epoch 21/100\n",
      "126/126 - 4s - loss: 0.6932 - accuracy: 0.4876 - val_loss: 0.6931 - val_accuracy: 0.5285 - 4s/epoch - 36ms/step\n",
      "Epoch 22/100\n",
      "126/126 - 4s - loss: 0.6932 - accuracy: 0.4960 - val_loss: 0.6931 - val_accuracy: 0.5285 - 4s/epoch - 35ms/step\n",
      "Epoch 23/100\n",
      "126/126 - 4s - loss: 0.6932 - accuracy: 0.4918 - val_loss: 0.6931 - val_accuracy: 0.5285 - 4s/epoch - 35ms/step\n",
      "Epoch 24/100\n",
      "126/126 - 4s - loss: 0.6932 - accuracy: 0.4916 - val_loss: 0.6931 - val_accuracy: 0.5285 - 4s/epoch - 35ms/step\n",
      "Epoch 25/100\n",
      "126/126 - 4s - loss: 0.6932 - accuracy: 0.4950 - val_loss: 0.6931 - val_accuracy: 0.5285 - 4s/epoch - 35ms/step\n",
      "Epoch 26/100\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.4935 - val_loss: 0.6931 - val_accuracy: 0.5285 - 5s/epoch - 36ms/step\n",
      "Epoch 27/100\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.4958 - val_loss: 0.6931 - val_accuracy: 0.5285 - 5s/epoch - 37ms/step\n",
      "Epoch 28/100\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.4990 - val_loss: 0.6932 - val_accuracy: 0.4715 - 5s/epoch - 36ms/step\n",
      "Epoch 29/100\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.4968 - val_loss: 0.6931 - val_accuracy: 0.5285 - 5s/epoch - 36ms/step\n",
      "Epoch 30/100\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.4940 - val_loss: 0.6931 - val_accuracy: 0.5285 - 5s/epoch - 37ms/step\n",
      "Epoch 31/100\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.4945 - val_loss: 0.6931 - val_accuracy: 0.5285 - 5s/epoch - 36ms/step\n",
      "Epoch 32/100\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5285 - 5s/epoch - 36ms/step\n",
      "Epoch 33/100\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.4955 - val_loss: 0.6930 - val_accuracy: 0.5285 - 5s/epoch - 36ms/step\n",
      "Epoch 34/100\n",
      "126/126 - 5s - loss: 0.6937 - accuracy: 0.5094 - val_loss: 0.6922 - val_accuracy: 0.5285 - 5s/epoch - 37ms/step\n",
      "Epoch 35/100\n",
      "126/126 - 5s - loss: 0.6934 - accuracy: 0.4898 - val_loss: 0.6933 - val_accuracy: 0.4715 - 5s/epoch - 36ms/step\n",
      "Epoch 36/100\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.4886 - val_loss: 0.6933 - val_accuracy: 0.4715 - 5s/epoch - 36ms/step\n",
      "Epoch 37/100\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.4913 - val_loss: 0.6932 - val_accuracy: 0.4715 - 5s/epoch - 36ms/step\n",
      "Epoch 38/100\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.4933 - val_loss: 0.6931 - val_accuracy: 0.5285 - 5s/epoch - 36ms/step\n",
      "Epoch 39/100\n",
      "126/126 - 4s - loss: 0.6932 - accuracy: 0.4970 - val_loss: 0.6931 - val_accuracy: 0.5285 - 4s/epoch - 36ms/step\n",
      "Epoch 40/100\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.4811 - val_loss: 0.6931 - val_accuracy: 0.5285 - 5s/epoch - 36ms/step\n",
      "Epoch 41/100\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.4715 - 5s/epoch - 36ms/step\n",
      "Epoch 42/100\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.5005 - val_loss: 0.6931 - val_accuracy: 0.5285 - 5s/epoch - 36ms/step\n",
      "Epoch 43/100\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.4940 - val_loss: 0.6932 - val_accuracy: 0.4715 - 5s/epoch - 36ms/step\n",
      "Epoch 44/100\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.4960 - val_loss: 0.6931 - val_accuracy: 0.5285 - 5s/epoch - 37ms/step\n",
      "Epoch 45/100\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.4958 - val_loss: 0.6931 - val_accuracy: 0.5285 - 5s/epoch - 37ms/step\n",
      "Epoch 46/100\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.4948 - val_loss: 0.6931 - val_accuracy: 0.5285 - 5s/epoch - 37ms/step\n",
      "Epoch 47/100\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.4901 - val_loss: 0.6931 - val_accuracy: 0.5285 - 5s/epoch - 37ms/step\n",
      "Epoch 48/100\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.4816 - val_loss: 0.6931 - val_accuracy: 0.5285 - 5s/epoch - 37ms/step\n",
      "Epoch 49/100\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.5015 - val_loss: 0.6932 - val_accuracy: 0.4715 - 5s/epoch - 37ms/step\n",
      "Epoch 50/100\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.4965 - val_loss: 0.6931 - val_accuracy: 0.5285 - 5s/epoch - 37ms/step\n",
      "Epoch 51/100\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.4911 - val_loss: 0.6931 - val_accuracy: 0.5285 - 5s/epoch - 37ms/step\n",
      "Epoch 52/100\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.4980 - val_loss: 0.6931 - val_accuracy: 0.5285 - 5s/epoch - 38ms/step\n",
      "Epoch 53/100\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.4925 - val_loss: 0.6931 - val_accuracy: 0.5285 - 5s/epoch - 37ms/step\n",
      "Epoch 54/100\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.4955 - val_loss: 0.6932 - val_accuracy: 0.4715 - 5s/epoch - 37ms/step\n",
      "Epoch 55/100\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.4945 - val_loss: 0.6931 - val_accuracy: 0.5285 - 5s/epoch - 37ms/step\n",
      "Epoch 56/100\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6930 - val_accuracy: 0.5285 - 5s/epoch - 37ms/step\n",
      "Epoch 57/100\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5285 - 5s/epoch - 37ms/step\n",
      "Epoch 58/100\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.4955 - val_loss: 0.6931 - val_accuracy: 0.5285 - 5s/epoch - 37ms/step\n",
      "Epoch 59/100\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.5015 - val_loss: 0.6932 - val_accuracy: 0.4715 - 5s/epoch - 37ms/step\n",
      "Epoch 60/100\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.4953 - val_loss: 0.6933 - val_accuracy: 0.4715 - 5s/epoch - 37ms/step\n",
      "Epoch 61/100\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.4715 - 5s/epoch - 37ms/step\n",
      "Epoch 62/100\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.4960 - val_loss: 0.6931 - val_accuracy: 0.5285 - 5s/epoch - 37ms/step\n",
      "Epoch 63/100\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.4906 - val_loss: 0.6931 - val_accuracy: 0.5285 - 5s/epoch - 37ms/step\n",
      "Epoch 64/100\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.4935 - val_loss: 0.6932 - val_accuracy: 0.4715 - 5s/epoch - 37ms/step\n",
      "Epoch 65/100\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.4950 - val_loss: 0.6931 - val_accuracy: 0.5285 - 5s/epoch - 37ms/step\n",
      "Epoch 66/100\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.4916 - val_loss: 0.6931 - val_accuracy: 0.5285 - 5s/epoch - 37ms/step\n",
      "Epoch 67/100\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.4970 - val_loss: 0.6932 - val_accuracy: 0.4715 - 5s/epoch - 37ms/step\n",
      "Epoch 68/100\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.4846 - val_loss: 0.6931 - val_accuracy: 0.5285 - 5s/epoch - 37ms/step\n",
      "Epoch 69/100\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.4965 - val_loss: 0.6932 - val_accuracy: 0.4715 - 5s/epoch - 38ms/step\n",
      "Epoch 70/100\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.4935 - val_loss: 0.6931 - val_accuracy: 0.5285 - 5s/epoch - 37ms/step\n",
      "Epoch 71/100\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.4911 - val_loss: 0.6936 - val_accuracy: 0.4715 - 5s/epoch - 37ms/step\n",
      "Epoch 72/100\n",
      "126/126 - 5s - loss: 0.6936 - accuracy: 0.5010 - val_loss: 0.6937 - val_accuracy: 0.4715 - 5s/epoch - 37ms/step\n",
      "Epoch 73/100\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.4923 - val_loss: 0.6932 - val_accuracy: 0.4715 - 5s/epoch - 37ms/step\n",
      "Epoch 74/100\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.4940 - val_loss: 0.6932 - val_accuracy: 0.4715 - 5s/epoch - 37ms/step\n",
      "Epoch 75/100\n",
      "126/126 - 5s - loss: 0.6933 - accuracy: 0.4938 - val_loss: 0.6933 - val_accuracy: 0.4715 - 5s/epoch - 38ms/step\n",
      "Epoch 76/100\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.4950 - val_loss: 0.6934 - val_accuracy: 0.4715 - 5s/epoch - 37ms/step\n",
      "Epoch 77/100\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.4893 - val_loss: 0.6933 - val_accuracy: 0.4715 - 5s/epoch - 37ms/step\n",
      "Epoch 78/100\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6933 - val_accuracy: 0.4715 - 5s/epoch - 37ms/step\n",
      "Epoch 79/100\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.4881 - val_loss: 0.6932 - val_accuracy: 0.4715 - 5s/epoch - 37ms/step\n",
      "Epoch 80/100\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.4963 - val_loss: 0.6932 - val_accuracy: 0.4715 - 5s/epoch - 37ms/step\n",
      "Epoch 81/100\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.4955 - val_loss: 0.6931 - val_accuracy: 0.5285 - 5s/epoch - 37ms/step\n",
      "Epoch 82/100\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.4928 - val_loss: 0.6932 - val_accuracy: 0.4715 - 5s/epoch - 37ms/step\n",
      "Epoch 83/100\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.4925 - val_loss: 0.6932 - val_accuracy: 0.4715 - 5s/epoch - 37ms/step\n",
      "Epoch 84/100\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.4903 - val_loss: 0.6932 - val_accuracy: 0.4715 - 5s/epoch - 37ms/step\n",
      "Epoch 85/100\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.4715 - 5s/epoch - 38ms/step\n",
      "Epoch 86/100\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.4715 - 5s/epoch - 37ms/step\n",
      "Epoch 87/100\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.5020 - val_loss: 0.6930 - val_accuracy: 0.5285 - 5s/epoch - 37ms/step\n",
      "Epoch 88/100\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.4891 - val_loss: 0.6931 - val_accuracy: 0.5285 - 5s/epoch - 37ms/step\n",
      "Epoch 89/100\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.4925 - val_loss: 0.6931 - val_accuracy: 0.4715 - 5s/epoch - 37ms/step\n",
      "Epoch 90/100\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.4985 - val_loss: 0.6931 - val_accuracy: 0.5285 - 5s/epoch - 37ms/step\n",
      "Epoch 91/100\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.4853 - val_loss: 0.6932 - val_accuracy: 0.4715 - 5s/epoch - 37ms/step\n",
      "Epoch 92/100\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.4983 - val_loss: 0.6930 - val_accuracy: 0.5285 - 5s/epoch - 37ms/step\n",
      "Epoch 93/100\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.5015 - val_loss: 0.6932 - val_accuracy: 0.4715 - 5s/epoch - 37ms/step\n",
      "Epoch 94/100\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.4861 - val_loss: 0.6931 - val_accuracy: 0.5285 - 5s/epoch - 37ms/step\n",
      "Epoch 95/100\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.4955 - val_loss: 0.6932 - val_accuracy: 0.4715 - 5s/epoch - 37ms/step\n",
      "Epoch 96/100\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.4935 - val_loss: 0.6932 - val_accuracy: 0.4715 - 5s/epoch - 37ms/step\n",
      "Epoch 97/100\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.4945 - val_loss: 0.6932 - val_accuracy: 0.4715 - 5s/epoch - 37ms/step\n",
      "Epoch 98/100\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.4965 - val_loss: 0.6931 - val_accuracy: 0.5285 - 5s/epoch - 37ms/step\n",
      "Epoch 99/100\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.4896 - val_loss: 0.6932 - val_accuracy: 0.4715 - 5s/epoch - 37ms/step\n",
      "Epoch 100/100\n",
      "126/126 - 5s - loss: 0.6932 - accuracy: 0.4829 - val_loss: 0.6931 - val_accuracy: 0.4715 - 5s/epoch - 37ms/step\n"
     ]
    }
   ],
   "source": [
    "history_lstm_epochs_100 = model_lstm_epochs_100.fit(\n",
    "        X_train_resampled,\n",
    "        y_train_resampled,\n",
    "        epochs=100,\n",
    "        validation_data=(X_test_padded, y_test),\n",
    "        verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Train Model LSTM (Parameter Trainable = True)</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_16 (Embedding)    (None, 100, 100)          652000    \n",
      "                                                                 \n",
      " lstm_16 (LSTM)              (None, 100)               80400     \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 100)               0         \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 64)                6464      \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 738,929\n",
      "Trainable params: 738,929\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_lstm_trainable_true = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Embedding(embed_matrix_100D.shape[0], embed_matrix_100D.shape[1], input_length=maxlen, weights=[embed_matrix_100D], trainable=True),\n",
    "        tf.keras.layers.LSTM(100),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Create Optimizer\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model_lstm_trainable_true.compile(\n",
    "        optimizer=opt,\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model_lstm_trainable_true.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "126/126 - 9s - loss: 0.6938 - accuracy: 0.4829 - val_loss: 0.6939 - val_accuracy: 0.4715 - 9s/epoch - 72ms/step\n",
      "Epoch 2/50\n",
      "126/126 - 7s - loss: 0.6936 - accuracy: 0.4993 - val_loss: 0.6953 - val_accuracy: 0.4715 - 7s/epoch - 53ms/step\n",
      "Epoch 3/50\n",
      "126/126 - 7s - loss: 0.6933 - accuracy: 0.5025 - val_loss: 0.6915 - val_accuracy: 0.5285 - 7s/epoch - 53ms/step\n",
      "Epoch 4/50\n",
      "126/126 - 7s - loss: 0.6937 - accuracy: 0.4935 - val_loss: 0.6926 - val_accuracy: 0.5285 - 7s/epoch - 53ms/step\n",
      "Epoch 5/50\n",
      "126/126 - 7s - loss: 0.6935 - accuracy: 0.4876 - val_loss: 0.6930 - val_accuracy: 0.5285 - 7s/epoch - 53ms/step\n",
      "Epoch 6/50\n",
      "126/126 - 7s - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6923 - val_accuracy: 0.5285 - 7s/epoch - 54ms/step\n",
      "Epoch 7/50\n",
      "126/126 - 7s - loss: 0.6936 - accuracy: 0.5017 - val_loss: 0.6928 - val_accuracy: 0.5285 - 7s/epoch - 55ms/step\n",
      "Epoch 8/50\n",
      "126/126 - 7s - loss: 0.6935 - accuracy: 0.4938 - val_loss: 0.6928 - val_accuracy: 0.5285 - 7s/epoch - 54ms/step\n",
      "Epoch 9/50\n",
      "126/126 - 7s - loss: 0.6933 - accuracy: 0.4995 - val_loss: 0.6931 - val_accuracy: 0.5285 - 7s/epoch - 54ms/step\n",
      "Epoch 10/50\n",
      "126/126 - 7s - loss: 0.6932 - accuracy: 0.4955 - val_loss: 0.6930 - val_accuracy: 0.5285 - 7s/epoch - 54ms/step\n",
      "Epoch 11/50\n",
      "126/126 - 7s - loss: 0.6932 - accuracy: 0.4886 - val_loss: 0.6930 - val_accuracy: 0.5285 - 7s/epoch - 54ms/step\n",
      "Epoch 12/50\n",
      "126/126 - 7s - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5285 - 7s/epoch - 55ms/step\n",
      "Epoch 13/50\n",
      "126/126 - 7s - loss: 0.6932 - accuracy: 0.4868 - val_loss: 0.6931 - val_accuracy: 0.5285 - 7s/epoch - 55ms/step\n",
      "Epoch 14/50\n",
      "126/126 - 7s - loss: 0.6932 - accuracy: 0.4955 - val_loss: 0.6932 - val_accuracy: 0.4715 - 7s/epoch - 55ms/step\n",
      "Epoch 15/50\n",
      "126/126 - 7s - loss: 0.6932 - accuracy: 0.4913 - val_loss: 0.6931 - val_accuracy: 0.5285 - 7s/epoch - 55ms/step\n",
      "Epoch 16/50\n",
      "126/126 - 7s - loss: 0.6932 - accuracy: 0.4950 - val_loss: 0.6932 - val_accuracy: 0.4715 - 7s/epoch - 56ms/step\n",
      "Epoch 17/50\n",
      "126/126 - 7s - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.4715 - 7s/epoch - 57ms/step\n",
      "Epoch 18/50\n",
      "126/126 - 7s - loss: 0.6932 - accuracy: 0.4821 - val_loss: 0.6931 - val_accuracy: 0.5285 - 7s/epoch - 56ms/step\n",
      "Epoch 19/50\n",
      "126/126 - 7s - loss: 0.6932 - accuracy: 0.4968 - val_loss: 0.6931 - val_accuracy: 0.5285 - 7s/epoch - 55ms/step\n",
      "Epoch 20/50\n",
      "126/126 - 7s - loss: 0.6935 - accuracy: 0.5037 - val_loss: 0.6957 - val_accuracy: 0.4715 - 7s/epoch - 52ms/step\n",
      "Epoch 21/50\n",
      "126/126 - 7s - loss: 0.6938 - accuracy: 0.5002 - val_loss: 0.6924 - val_accuracy: 0.5285 - 7s/epoch - 54ms/step\n",
      "Epoch 22/50\n",
      "126/126 - 7s - loss: 0.6935 - accuracy: 0.4945 - val_loss: 0.6930 - val_accuracy: 0.5285 - 7s/epoch - 57ms/step\n",
      "Epoch 23/50\n",
      "126/126 - 7s - loss: 0.6932 - accuracy: 0.4995 - val_loss: 0.6930 - val_accuracy: 0.5285 - 7s/epoch - 56ms/step\n",
      "Epoch 24/50\n",
      "126/126 - 7s - loss: 0.6932 - accuracy: 0.4940 - val_loss: 0.6931 - val_accuracy: 0.5285 - 7s/epoch - 54ms/step\n",
      "Epoch 25/50\n",
      "126/126 - 7s - loss: 0.6932 - accuracy: 0.4970 - val_loss: 0.6932 - val_accuracy: 0.4715 - 7s/epoch - 54ms/step\n",
      "Epoch 26/50\n",
      "126/126 - 7s - loss: 0.6932 - accuracy: 0.4863 - val_loss: 0.6931 - val_accuracy: 0.5285 - 7s/epoch - 55ms/step\n",
      "Epoch 27/50\n",
      "126/126 - 7s - loss: 0.6932 - accuracy: 0.4846 - val_loss: 0.6931 - val_accuracy: 0.5285 - 7s/epoch - 54ms/step\n",
      "Epoch 28/50\n",
      "126/126 - 7s - loss: 0.6932 - accuracy: 0.4824 - val_loss: 0.6931 - val_accuracy: 0.5285 - 7s/epoch - 53ms/step\n",
      "Epoch 29/50\n",
      "126/126 - 7s - loss: 0.6932 - accuracy: 0.4883 - val_loss: 0.6931 - val_accuracy: 0.5285 - 7s/epoch - 55ms/step\n",
      "Epoch 30/50\n",
      "126/126 - 8s - loss: 0.6932 - accuracy: 0.4940 - val_loss: 0.6932 - val_accuracy: 0.4715 - 8s/epoch - 60ms/step\n",
      "Epoch 31/50\n",
      "126/126 - 7s - loss: 0.6932 - accuracy: 0.4970 - val_loss: 0.6931 - val_accuracy: 0.5285 - 7s/epoch - 55ms/step\n",
      "Epoch 32/50\n",
      "126/126 - 7s - loss: 0.6932 - accuracy: 0.4940 - val_loss: 0.6931 - val_accuracy: 0.5285 - 7s/epoch - 55ms/step\n",
      "Epoch 33/50\n",
      "126/126 - 7s - loss: 0.6932 - accuracy: 0.4866 - val_loss: 0.6931 - val_accuracy: 0.5285 - 7s/epoch - 54ms/step\n",
      "Epoch 34/50\n",
      "126/126 - 7s - loss: 0.6932 - accuracy: 0.4930 - val_loss: 0.6931 - val_accuracy: 0.5285 - 7s/epoch - 58ms/step\n",
      "Epoch 35/50\n",
      "126/126 - 7s - loss: 0.6932 - accuracy: 0.4920 - val_loss: 0.6932 - val_accuracy: 0.4715 - 7s/epoch - 55ms/step\n",
      "Epoch 36/50\n",
      "126/126 - 7s - loss: 0.6932 - accuracy: 0.4965 - val_loss: 0.6931 - val_accuracy: 0.5285 - 7s/epoch - 54ms/step\n",
      "Epoch 37/50\n",
      "126/126 - 7s - loss: 0.6932 - accuracy: 0.4965 - val_loss: 0.6932 - val_accuracy: 0.4715 - 7s/epoch - 54ms/step\n",
      "Epoch 38/50\n",
      "126/126 - 7s - loss: 0.6932 - accuracy: 0.4975 - val_loss: 0.6931 - val_accuracy: 0.5285 - 7s/epoch - 55ms/step\n",
      "Epoch 39/50\n",
      "126/126 - 7s - loss: 0.6932 - accuracy: 0.4928 - val_loss: 0.6931 - val_accuracy: 0.5285 - 7s/epoch - 55ms/step\n",
      "Epoch 40/50\n",
      "126/126 - 7s - loss: 0.6932 - accuracy: 0.4881 - val_loss: 0.6931 - val_accuracy: 0.5285 - 7s/epoch - 55ms/step\n",
      "Epoch 41/50\n",
      "126/126 - 7s - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5285 - 7s/epoch - 55ms/step\n",
      "Epoch 42/50\n",
      "126/126 - 7s - loss: 0.6932 - accuracy: 0.4955 - val_loss: 0.6932 - val_accuracy: 0.4715 - 7s/epoch - 54ms/step\n",
      "Epoch 43/50\n",
      "126/126 - 7s - loss: 0.6932 - accuracy: 0.4866 - val_loss: 0.6931 - val_accuracy: 0.5285 - 7s/epoch - 55ms/step\n",
      "Epoch 44/50\n",
      "126/126 - 7s - loss: 0.6932 - accuracy: 0.4891 - val_loss: 0.6931 - val_accuracy: 0.5285 - 7s/epoch - 55ms/step\n",
      "Epoch 45/50\n",
      "126/126 - 7s - loss: 0.6936 - accuracy: 0.4998 - val_loss: 0.6927 - val_accuracy: 0.5285 - 7s/epoch - 56ms/step\n",
      "Epoch 46/50\n",
      "126/126 - 7s - loss: 0.6935 - accuracy: 0.4990 - val_loss: 0.6947 - val_accuracy: 0.4715 - 7s/epoch - 56ms/step\n",
      "Epoch 47/50\n",
      "126/126 - 7s - loss: 0.6933 - accuracy: 0.4995 - val_loss: 0.6946 - val_accuracy: 0.4715 - 7s/epoch - 55ms/step\n",
      "Epoch 48/50\n",
      "126/126 - 7s - loss: 0.6934 - accuracy: 0.5020 - val_loss: 0.6931 - val_accuracy: 0.5285 - 7s/epoch - 56ms/step\n",
      "Epoch 49/50\n",
      "126/126 - 7s - loss: 0.6932 - accuracy: 0.5012 - val_loss: 0.6935 - val_accuracy: 0.4715 - 7s/epoch - 58ms/step\n",
      "Epoch 50/50\n",
      "126/126 - 7s - loss: 0.6933 - accuracy: 0.4898 - val_loss: 0.6930 - val_accuracy: 0.5285 - 7s/epoch - 55ms/step\n"
     ]
    }
   ],
   "source": [
    "history_lstm_trainable_true = model_lstm_trainable_true.fit(\n",
    "        X_train_resampled,\n",
    "        y_train_resampled,\n",
    "        epochs=50,\n",
    "        validation_data=(X_test_padded, y_test),\n",
    "        verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Train Model LSTM (Parameter Learning Rate = 0.0001)</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_19 (Embedding)    (None, 100, 100)          652000    \n",
      "                                                                 \n",
      " lstm_19 (LSTM)              (None, 100)               80400     \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 100)               0         \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 64)                6464      \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 738,929\n",
      "Trainable params: 738,929\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_lstm_learningrate_0_0001 = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Embedding(embed_matrix_100D.shape[0], embed_matrix_100D.shape[1], input_length=maxlen, weights=[embed_matrix_100D], trainable=True),\n",
    "        tf.keras.layers.LSTM(100),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Create Optimizer\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "model_lstm_learningrate_0_0001.compile(\n",
    "        optimizer=opt,\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model_lstm_learningrate_0_0001.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "126/126 - 9s - loss: 0.6932 - accuracy: 0.4918 - val_loss: 0.6933 - val_accuracy: 0.4715 - 9s/epoch - 75ms/step\n",
      "Epoch 2/50\n",
      "126/126 - 7s - loss: 0.6932 - accuracy: 0.4958 - val_loss: 0.6933 - val_accuracy: 0.4715 - 7s/epoch - 56ms/step\n",
      "Epoch 3/50\n",
      "126/126 - 7s - loss: 0.6932 - accuracy: 0.4863 - val_loss: 0.6932 - val_accuracy: 0.4715 - 7s/epoch - 57ms/step\n",
      "Epoch 4/50\n",
      "126/126 - 7s - loss: 0.6932 - accuracy: 0.5002 - val_loss: 0.6932 - val_accuracy: 0.4715 - 7s/epoch - 57ms/step\n",
      "Epoch 5/50\n",
      "126/126 - 7s - loss: 0.6932 - accuracy: 0.4903 - val_loss: 0.6932 - val_accuracy: 0.4715 - 7s/epoch - 57ms/step\n",
      "Epoch 6/50\n",
      "126/126 - 7s - loss: 0.6932 - accuracy: 0.5037 - val_loss: 0.6931 - val_accuracy: 0.5285 - 7s/epoch - 57ms/step\n",
      "Epoch 7/50\n",
      "126/126 - 7s - loss: 0.6932 - accuracy: 0.4920 - val_loss: 0.6933 - val_accuracy: 0.4715 - 7s/epoch - 57ms/step\n",
      "Epoch 8/50\n",
      "126/126 - 7s - loss: 0.6932 - accuracy: 0.5005 - val_loss: 0.6933 - val_accuracy: 0.4715 - 7s/epoch - 57ms/step\n",
      "Epoch 9/50\n",
      "126/126 - 7s - loss: 0.6932 - accuracy: 0.4876 - val_loss: 0.6933 - val_accuracy: 0.4715 - 7s/epoch - 57ms/step\n",
      "Epoch 10/50\n",
      "126/126 - 7s - loss: 0.6932 - accuracy: 0.4980 - val_loss: 0.6932 - val_accuracy: 0.4715 - 7s/epoch - 57ms/step\n",
      "Epoch 11/50\n",
      "126/126 - 7s - loss: 0.6932 - accuracy: 0.5007 - val_loss: 0.6933 - val_accuracy: 0.4715 - 7s/epoch - 57ms/step\n",
      "Epoch 12/50\n",
      "126/126 - 7s - loss: 0.6931 - accuracy: 0.4916 - val_loss: 0.6931 - val_accuracy: 0.5285 - 7s/epoch - 57ms/step\n",
      "Epoch 13/50\n",
      "126/126 - 7s - loss: 0.6932 - accuracy: 0.4988 - val_loss: 0.6929 - val_accuracy: 0.5285 - 7s/epoch - 57ms/step\n",
      "Epoch 14/50\n",
      "126/126 - 7s - loss: 0.6932 - accuracy: 0.4809 - val_loss: 0.6932 - val_accuracy: 0.4715 - 7s/epoch - 58ms/step\n",
      "Epoch 15/50\n",
      "126/126 - 7s - loss: 0.6932 - accuracy: 0.4925 - val_loss: 0.6932 - val_accuracy: 0.4715 - 7s/epoch - 57ms/step\n",
      "Epoch 16/50\n",
      "126/126 - 7s - loss: 0.6932 - accuracy: 0.5022 - val_loss: 0.6932 - val_accuracy: 0.4715 - 7s/epoch - 57ms/step\n",
      "Epoch 17/50\n",
      "126/126 - 7s - loss: 0.6933 - accuracy: 0.4881 - val_loss: 0.6928 - val_accuracy: 0.5285 - 7s/epoch - 57ms/step\n",
      "Epoch 18/50\n",
      "126/126 - 7s - loss: 0.6932 - accuracy: 0.4950 - val_loss: 0.6930 - val_accuracy: 0.5285 - 7s/epoch - 57ms/step\n",
      "Epoch 19/50\n",
      "126/126 - 7s - loss: 0.6932 - accuracy: 0.4995 - val_loss: 0.6931 - val_accuracy: 0.5285 - 7s/epoch - 57ms/step\n",
      "Epoch 20/50\n",
      "126/126 - 7s - loss: 0.6932 - accuracy: 0.5007 - val_loss: 0.6933 - val_accuracy: 0.4715 - 7s/epoch - 58ms/step\n",
      "Epoch 21/50\n",
      "126/126 - 7s - loss: 0.6932 - accuracy: 0.4973 - val_loss: 0.6931 - val_accuracy: 0.5285 - 7s/epoch - 58ms/step\n",
      "Epoch 22/50\n",
      "126/126 - 7s - loss: 0.6932 - accuracy: 0.4940 - val_loss: 0.6932 - val_accuracy: 0.4715 - 7s/epoch - 58ms/step\n",
      "Epoch 23/50\n",
      "126/126 - 7s - loss: 0.6932 - accuracy: 0.4950 - val_loss: 0.6930 - val_accuracy: 0.5285 - 7s/epoch - 58ms/step\n",
      "Epoch 24/50\n",
      "126/126 - 7s - loss: 0.6932 - accuracy: 0.4916 - val_loss: 0.6931 - val_accuracy: 0.5285 - 7s/epoch - 58ms/step\n",
      "Epoch 25/50\n",
      "126/126 - 7s - loss: 0.6932 - accuracy: 0.4960 - val_loss: 0.6931 - val_accuracy: 0.5285 - 7s/epoch - 57ms/step\n",
      "Epoch 26/50\n",
      "126/126 - 7s - loss: 0.6932 - accuracy: 0.5032 - val_loss: 0.6932 - val_accuracy: 0.4715 - 7s/epoch - 58ms/step\n",
      "Epoch 27/50\n",
      "126/126 - 7s - loss: 0.6932 - accuracy: 0.4943 - val_loss: 0.6932 - val_accuracy: 0.4715 - 7s/epoch - 58ms/step\n",
      "Epoch 28/50\n",
      "126/126 - 7s - loss: 0.6933 - accuracy: 0.5015 - val_loss: 0.6933 - val_accuracy: 0.4715 - 7s/epoch - 58ms/step\n",
      "Epoch 29/50\n",
      "126/126 - 7s - loss: 0.6932 - accuracy: 0.5010 - val_loss: 0.6932 - val_accuracy: 0.4715 - 7s/epoch - 58ms/step\n",
      "Epoch 30/50\n",
      "126/126 - 7s - loss: 0.6932 - accuracy: 0.4913 - val_loss: 0.6933 - val_accuracy: 0.4715 - 7s/epoch - 58ms/step\n",
      "Epoch 31/50\n",
      "126/126 - 7s - loss: 0.6932 - accuracy: 0.4933 - val_loss: 0.6931 - val_accuracy: 0.5285 - 7s/epoch - 58ms/step\n",
      "Epoch 32/50\n",
      "126/126 - 7s - loss: 0.6932 - accuracy: 0.4891 - val_loss: 0.6931 - val_accuracy: 0.5285 - 7s/epoch - 58ms/step\n",
      "Epoch 33/50\n",
      "126/126 - 7s - loss: 0.6932 - accuracy: 0.4776 - val_loss: 0.6933 - val_accuracy: 0.4715 - 7s/epoch - 58ms/step\n",
      "Epoch 34/50\n",
      "126/126 - 7s - loss: 0.6932 - accuracy: 0.4916 - val_loss: 0.6932 - val_accuracy: 0.4715 - 7s/epoch - 58ms/step\n",
      "Epoch 35/50\n",
      "126/126 - 7s - loss: 0.6932 - accuracy: 0.5022 - val_loss: 0.6930 - val_accuracy: 0.5285 - 7s/epoch - 58ms/step\n",
      "Epoch 36/50\n",
      "126/126 - 7s - loss: 0.6932 - accuracy: 0.4826 - val_loss: 0.6930 - val_accuracy: 0.5285 - 7s/epoch - 58ms/step\n",
      "Epoch 37/50\n",
      "126/126 - 7s - loss: 0.6931 - accuracy: 0.5020 - val_loss: 0.6932 - val_accuracy: 0.4715 - 7s/epoch - 58ms/step\n",
      "Epoch 38/50\n",
      "126/126 - 7s - loss: 0.6932 - accuracy: 0.5055 - val_loss: 0.6930 - val_accuracy: 0.5285 - 7s/epoch - 58ms/step\n",
      "Epoch 39/50\n",
      "126/126 - 7s - loss: 0.6932 - accuracy: 0.4928 - val_loss: 0.6931 - val_accuracy: 0.5285 - 7s/epoch - 58ms/step\n",
      "Epoch 40/50\n",
      "126/126 - 7s - loss: 0.6932 - accuracy: 0.4928 - val_loss: 0.6931 - val_accuracy: 0.5285 - 7s/epoch - 57ms/step\n",
      "Epoch 41/50\n",
      "126/126 - 7s - loss: 0.6932 - accuracy: 0.4903 - val_loss: 0.6932 - val_accuracy: 0.4715 - 7s/epoch - 58ms/step\n",
      "Epoch 42/50\n",
      "126/126 - 7s - loss: 0.6932 - accuracy: 0.4945 - val_loss: 0.6930 - val_accuracy: 0.5285 - 7s/epoch - 57ms/step\n",
      "Epoch 43/50\n",
      "126/126 - 7s - loss: 0.6932 - accuracy: 0.5037 - val_loss: 0.6931 - val_accuracy: 0.5285 - 7s/epoch - 58ms/step\n",
      "Epoch 44/50\n",
      "126/126 - 7s - loss: 0.6932 - accuracy: 0.4958 - val_loss: 0.6931 - val_accuracy: 0.5285 - 7s/epoch - 57ms/step\n",
      "Epoch 45/50\n",
      "126/126 - 7s - loss: 0.6932 - accuracy: 0.4975 - val_loss: 0.6931 - val_accuracy: 0.5285 - 7s/epoch - 57ms/step\n",
      "Epoch 46/50\n",
      "126/126 - 7s - loss: 0.6932 - accuracy: 0.4923 - val_loss: 0.6932 - val_accuracy: 0.4715 - 7s/epoch - 57ms/step\n",
      "Epoch 47/50\n",
      "126/126 - 7s - loss: 0.6932 - accuracy: 0.4906 - val_loss: 0.6932 - val_accuracy: 0.4715 - 7s/epoch - 57ms/step\n",
      "Epoch 48/50\n",
      "126/126 - 7s - loss: 0.6932 - accuracy: 0.4950 - val_loss: 0.6930 - val_accuracy: 0.5285 - 7s/epoch - 57ms/step\n",
      "Epoch 49/50\n",
      "126/126 - 7s - loss: 0.6932 - accuracy: 0.4903 - val_loss: 0.6931 - val_accuracy: 0.4715 - 7s/epoch - 58ms/step\n",
      "Epoch 50/50\n",
      "126/126 - 7s - loss: 0.6932 - accuracy: 0.4925 - val_loss: 0.6933 - val_accuracy: 0.4715 - 7s/epoch - 57ms/step\n"
     ]
    }
   ],
   "source": [
    "history_lstm_learningrate_0_0001 = model_lstm_learningrate_0_0001.fit(\n",
    "        X_train_resampled,\n",
    "        y_train_resampled,\n",
    "        epochs=50,\n",
    "        validation_data=(X_test_padded, y_test),\n",
    "        verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Train Model LSTM (Parameter Learning Rate = 0.01)</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_20 (Embedding)    (None, 100, 100)          652000    \n",
      "                                                                 \n",
      " lstm_20 (LSTM)              (None, 100)               80400     \n",
      "                                                                 \n",
      " dropout_20 (Dropout)        (None, 100)               0         \n",
      "                                                                 \n",
      " dense_40 (Dense)            (None, 64)                6464      \n",
      "                                                                 \n",
      " dense_41 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 738,929\n",
      "Trainable params: 738,929\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_lstm_learningrate_0_01 = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Embedding(embed_matrix_100D.shape[0], embed_matrix_100D.shape[1], input_length=maxlen, weights=[embed_matrix_100D], trainable=True),\n",
    "        tf.keras.layers.LSTM(100),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Create Optimizer\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "model_lstm_learningrate_0_01.compile(\n",
    "        optimizer=opt,\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model_lstm_learningrate_0_01.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "126/126 - 9s - loss: 0.6961 - accuracy: 0.4940 - val_loss: 0.6918 - val_accuracy: 0.5285 - 9s/epoch - 73ms/step\n",
      "Epoch 2/50\n",
      "126/126 - 8s - loss: 0.6938 - accuracy: 0.4863 - val_loss: 0.6928 - val_accuracy: 0.5285 - 8s/epoch - 62ms/step\n",
      "Epoch 3/50\n",
      "126/126 - 7s - loss: 0.6934 - accuracy: 0.4896 - val_loss: 0.6929 - val_accuracy: 0.5285 - 7s/epoch - 56ms/step\n",
      "Epoch 4/50\n",
      "126/126 - 7s - loss: 0.6936 - accuracy: 0.4846 - val_loss: 0.6931 - val_accuracy: 0.5285 - 7s/epoch - 58ms/step\n",
      "Epoch 5/50\n",
      "126/126 - 7s - loss: 0.6935 - accuracy: 0.4970 - val_loss: 0.6928 - val_accuracy: 0.5285 - 7s/epoch - 58ms/step\n",
      "Epoch 6/50\n",
      "126/126 - 7s - loss: 0.6934 - accuracy: 0.4881 - val_loss: 0.6940 - val_accuracy: 0.4715 - 7s/epoch - 55ms/step\n",
      "Epoch 7/50\n",
      "126/126 - 7s - loss: 0.6940 - accuracy: 0.4965 - val_loss: 0.6932 - val_accuracy: 0.4715 - 7s/epoch - 58ms/step\n",
      "Epoch 8/50\n",
      "126/126 - 7s - loss: 0.6932 - accuracy: 0.5117 - val_loss: 0.6957 - val_accuracy: 0.4715 - 7s/epoch - 56ms/step\n",
      "Epoch 9/50\n",
      "126/126 - 7s - loss: 0.6935 - accuracy: 0.4925 - val_loss: 0.6926 - val_accuracy: 0.5285 - 7s/epoch - 56ms/step\n",
      "Epoch 10/50\n",
      "126/126 - 7s - loss: 0.6933 - accuracy: 0.5020 - val_loss: 0.6940 - val_accuracy: 0.4715 - 7s/epoch - 56ms/step\n",
      "Epoch 11/50\n",
      "126/126 - 7s - loss: 0.6934 - accuracy: 0.4925 - val_loss: 0.6932 - val_accuracy: 0.4715 - 7s/epoch - 58ms/step\n",
      "Epoch 12/50\n",
      "126/126 - 7s - loss: 0.6933 - accuracy: 0.5015 - val_loss: 0.6926 - val_accuracy: 0.5285 - 7s/epoch - 56ms/step\n",
      "Epoch 13/50\n",
      "126/126 - 7s - loss: 0.6934 - accuracy: 0.4886 - val_loss: 0.6928 - val_accuracy: 0.5285 - 7s/epoch - 57ms/step\n",
      "Epoch 14/50\n",
      "126/126 - 7s - loss: 0.6935 - accuracy: 0.4916 - val_loss: 0.6929 - val_accuracy: 0.5285 - 7s/epoch - 56ms/step\n",
      "Epoch 15/50\n",
      "126/126 - 7s - loss: 0.6932 - accuracy: 0.5075 - val_loss: 0.6921 - val_accuracy: 0.5285 - 7s/epoch - 57ms/step\n",
      "Epoch 16/50\n",
      "126/126 - 7s - loss: 0.6935 - accuracy: 0.4871 - val_loss: 0.6931 - val_accuracy: 0.5285 - 7s/epoch - 58ms/step\n",
      "Epoch 17/50\n",
      "126/126 - 7s - loss: 0.6935 - accuracy: 0.5035 - val_loss: 0.6936 - val_accuracy: 0.4715 - 7s/epoch - 57ms/step\n",
      "Epoch 18/50\n",
      "126/126 - 7s - loss: 0.6934 - accuracy: 0.4965 - val_loss: 0.6922 - val_accuracy: 0.5285 - 7s/epoch - 58ms/step\n",
      "Epoch 19/50\n",
      "126/126 - 7s - loss: 0.6935 - accuracy: 0.4876 - val_loss: 0.6925 - val_accuracy: 0.5285 - 7s/epoch - 58ms/step\n",
      "Epoch 20/50\n",
      "126/126 - 7s - loss: 0.6934 - accuracy: 0.4876 - val_loss: 0.6926 - val_accuracy: 0.5285 - 7s/epoch - 59ms/step\n",
      "Epoch 21/50\n",
      "126/126 - 7s - loss: 0.6934 - accuracy: 0.4985 - val_loss: 0.6921 - val_accuracy: 0.5285 - 7s/epoch - 58ms/step\n",
      "Epoch 22/50\n",
      "126/126 - 7s - loss: 0.6935 - accuracy: 0.4876 - val_loss: 0.6927 - val_accuracy: 0.5285 - 7s/epoch - 56ms/step\n",
      "Epoch 23/50\n",
      "126/126 - 7s - loss: 0.6934 - accuracy: 0.4990 - val_loss: 0.6924 - val_accuracy: 0.5285 - 7s/epoch - 56ms/step\n",
      "Epoch 24/50\n",
      "126/126 - 7s - loss: 0.6936 - accuracy: 0.4925 - val_loss: 0.6928 - val_accuracy: 0.5285 - 7s/epoch - 55ms/step\n",
      "Epoch 25/50\n",
      "126/126 - 7s - loss: 0.6933 - accuracy: 0.4871 - val_loss: 0.6938 - val_accuracy: 0.4715 - 7s/epoch - 55ms/step\n",
      "Epoch 26/50\n",
      "126/126 - 7s - loss: 0.6934 - accuracy: 0.4990 - val_loss: 0.6924 - val_accuracy: 0.5285 - 7s/epoch - 55ms/step\n",
      "Epoch 27/50\n",
      "126/126 - 7s - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6950 - val_accuracy: 0.4715 - 7s/epoch - 57ms/step\n",
      "Epoch 28/50\n",
      "126/126 - 7s - loss: 0.6933 - accuracy: 0.5005 - val_loss: 0.6926 - val_accuracy: 0.5285 - 7s/epoch - 56ms/step\n",
      "Epoch 29/50\n",
      "126/126 - 9s - loss: 0.6933 - accuracy: 0.5040 - val_loss: 0.6918 - val_accuracy: 0.5285 - 9s/epoch - 68ms/step\n",
      "Epoch 30/50\n",
      "126/126 - 8s - loss: 0.6936 - accuracy: 0.4945 - val_loss: 0.6923 - val_accuracy: 0.5285 - 8s/epoch - 64ms/step\n",
      "Epoch 31/50\n",
      "126/126 - 8s - loss: 0.6936 - accuracy: 0.4876 - val_loss: 0.6937 - val_accuracy: 0.4715 - 8s/epoch - 60ms/step\n",
      "Epoch 32/50\n",
      "126/126 - 8s - loss: 0.6935 - accuracy: 0.4871 - val_loss: 0.6934 - val_accuracy: 0.4715 - 8s/epoch - 60ms/step\n",
      "Epoch 33/50\n",
      "126/126 - 8s - loss: 0.6933 - accuracy: 0.4935 - val_loss: 0.6937 - val_accuracy: 0.4715 - 8s/epoch - 64ms/step\n",
      "Epoch 34/50\n",
      "126/126 - 7s - loss: 0.6934 - accuracy: 0.4940 - val_loss: 0.6945 - val_accuracy: 0.4715 - 7s/epoch - 59ms/step\n",
      "Epoch 35/50\n",
      "126/126 - 8s - loss: 0.6936 - accuracy: 0.4916 - val_loss: 0.6940 - val_accuracy: 0.4715 - 8s/epoch - 61ms/step\n",
      "Epoch 36/50\n",
      "126/126 - 7s - loss: 0.6934 - accuracy: 0.4990 - val_loss: 0.6927 - val_accuracy: 0.5285 - 7s/epoch - 57ms/step\n",
      "Epoch 37/50\n",
      "126/126 - 7s - loss: 0.6935 - accuracy: 0.4896 - val_loss: 0.6932 - val_accuracy: 0.4715 - 7s/epoch - 58ms/step\n",
      "Epoch 38/50\n",
      "126/126 - 7s - loss: 0.6932 - accuracy: 0.4990 - val_loss: 0.6940 - val_accuracy: 0.4715 - 7s/epoch - 58ms/step\n",
      "Epoch 39/50\n",
      "126/126 - 8s - loss: 0.6935 - accuracy: 0.4925 - val_loss: 0.6934 - val_accuracy: 0.4715 - 8s/epoch - 60ms/step\n",
      "Epoch 40/50\n",
      "126/126 - 7s - loss: 0.6935 - accuracy: 0.4965 - val_loss: 0.6938 - val_accuracy: 0.4715 - 7s/epoch - 57ms/step\n",
      "Epoch 41/50\n",
      "126/126 - 7s - loss: 0.6933 - accuracy: 0.4930 - val_loss: 0.6931 - val_accuracy: 0.5285 - 7s/epoch - 58ms/step\n",
      "Epoch 42/50\n",
      "126/126 - 7s - loss: 0.6958 - accuracy: 0.4911 - val_loss: 0.6927 - val_accuracy: 0.5285 - 7s/epoch - 59ms/step\n",
      "Epoch 43/50\n",
      "126/126 - 8s - loss: 0.6938 - accuracy: 0.4948 - val_loss: 0.6935 - val_accuracy: 0.4715 - 8s/epoch - 60ms/step\n",
      "Epoch 44/50\n",
      "126/126 - 7s - loss: 0.6938 - accuracy: 0.4911 - val_loss: 0.6951 - val_accuracy: 0.4715 - 7s/epoch - 58ms/step\n",
      "Epoch 45/50\n",
      "126/126 - 7s - loss: 0.6934 - accuracy: 0.4953 - val_loss: 0.6927 - val_accuracy: 0.5285 - 7s/epoch - 59ms/step\n",
      "Epoch 46/50\n",
      "126/126 - 7s - loss: 0.6934 - accuracy: 0.4975 - val_loss: 0.6926 - val_accuracy: 0.5285 - 7s/epoch - 56ms/step\n",
      "Epoch 47/50\n",
      "126/126 - 7s - loss: 0.6933 - accuracy: 0.5080 - val_loss: 0.6940 - val_accuracy: 0.4715 - 7s/epoch - 58ms/step\n",
      "Epoch 48/50\n",
      "126/126 - 7s - loss: 0.6935 - accuracy: 0.4985 - val_loss: 0.6950 - val_accuracy: 0.4715 - 7s/epoch - 57ms/step\n",
      "Epoch 49/50\n",
      "126/126 - 7s - loss: 0.6936 - accuracy: 0.5010 - val_loss: 0.6924 - val_accuracy: 0.5285 - 7s/epoch - 58ms/step\n",
      "Epoch 50/50\n",
      "126/126 - 7s - loss: 0.6936 - accuracy: 0.4955 - val_loss: 0.6924 - val_accuracy: 0.5285 - 7s/epoch - 57ms/step\n"
     ]
    }
   ],
   "source": [
    "history_lstm_learningrate_0_01 = model_lstm_learningrate_0_01.fit(\n",
    "        X_train_resampled,\n",
    "        y_train_resampled,\n",
    "        epochs=50,\n",
    "        validation_data=(X_test_padded, y_test),\n",
    "        verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Create SVM Model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(binary=True)\n",
    "\n",
    "vectorizer.fit(list(X_train) + list(X_test))\n",
    "\n",
    "X_train_vec = vectorizer.transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = svm.SVC(kernel='linear', probability=True)\n",
    "\n",
    "prob = svc.fit(X_train_vec, y_train).predict_proba(X_test_vec)\n",
    "\n",
    "y_pred_svm = svc.predict(X_test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 54.21%\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy : {round(accuracy_score(y_test, y_pred_svm) * 100, 2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.51800326, 0.48199674],\n",
       "       [0.52244987, 0.47755013],\n",
       "       [0.56833728, 0.43166272],\n",
       "       [0.4204815 , 0.5795185 ],\n",
       "       [0.5212829 , 0.4787171 ],\n",
       "       [0.51432481, 0.48567519],\n",
       "       [0.51902092, 0.48097908],\n",
       "       [0.56711882, 0.43288118],\n",
       "       [0.49446049, 0.50553951],\n",
       "       [0.5       , 0.5       ],\n",
       "       [0.47902939, 0.52097061],\n",
       "       [0.5       , 0.5       ],\n",
       "       [0.55123352, 0.44876648],\n",
       "       [0.47908495, 0.52091505],\n",
       "       [0.50662938, 0.49337062],\n",
       "       [0.46641028, 0.53358972],\n",
       "       [0.44842109, 0.55157891],\n",
       "       [0.53769802, 0.46230198],\n",
       "       [0.52303735, 0.47696265],\n",
       "       [0.52244987, 0.47755013],\n",
       "       [0.52554246, 0.47445754],\n",
       "       [0.55503394, 0.44496606],\n",
       "       [0.5       , 0.5       ],\n",
       "       [0.51511704, 0.48488296],\n",
       "       [0.52119019, 0.47880981],\n",
       "       [0.52018892, 0.47981108],\n",
       "       [0.49465392, 0.50534608],\n",
       "       [0.5       , 0.5       ],\n",
       "       [0.51083051, 0.48916949],\n",
       "       [0.53772499, 0.46227501],\n",
       "       [0.53390478, 0.46609522],\n",
       "       [0.49313627, 0.50686373],\n",
       "       [0.5       , 0.5       ],\n",
       "       [0.5553184 , 0.4446816 ],\n",
       "       [0.57153685, 0.42846315],\n",
       "       [0.47907186, 0.52092814],\n",
       "       [0.5       , 0.5       ],\n",
       "       [0.47883973, 0.52116027],\n",
       "       [0.5616251 , 0.4383749 ],\n",
       "       [0.46692171, 0.53307829],\n",
       "       [0.45662987, 0.54337013],\n",
       "       [0.53274193, 0.46725807],\n",
       "       [0.50755685, 0.49244315],\n",
       "       [0.53751587, 0.46248413],\n",
       "       [0.49292846, 0.50707154],\n",
       "       [0.57145519, 0.42854481],\n",
       "       [0.53701708, 0.46298292],\n",
       "       [0.48147483, 0.51852517],\n",
       "       [0.47908945, 0.52091055],\n",
       "       [0.54106808, 0.45893192],\n",
       "       [0.51661315, 0.48338685],\n",
       "       [0.52784239, 0.47215761],\n",
       "       [0.47907347, 0.52092653],\n",
       "       [0.48616265, 0.51383735],\n",
       "       [0.46023082, 0.53976918],\n",
       "       [0.5131106 , 0.4868894 ],\n",
       "       [0.55831643, 0.44168357],\n",
       "       [0.57358893, 0.42641107],\n",
       "       [0.5       , 0.5       ],\n",
       "       [0.4138245 , 0.5861755 ],\n",
       "       [0.53743113, 0.46256887],\n",
       "       [0.5       , 0.5       ],\n",
       "       [0.50925574, 0.49074426],\n",
       "       [0.51434973, 0.48565027],\n",
       "       [0.51254512, 0.48745488],\n",
       "       [0.52114768, 0.47885232],\n",
       "       [0.46521036, 0.53478964],\n",
       "       [0.5       , 0.5       ],\n",
       "       [0.50985173, 0.49014827],\n",
       "       [0.49176443, 0.50823557],\n",
       "       [0.50901192, 0.49098808],\n",
       "       [0.50818085, 0.49181915],\n",
       "       [0.5239835 , 0.4760165 ],\n",
       "       [0.53567958, 0.46432042],\n",
       "       [0.51269373, 0.48730627],\n",
       "       [0.50563169, 0.49436831],\n",
       "       [0.51538057, 0.48461943],\n",
       "       [0.60848303, 0.39151697],\n",
       "       [0.53264083, 0.46735917],\n",
       "       [0.51579297, 0.48420703],\n",
       "       [0.48474956, 0.51525044],\n",
       "       [0.46390326, 0.53609674],\n",
       "       [0.52105165, 0.47894835],\n",
       "       [0.55926492, 0.44073508],\n",
       "       [0.51871158, 0.48128842],\n",
       "       [0.5       , 0.5       ],\n",
       "       [0.51582228, 0.48417772],\n",
       "       [0.48633504, 0.51366496],\n",
       "       [0.55147443, 0.44852557],\n",
       "       [0.47763329, 0.52236671],\n",
       "       [0.47679476, 0.52320524],\n",
       "       [0.5376833 , 0.4623167 ],\n",
       "       [0.5       , 0.5       ],\n",
       "       [0.51049954, 0.48950046],\n",
       "       [0.48294276, 0.51705724],\n",
       "       [0.44730526, 0.55269474],\n",
       "       [0.51083288, 0.48916712],\n",
       "       [0.53299445, 0.46700555],\n",
       "       [0.54558772, 0.45441228],\n",
       "       [0.5262095 , 0.4737905 ],\n",
       "       [0.51269124, 0.48730876],\n",
       "       [0.54454452, 0.45545548],\n",
       "       [0.47744902, 0.52255098],\n",
       "       [0.53769372, 0.46230628],\n",
       "       [0.48496814, 0.51503186],\n",
       "       [0.51735685, 0.48264315],\n",
       "       [0.53675054, 0.46324946],\n",
       "       [0.53768324, 0.46231676],\n",
       "       [0.46796803, 0.53203197],\n",
       "       [0.51948641, 0.48051359],\n",
       "       [0.53768203, 0.46231797],\n",
       "       [0.62341735, 0.37658265],\n",
       "       [0.53768457, 0.46231543],\n",
       "       [0.45628182, 0.54371818],\n",
       "       [0.46531652, 0.53468348],\n",
       "       [0.56517972, 0.43482028],\n",
       "       [0.52243577, 0.47756423],\n",
       "       [0.53531147, 0.46468853],\n",
       "       [0.52822244, 0.47177756],\n",
       "       [0.48147467, 0.51852533],\n",
       "       [0.53631645, 0.46368355],\n",
       "       [0.53681643, 0.46318357],\n",
       "       [0.48357581, 0.51642419],\n",
       "       [0.51355402, 0.48644598],\n",
       "       [0.51903246, 0.48096754],\n",
       "       [0.51824151, 0.48175849],\n",
       "       [0.45784152, 0.54215848],\n",
       "       [0.53769468, 0.46230532],\n",
       "       [0.48263459, 0.51736541],\n",
       "       [0.48590693, 0.51409307],\n",
       "       [0.48187719, 0.51812281],\n",
       "       [0.62589189, 0.37410811],\n",
       "       [0.51052004, 0.48947996],\n",
       "       [0.48226339, 0.51773661],\n",
       "       [0.52987966, 0.47012034],\n",
       "       [0.50572145, 0.49427855],\n",
       "       [0.50936612, 0.49063388],\n",
       "       [0.51831443, 0.48168557],\n",
       "       [0.50682279, 0.49317721],\n",
       "       [0.41291076, 0.58708924],\n",
       "       [0.5       , 0.5       ],\n",
       "       [0.4553375 , 0.5446625 ],\n",
       "       [0.53769726, 0.46230274],\n",
       "       [0.53401955, 0.46598045],\n",
       "       [0.5       , 0.5       ],\n",
       "       [0.54351413, 0.45648587],\n",
       "       [0.53916036, 0.46083964],\n",
       "       [0.5       , 0.5       ],\n",
       "       [0.46961682, 0.53038318],\n",
       "       [0.50804058, 0.49195942],\n",
       "       [0.53339198, 0.46660802],\n",
       "       [0.5       , 0.5       ],\n",
       "       [0.51362897, 0.48637103],\n",
       "       [0.5       , 0.5       ],\n",
       "       [0.47907447, 0.52092553],\n",
       "       [0.47546708, 0.52453292],\n",
       "       [0.54074029, 0.45925971],\n",
       "       [0.45340712, 0.54659288],\n",
       "       [0.52456176, 0.47543824],\n",
       "       [0.5       , 0.5       ],\n",
       "       [0.48946419, 0.51053581],\n",
       "       [0.49091425, 0.50908575],\n",
       "       [0.46579348, 0.53420652],\n",
       "       [0.53610031, 0.46389969],\n",
       "       [0.5       , 0.5       ],\n",
       "       [0.48081401, 0.51918599],\n",
       "       [0.52376034, 0.47623966],\n",
       "       [0.54798776, 0.45201224],\n",
       "       [0.52127993, 0.47872007],\n",
       "       [0.51233784, 0.48766216],\n",
       "       [0.55433446, 0.44566554],\n",
       "       [0.55774191, 0.44225809],\n",
       "       [0.5       , 0.5       ],\n",
       "       [0.48638863, 0.51361137],\n",
       "       [0.5       , 0.5       ],\n",
       "       [0.5232769 , 0.4767231 ],\n",
       "       [0.5       , 0.5       ],\n",
       "       [0.51264623, 0.48735377],\n",
       "       [0.5       , 0.5       ],\n",
       "       [0.5       , 0.5       ],\n",
       "       [0.50648688, 0.49351312],\n",
       "       [0.5       , 0.5       ],\n",
       "       [0.46547051, 0.53452949],\n",
       "       [0.4920696 , 0.5079304 ],\n",
       "       [0.52963921, 0.47036079],\n",
       "       [0.53768641, 0.46231359],\n",
       "       [0.5       , 0.5       ],\n",
       "       [0.51725058, 0.48274942],\n",
       "       [0.5111614 , 0.4888386 ],\n",
       "       [0.5       , 0.5       ],\n",
       "       [0.46426941, 0.53573059],\n",
       "       [0.53769433, 0.46230567],\n",
       "       [0.54133232, 0.45866768],\n",
       "       [0.53000534, 0.46999466],\n",
       "       [0.5       , 0.5       ],\n",
       "       [0.47394988, 0.52605012],\n",
       "       [0.51787759, 0.48212241],\n",
       "       [0.47329539, 0.52670461],\n",
       "       [0.47736615, 0.52263385],\n",
       "       [0.53768683, 0.46231317],\n",
       "       [0.50763594, 0.49236406],\n",
       "       [0.53763653, 0.46236347],\n",
       "       [0.48520839, 0.51479161],\n",
       "       [0.49008019, 0.50991981],\n",
       "       [0.50870447, 0.49129553],\n",
       "       [0.43337572, 0.56662428],\n",
       "       [0.5       , 0.5       ],\n",
       "       [0.55078646, 0.44921354],\n",
       "       [0.48633847, 0.51366153],\n",
       "       [0.54982352, 0.45017648],\n",
       "       [0.51646517, 0.48353483],\n",
       "       [0.5       , 0.5       ],\n",
       "       [0.54771061, 0.45228939],\n",
       "       [0.53767953, 0.46232047],\n",
       "       [0.4572425 , 0.5427575 ],\n",
       "       [0.5       , 0.5       ],\n",
       "       [0.50573745, 0.49426255],\n",
       "       [0.53768484, 0.46231516],\n",
       "       [0.48681993, 0.51318007],\n",
       "       [0.53106605, 0.46893395],\n",
       "       [0.47745131, 0.52254869],\n",
       "       [0.53678948, 0.46321052],\n",
       "       [0.48422523, 0.51577477],\n",
       "       [0.5       , 0.5       ],\n",
       "       [0.49269464, 0.50730536],\n",
       "       [0.51729179, 0.48270821],\n",
       "       [0.44664948, 0.55335052],\n",
       "       [0.53769796, 0.46230204],\n",
       "       [0.57929985, 0.42070015],\n",
       "       [0.50964318, 0.49035682],\n",
       "       [0.51742498, 0.48257502],\n",
       "       [0.48958356, 0.51041644],\n",
       "       [0.52635461, 0.47364539],\n",
       "       [0.47157047, 0.52842953],\n",
       "       [0.5       , 0.5       ],\n",
       "       [0.48609339, 0.51390661],\n",
       "       [0.44301678, 0.55698322],\n",
       "       [0.5       , 0.5       ],\n",
       "       [0.53027338, 0.46972662],\n",
       "       [0.47948783, 0.52051217],\n",
       "       [0.52962661, 0.47037339],\n",
       "       [0.51319264, 0.48680736],\n",
       "       [0.52002946, 0.47997054],\n",
       "       [0.51219141, 0.48780859],\n",
       "       [0.55307693, 0.44692307],\n",
       "       [0.50909064, 0.49090936],\n",
       "       [0.48352787, 0.51647213],\n",
       "       [0.49142744, 0.50857256],\n",
       "       [0.5       , 0.5       ],\n",
       "       [0.48365633, 0.51634367],\n",
       "       [0.5       , 0.5       ],\n",
       "       [0.5       , 0.5       ],\n",
       "       [0.49281611, 0.50718389],\n",
       "       [0.5       , 0.5       ],\n",
       "       [0.47748108, 0.52251892],\n",
       "       [0.5       , 0.5       ],\n",
       "       [0.50900823, 0.49099177],\n",
       "       [0.51165131, 0.48834869],\n",
       "       [0.49003279, 0.50996721],\n",
       "       [0.49429207, 0.50570793],\n",
       "       [0.47557444, 0.52442556],\n",
       "       [0.52674714, 0.47325286],\n",
       "       [0.47448234, 0.52551766],\n",
       "       [0.48869972, 0.51130028],\n",
       "       [0.45135754, 0.54864246],\n",
       "       [0.50874816, 0.49125184],\n",
       "       [0.53769432, 0.46230568],\n",
       "       [0.55893902, 0.44106098],\n",
       "       [0.4475792 , 0.5524208 ],\n",
       "       [0.44105369, 0.55894631],\n",
       "       [0.5       , 0.5       ],\n",
       "       [0.52178072, 0.47821928],\n",
       "       [0.52385643, 0.47614357],\n",
       "       [0.56292444, 0.43707556],\n",
       "       [0.46633973, 0.53366027],\n",
       "       [0.59328232, 0.40671768],\n",
       "       [0.48470588, 0.51529412],\n",
       "       [0.53824546, 0.46175454],\n",
       "       [0.5       , 0.5       ],\n",
       "       [0.47233222, 0.52766778],\n",
       "       [0.53446477, 0.46553523],\n",
       "       [0.53295725, 0.46704275],\n",
       "       [0.52591651, 0.47408349],\n",
       "       [0.53274415, 0.46725585],\n",
       "       [0.51164378, 0.48835622],\n",
       "       [0.51445361, 0.48554639],\n",
       "       [0.53769148, 0.46230852],\n",
       "       [0.50841094, 0.49158906],\n",
       "       [0.46595165, 0.53404835],\n",
       "       [0.52237575, 0.47762425],\n",
       "       [0.52774718, 0.47225282],\n",
       "       [0.48947601, 0.51052399],\n",
       "       [0.50770144, 0.49229856],\n",
       "       [0.50539294, 0.49460706],\n",
       "       [0.54623744, 0.45376256],\n",
       "       [0.5       , 0.5       ],\n",
       "       [0.48418437, 0.51581563],\n",
       "       [0.53846852, 0.46153148],\n",
       "       [0.53378554, 0.46621446],\n",
       "       [0.54387796, 0.45612204],\n",
       "       [0.51452871, 0.48547129],\n",
       "       [0.40655316, 0.59344684],\n",
       "       [0.45458835, 0.54541165],\n",
       "       [0.51119463, 0.48880537],\n",
       "       [0.55584166, 0.44415834],\n",
       "       [0.48322367, 0.51677633],\n",
       "       [0.51526248, 0.48473752],\n",
       "       [0.46995656, 0.53004344],\n",
       "       [0.50573745, 0.49426255],\n",
       "       [0.55946265, 0.44053735],\n",
       "       [0.53769389, 0.46230611],\n",
       "       [0.51486994, 0.48513006],\n",
       "       [0.5       , 0.5       ],\n",
       "       [0.5       , 0.5       ],\n",
       "       [0.48874681, 0.51125319],\n",
       "       [0.51541376, 0.48458624],\n",
       "       [0.53768683, 0.46231317],\n",
       "       [0.47181869, 0.52818131],\n",
       "       [0.52562654, 0.47437346],\n",
       "       [0.5       , 0.5       ],\n",
       "       [0.55255395, 0.44744605],\n",
       "       [0.5453911 , 0.4546089 ],\n",
       "       [0.51519064, 0.48480936],\n",
       "       [0.50933197, 0.49066803],\n",
       "       [0.53317538, 0.46682462],\n",
       "       [0.53767976, 0.46232024],\n",
       "       [0.46644495, 0.53355505],\n",
       "       [0.50944628, 0.49055372],\n",
       "       [0.52858776, 0.47141224],\n",
       "       [0.5548422 , 0.4451578 ],\n",
       "       [0.54439896, 0.45560104],\n",
       "       [0.46947139, 0.53052861],\n",
       "       [0.52440858, 0.47559142],\n",
       "       [0.47907675, 0.52092325],\n",
       "       [0.57998583, 0.42001417],\n",
       "       [0.55477026, 0.44522974],\n",
       "       [0.54087166, 0.45912834],\n",
       "       [0.4912196 , 0.5087804 ],\n",
       "       [0.42694012, 0.57305988],\n",
       "       [0.48786139, 0.51213861],\n",
       "       [0.50563169, 0.49436831],\n",
       "       [0.50631203, 0.49368797],\n",
       "       [0.47908832, 0.52091168],\n",
       "       [0.50625266, 0.49374734],\n",
       "       [0.52914147, 0.47085853],\n",
       "       [0.52844643, 0.47155357],\n",
       "       [0.4445953 , 0.5554047 ],\n",
       "       [0.47907632, 0.52092368],\n",
       "       [0.48083066, 0.51916934],\n",
       "       [0.53769489, 0.46230511],\n",
       "       [0.5       , 0.5       ],\n",
       "       [0.47683235, 0.52316765],\n",
       "       [0.5       , 0.5       ],\n",
       "       [0.53224781, 0.46775219],\n",
       "       [0.47475768, 0.52524232],\n",
       "       [0.47041625, 0.52958375],\n",
       "       [0.51603321, 0.48396679],\n",
       "       [0.4921627 , 0.5078373 ],\n",
       "       [0.48225641, 0.51774359],\n",
       "       [0.5       , 0.5       ],\n",
       "       [0.47444381, 0.52555619],\n",
       "       [0.47569038, 0.52430962],\n",
       "       [0.54808265, 0.45191735],\n",
       "       [0.54960423, 0.45039577],\n",
       "       [0.53768395, 0.46231605],\n",
       "       [0.51159431, 0.48840569],\n",
       "       [0.51939557, 0.48060443],\n",
       "       [0.55070827, 0.44929173],\n",
       "       [0.51516278, 0.48483722],\n",
       "       [0.53476251, 0.46523749],\n",
       "       [0.47907438, 0.52092562],\n",
       "       [0.51170224, 0.48829776],\n",
       "       [0.6418204 , 0.3581796 ],\n",
       "       [0.47948218, 0.52051782],\n",
       "       [0.53207826, 0.46792174],\n",
       "       [0.46701578, 0.53298422],\n",
       "       [0.55696176, 0.44303824],\n",
       "       [0.50925011, 0.49074989],\n",
       "       [0.47908525, 0.52091475],\n",
       "       [0.49454281, 0.50545719],\n",
       "       [0.51487462, 0.48512538],\n",
       "       [0.5       , 0.5       ],\n",
       "       [0.49464545, 0.50535455],\n",
       "       [0.5376924 , 0.4623076 ],\n",
       "       [0.53985344, 0.46014656],\n",
       "       [0.47810284, 0.52189716],\n",
       "       [0.47769042, 0.52230958],\n",
       "       [0.54989905, 0.45010095],\n",
       "       [0.51609811, 0.48390189],\n",
       "       [0.55749299, 0.44250701],\n",
       "       [0.53768959, 0.46231041],\n",
       "       [0.53769792, 0.46230208],\n",
       "       [0.50789028, 0.49210972],\n",
       "       [0.5       , 0.5       ],\n",
       "       [0.57503258, 0.42496742],\n",
       "       [0.5       , 0.5       ],\n",
       "       [0.51561752, 0.48438248],\n",
       "       [0.48293568, 0.51706432],\n",
       "       [0.50679896, 0.49320104],\n",
       "       [0.52140376, 0.47859624],\n",
       "       [0.44981447, 0.55018553],\n",
       "       [0.5       , 0.5       ],\n",
       "       [0.47308085, 0.52691915],\n",
       "       [0.51500711, 0.48499289],\n",
       "       [0.53183414, 0.46816586],\n",
       "       [0.54417899, 0.45582101],\n",
       "       [0.48415762, 0.51584238],\n",
       "       [0.50755685, 0.49244315],\n",
       "       [0.52938372, 0.47061628],\n",
       "       [0.47525718, 0.52474282],\n",
       "       [0.5050817 , 0.4949183 ],\n",
       "       [0.46584257, 0.53415743],\n",
       "       [0.50547999, 0.49452001],\n",
       "       [0.53084414, 0.46915586],\n",
       "       [0.455496  , 0.544504  ],\n",
       "       [0.53768535, 0.46231465],\n",
       "       [0.61002364, 0.38997636],\n",
       "       [0.52820847, 0.47179153],\n",
       "       [0.49185875, 0.50814125],\n",
       "       [0.48633847, 0.51366153],\n",
       "       [0.47651798, 0.52348202],\n",
       "       [0.47907167, 0.52092833],\n",
       "       [0.51226867, 0.48773133],\n",
       "       [0.51137479, 0.48862521],\n",
       "       [0.51282569, 0.48717431],\n",
       "       [0.53768942, 0.46231058],\n",
       "       [0.46215613, 0.53784387],\n",
       "       [0.5199242 , 0.4800758 ],\n",
       "       [0.49364229, 0.50635771],\n",
       "       [0.50765681, 0.49234319],\n",
       "       [0.42961345, 0.57038655],\n",
       "       [0.54276585, 0.45723415],\n",
       "       [0.44209178, 0.55790822],\n",
       "       [0.53768469, 0.46231531],\n",
       "       [0.49419418, 0.50580582],\n",
       "       [0.4841181 , 0.5158819 ],\n",
       "       [0.52388709, 0.47611291],\n",
       "       [0.49016507, 0.50983493],\n",
       "       [0.51255684, 0.48744316]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
