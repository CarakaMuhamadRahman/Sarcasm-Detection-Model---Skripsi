{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Read Datasets<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4510 entries, 0 to 4509\n",
      "Data columns (total 17 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Unnamed: 0      4510 non-null   int64  \n",
      " 1   Text            4510 non-null   object \n",
      " 2   emoji           4510 non-null   object \n",
      " 3   Tokenized       4510 non-null   object \n",
      " 4   final_text      4494 non-null   object \n",
      " 5   text_emoji      4510 non-null   object \n",
      " 6   Pos_Word        4510 non-null   int64  \n",
      " 7   Neg_Word        4510 non-null   int64  \n",
      " 8   Total_Word      4510 non-null   int64  \n",
      " 9   Pos_Ratio       4510 non-null   float64\n",
      " 10  Neg_Ratio       4510 non-null   float64\n",
      " 11  Sentimen_Text   4510 non-null   object \n",
      " 12  Tokenize_Emoji  4510 non-null   object \n",
      " 13  Pos_Emoji       4510 non-null   int64  \n",
      " 14  Neg_Emoji       4510 non-null   int64  \n",
      " 15  Sentimen_Emoji  4510 non-null   object \n",
      " 16  Sarcasm         4510 non-null   object \n",
      "dtypes: float64(2), int64(6), object(9)\n",
      "memory usage: 599.1+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Text</th>\n",
       "      <th>emoji</th>\n",
       "      <th>Tokenized</th>\n",
       "      <th>final_text</th>\n",
       "      <th>text_emoji</th>\n",
       "      <th>Pos_Word</th>\n",
       "      <th>Neg_Word</th>\n",
       "      <th>Total_Word</th>\n",
       "      <th>Pos_Ratio</th>\n",
       "      <th>Neg_Ratio</th>\n",
       "      <th>Sentimen_Text</th>\n",
       "      <th>Tokenize_Emoji</th>\n",
       "      <th>Pos_Emoji</th>\n",
       "      <th>Neg_Emoji</th>\n",
       "      <th>Sentimen_Emoji</th>\n",
       "      <th>Sarcasm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>kawan2 sunda bersatu jemput arteria dahlan</td>\n",
       "      <td>😁</td>\n",
       "      <td>['kawan', 'sunda', 'bersatu', 'jemput', 'arter...</td>\n",
       "      <td>kawan sunda bersatu jemput arteria dahlan</td>\n",
       "      <td>kawan sunda bersatu jemput arteria dahlan 😁</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Positif</td>\n",
       "      <td>['kawan', 'sunda', 'bersatu', 'jemput', 'arter...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Positif</td>\n",
       "      <td>Negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>arteria dahlan disidang adat sunda daerah menu...</td>\n",
       "      <td>😁</td>\n",
       "      <td>['arteria', 'dahlan', 'sidang', 'adat', 'sunda...</td>\n",
       "      <td>arteria dahlan sidang adat sunda daerah menunt...</td>\n",
       "      <td>arteria dahlan sidang adat sunda daerah menunt...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>Positif</td>\n",
       "      <td>['arteria', 'dahlan', 'sidang', 'adat', 'sunda...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Positif</td>\n",
       "      <td>Negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>ga ditafsirkan membanding bandingkan edy arter...</td>\n",
       "      <td>😁</td>\n",
       "      <td>['ga', 'tafsir', 'membanding', 'membandingkan'...</td>\n",
       "      <td>ga tafsir membanding membandingkan edy arteria...</td>\n",
       "      <td>ga tafsir membanding membandingkan edy arteria...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>Positif</td>\n",
       "      <td>['ga', 'tafsir', 'membanding', 'membandingkan'...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Positif</td>\n",
       "      <td>Negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>nantik ngak divhumas polri nya bilang palsu td...</td>\n",
       "      <td>😁</td>\n",
       "      <td>['nanti', 'tidak', 'divisi humas', 'polri', '....</td>\n",
       "      <td>divisi humas polri bilang palsu mengeluarkan a...</td>\n",
       "      <td>divisi humas polri bilang palsu mengeluarkan a...</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>Negatif</td>\n",
       "      <td>['divisi', 'humas', 'polri', 'bilang', 'palsu'...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Positif</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>urut dada dech kuasa hukum tdk mengerti hukum ...</td>\n",
       "      <td>😁</td>\n",
       "      <td>['urut', 'dada', 'deh', 'kuasa', 'hukum', 'tid...</td>\n",
       "      <td>urut dada deh kuasa hukum mengerti hukum arter...</td>\n",
       "      <td>urut dada deh kuasa hukum mengerti hukum arter...</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>28</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>Positif</td>\n",
       "      <td>['urut', 'dada', 'deh', 'kuasa', 'hukum', 'men...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Positif</td>\n",
       "      <td>Negatif</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               Text  \\\n",
       "0           0         kawan2 sunda bersatu jemput arteria dahlan   \n",
       "1           2  arteria dahlan disidang adat sunda daerah menu...   \n",
       "2           4  ga ditafsirkan membanding bandingkan edy arter...   \n",
       "3           5  nantik ngak divhumas polri nya bilang palsu td...   \n",
       "4           6  urut dada dech kuasa hukum tdk mengerti hukum ...   \n",
       "\n",
       "                           emoji  \\\n",
       "0                              😁   \n",
       "1                              😁   \n",
       "2                              😁   \n",
       "3                              😁   \n",
       "4                              😁   \n",
       "\n",
       "                                           Tokenized  \\\n",
       "0  ['kawan', 'sunda', 'bersatu', 'jemput', 'arter...   \n",
       "1  ['arteria', 'dahlan', 'sidang', 'adat', 'sunda...   \n",
       "2  ['ga', 'tafsir', 'membanding', 'membandingkan'...   \n",
       "3  ['nanti', 'tidak', 'divisi humas', 'polri', '....   \n",
       "4  ['urut', 'dada', 'deh', 'kuasa', 'hukum', 'tid...   \n",
       "\n",
       "                                          final_text  \\\n",
       "0          kawan sunda bersatu jemput arteria dahlan   \n",
       "1  arteria dahlan sidang adat sunda daerah menunt...   \n",
       "2  ga tafsir membanding membandingkan edy arteria...   \n",
       "3  divisi humas polri bilang palsu mengeluarkan a...   \n",
       "4  urut dada deh kuasa hukum mengerti hukum arter...   \n",
       "\n",
       "                                          text_emoji  Pos_Word  Neg_Word  \\\n",
       "0        kawan sunda bersatu jemput arteria dahlan 😁         2         0   \n",
       "1  arteria dahlan sidang adat sunda daerah menunt...         5         4   \n",
       "2  ga tafsir membanding membandingkan edy arteria...         3         2   \n",
       "3  divisi humas polri bilang palsu mengeluarkan a...         4         8   \n",
       "4  urut dada deh kuasa hukum mengerti hukum arter...        14         6   \n",
       "\n",
       "   Total_Word  Pos_Ratio  Neg_Ratio Sentimen_Text  \\\n",
       "0           6   0.333333   0.000000       Positif   \n",
       "1           9   0.555556   0.444444       Positif   \n",
       "2           9   0.333333   0.222222       Positif   \n",
       "3          16   0.250000   0.500000       Negatif   \n",
       "4          28   0.500000   0.214286       Positif   \n",
       "\n",
       "                                      Tokenize_Emoji  Pos_Emoji  Neg_Emoji  \\\n",
       "0  ['kawan', 'sunda', 'bersatu', 'jemput', 'arter...          1          0   \n",
       "1  ['arteria', 'dahlan', 'sidang', 'adat', 'sunda...          1          0   \n",
       "2  ['ga', 'tafsir', 'membanding', 'membandingkan'...          1          0   \n",
       "3  ['divisi', 'humas', 'polri', 'bilang', 'palsu'...          1          0   \n",
       "4  ['urut', 'dada', 'deh', 'kuasa', 'hukum', 'men...          1          0   \n",
       "\n",
       "  Sentimen_Emoji  Sarcasm  \n",
       "0        Positif  Negatif  \n",
       "1        Positif  Negatif  \n",
       "2        Positif  Negatif  \n",
       "3        Positif  Positif  \n",
       "4        Positif  Negatif  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('Datasets_Ready.xlsx')\n",
    "\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unused column/feature\n",
    "df = df.drop(columns='Unnamed: 0')\n",
    "df = df.drop(columns='Text')\n",
    "df = df.drop(columns='emoji')\n",
    "df = df.drop(columns='Tokenized')\n",
    "df = df.drop(columns='final_text')\n",
    "df = df.drop(columns='Pos_Word')\n",
    "df = df.drop(columns='Neg_Word')\n",
    "df = df.drop(columns='Total_Word')\n",
    "df = df.drop(columns='Pos_Ratio')\n",
    "df = df.drop(columns='Neg_Ratio')\n",
    "df = df.drop(columns='Tokenize_Emoji')\n",
    "df = df.drop(columns='Pos_Emoji')\n",
    "df = df.drop(columns='Neg_Emoji')\n",
    "df = df.drop(columns='Sentimen_Emoji')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_emoji</th>\n",
       "      <th>Sentimen_Text</th>\n",
       "      <th>Sarcasm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kawan sunda bersatu jemput arteria dahlan 😁</td>\n",
       "      <td>Positif</td>\n",
       "      <td>Negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>arteria dahlan sidang adat sunda daerah menunt...</td>\n",
       "      <td>Positif</td>\n",
       "      <td>Negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ga tafsir membanding membandingkan edy arteria...</td>\n",
       "      <td>Positif</td>\n",
       "      <td>Negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>divisi humas polri bilang palsu mengeluarkan a...</td>\n",
       "      <td>Negatif</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>urut dada deh kuasa hukum mengerti hukum arter...</td>\n",
       "      <td>Positif</td>\n",
       "      <td>Negatif</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          text_emoji Sentimen_Text  Sarcasm\n",
       "0        kawan sunda bersatu jemput arteria dahlan 😁       Positif  Negatif\n",
       "1  arteria dahlan sidang adat sunda daerah menunt...       Positif  Negatif\n",
       "2  ga tafsir membanding membandingkan edy arteria...       Positif  Negatif\n",
       "3  divisi humas polri bilang palsu mengeluarkan a...       Negatif  Positif\n",
       "4  urut dada deh kuasa hukum mengerti hukum arter...       Positif  Negatif"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Duplicated Data: 120\n"
     ]
    }
   ],
   "source": [
    "print(f'Total Duplicated Data: {df.duplicated().sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Duplicated Data After Handling: 0\n"
     ]
    }
   ],
   "source": [
    "print(f'Total Duplicated Data After Handling: {df.duplicated().sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Missing Value: \n",
      "text_emoji       0\n",
      "Sentimen_Text    0\n",
      "Sarcasm          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f'Total Missing Value: \\n{df.isnull().sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Sentimen_Text'] = df['Sentimen_Text'].replace('Positif', 1)\n",
    "df['Sentimen_Text'] = df['Sentimen_Text'].replace('Negatif', 0)\n",
    "\n",
    "df['Sarcasm'] = df['Sarcasm'].replace('Positif', 1)\n",
    "df['Sarcasm'] = df['Sarcasm'].replace('Negatif', 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Splitting Data</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['text_emoji'].values\n",
    "y = df['Sarcasm'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Tokenization</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "maxlen = 100\n",
    "tokenizer = Tokenizer(num_words=10000, oov_token='<OOV>')\n",
    "\n",
    "tokenizer.fit_on_texts(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<OOV>': 1,\n",
       " '👍': 2,\n",
       " 'luhut': 3,\n",
       " '💩': 4,\n",
       " '😁': 5,\n",
       " 'indonesia': 6,\n",
       " 'cak': 7,\n",
       " '😠': 8,\n",
       " 'puan': 9,\n",
       " 'orang': 10,\n",
       " '💯': 11,\n",
       " 'nun': 12,\n",
       " 'jokowi': 13,\n",
       " 'presiden': 14,\n",
       " 'binsar': 15,\n",
       " '👎': 16,\n",
       " 'partai': 17,\n",
       " '😊': 18,\n",
       " 'anies': 19,\n",
       " 'rakyat': 20,\n",
       " '😭': 21,\n",
       " 'maharani': 22,\n",
       " 'bu': 23,\n",
       " '😨': 24,\n",
       " 'ganjar': 25,\n",
       " 'menteri': 26,\n",
       " 'prabowo': 27,\n",
       " 'pemimpin': 28,\n",
       " 'semoga': 29,\n",
       " 'aja': 30,\n",
       " 'baswedan': 31,\n",
       " 'ga': 32,\n",
       " 'negara': 33,\n",
       " 'masyarakat': 34,\n",
       " '😆': 35,\n",
       " 'anak': 36,\n",
       " 'calon': 37,\n",
       " '2024': 38,\n",
       " '💕': 39,\n",
       " 'jakarta': 40,\n",
       " 'kalo': 41,\n",
       " 'bangsa': 42,\n",
       " 'demokrasi': 43,\n",
       " 'politik': 44,\n",
       " 'banget': 45,\n",
       " 'ketua': 46,\n",
       " 'perjuangan': 47,\n",
       " 'lucu': 48,\n",
       " '😔': 49,\n",
       " 'mbak': 50,\n",
       " 'nama': 51,\n",
       " 'salah': 52,\n",
       " '✌': 53,\n",
       " 'firaun': 54,\n",
       " 'kerja': 55,\n",
       " 'israel': 56,\n",
       " 'capres': 57,\n",
       " 'beliau': 58,\n",
       " 'sih': 59,\n",
       " '1': 60,\n",
       " 'investasi': 61,\n",
       " '😴': 62,\n",
       " 'mulyadi': 63,\n",
       " 'cocok': 64,\n",
       " 'program': 65,\n",
       " 'kadrun': 66,\n",
       " 'biar': 67,\n",
       " 'ri': 68,\n",
       " 'dunia': 69,\n",
       " 'dg': 70,\n",
       " 'edi': 71,\n",
       " 'lu': 72,\n",
       " 'negeri': 73,\n",
       " 'pilih': 74,\n",
       " 'gubernur': 75,\n",
       " 'nih': 76,\n",
       " 'bikin': 77,\n",
       " 'keren': 78,\n",
       " 'bagus': 79,\n",
       " 'rt': 80,\n",
       " 'bohong': 81,\n",
       " 'tau': 82,\n",
       " 'maaf': 83,\n",
       " 'bidang': 84,\n",
       " 'pilpres': 85,\n",
       " 'manusia': 86,\n",
       " 'pemerintah': 87,\n",
       " 'suka': 88,\n",
       " 'masuk': 89,\n",
       " 'hidup': 90,\n",
       " 'dukung': 91,\n",
       " 'pemilu': 92,\n",
       " 'kali': 93,\n",
       " 'kemaritiman': 94,\n",
       " 'tp': 95,\n",
       " 'bilang': 96,\n",
       " 'pencitraan': 97,\n",
       " 'emang': 98,\n",
       " 'warga': 99,\n",
       " 'maju': 100,\n",
       " 'sehat': 101,\n",
       " 'langsung': 102,\n",
       " 'berbicara': 103,\n",
       " 'sosok': 104,\n",
       " 'pakai': 105,\n",
       " 'semangat': 106,\n",
       " 'mbah': 107,\n",
       " 'allah': 108,\n",
       " 'krn': 109,\n",
       " 'koordinator': 110,\n",
       " 'lihat': 111,\n",
       " 'mas': 112,\n",
       " 'rumah': 113,\n",
       " 'hati': 114,\n",
       " 'pejabat': 115,\n",
       " 'berani': 116,\n",
       " 'dpr': 117,\n",
       " 'membangun': 118,\n",
       " 'mendukung': 119,\n",
       " 'jalan': 120,\n",
       " 'keluarga': 121,\n",
       " 'hukum': 122,\n",
       " 'pendidikan': 123,\n",
       " 'kau': 124,\n",
       " 'kayak': 125,\n",
       " 'memiliki': 126,\n",
       " 'hasil': 127,\n",
       " 'merakyat': 128,\n",
       " 'setuju': 129,\n",
       " 'cari': 130,\n",
       " 'prestasi': 131,\n",
       " 'subianto': 132,\n",
       " 'kaya': 133,\n",
       " 'nkri': 134,\n",
       " 'takut': 135,\n",
       " 'aparat': 136,\n",
       " 'mantap': 137,\n",
       " 'islam': 138,\n",
       " 'terbaik': 139,\n",
       " 'contoh': 140,\n",
       " 'uang': 141,\n",
       " 'malu': 142,\n",
       " 'bodoh': 143,\n",
       " 'muda': 144,\n",
       " 'menolak': 145,\n",
       " 'pernyataan': 146,\n",
       " 'kasih': 147,\n",
       " 'coba': 148,\n",
       " 'air': 149,\n",
       " 'penuh': 150,\n",
       " 'kesambet': 151,\n",
       " 'tuh': 152,\n",
       " 'beda': 153,\n",
       " 'perempuan': 154,\n",
       " 'caknun': 155,\n",
       " 'mimpi': 156,\n",
       " 'gitu': 157,\n",
       " 'tuhan': 158,\n",
       " 'hebat': 159,\n",
       " 'pendukung': 160,\n",
       " 'n': 161,\n",
       " 'keadilan': 162,\n",
       " 'jawa': 163,\n",
       " 'daerah': 164,\n",
       " 'yudhoyono': 165,\n",
       " 'korupsi': 166,\n",
       " 'pikir': 167,\n",
       " 'paham': 168,\n",
       " 'video': 169,\n",
       " 'politisi': 170,\n",
       " 'haman': 171,\n",
       " 'koruptor': 172,\n",
       " 'dukungan': 173,\n",
       " 'kaos': 174,\n",
       " 'palestina': 175,\n",
       " 'otak': 176,\n",
       " 'kpk': 177,\n",
       " 'bangsat': 178,\n",
       " 'tni': 179,\n",
       " '2022': 180,\n",
       " 'agama': 181,\n",
       " 'acara': 182,\n",
       " 'nilai': 183,\n",
       " 'ott': 184,\n",
       " 'goblok': 185,\n",
       " 'bantuan': 186,\n",
       " 'dah': 187,\n",
       " 'tangkap': 188,\n",
       " 'pintar': 189,\n",
       " 'diam': 190,\n",
       " 'china': 191,\n",
       " 'b': 192,\n",
       " 'wakil': 193,\n",
       " 'tangan': 194,\n",
       " 'cawapres': 195,\n",
       " 'makasih': 196,\n",
       " 'kawan': 197,\n",
       " 'muka': 198,\n",
       " 'kota': 199,\n",
       " 'turun': 200,\n",
       " 'asli': 201,\n",
       " 'mending': 202,\n",
       " 'main': 203,\n",
       " 'kalimantan': 204,\n",
       " 'menang': 205,\n",
       " 'mu': 206,\n",
       " 'amin': 207,\n",
       " 'kubu': 208,\n",
       " 'cinta': 209,\n",
       " 'kebenaran': 210,\n",
       " 'harga': 211,\n",
       " 'tokoh': 212,\n",
       " 'suara': 213,\n",
       " 'virus': 214,\n",
       " 'fakta': 215,\n",
       " 'sejahtera': 216,\n",
       " 'sejarah': 217,\n",
       " 'alasan': 218,\n",
       " 'pertemuan': 219,\n",
       " 'sosial': 220,\n",
       " 'iya': 221,\n",
       " 'pa': 222,\n",
       " 'bacot': 223,\n",
       " 'kader': 224,\n",
       " 'urusan': 225,\n",
       " 'sukses': 226,\n",
       " 'media': 227,\n",
       " 'bali': 228,\n",
       " 'arteria': 229,\n",
       " 'ad': 230,\n",
       " 'bola': 231,\n",
       " 'fifa': 232,\n",
       " 'menjadikan': 233,\n",
       " 'pkb': 234,\n",
       " 'petani': 235,\n",
       " 'sayang': 236,\n",
       " 'rezim': 237,\n",
       " 'liat': 238,\n",
       " 'pembangunan': 239,\n",
       " 'senyum': 240,\n",
       " 'sbg': 241,\n",
       " 'deh': 242,\n",
       " 'baca': 243,\n",
       " 'mendampingi': 244,\n",
       " 'berita': 245,\n",
       " 'tolak': 246,\n",
       " 'd': 247,\n",
       " 'kl': 248,\n",
       " 'gue': 249,\n",
       " 'mata': 250,\n",
       " 'pas': 251,\n",
       " 'lempar': 252,\n",
       " 'jiwa': 253,\n",
       " 'belajar': 254,\n",
       " 'bayar': 255,\n",
       " 'makan': 256,\n",
       " '🤣🤣🤣': 257,\n",
       " 'generasi': 258,\n",
       " 'sahabat': 259,\n",
       " 'tim': 260,\n",
       " 'gini': 261,\n",
       " 'silakan': 262,\n",
       " 'publik': 263,\n",
       " 'menilai': 264,\n",
       " 'doang': 265,\n",
       " 'bebas': 266,\n",
       " 'habis': 267,\n",
       " 'percaya': 268,\n",
       " 'kasihan': 269,\n",
       " '👇': 270,\n",
       " 'jenderal': 271,\n",
       " 'peduli': 272,\n",
       " '2023': 273,\n",
       " 'hak': 274,\n",
       " 'sesuai': 275,\n",
       " 'mati': 276,\n",
       " 'senang': 277,\n",
       " 'paman': 278,\n",
       " 'ayo': 279,\n",
       " 'kalah': 280,\n",
       " 'menyebut': 281,\n",
       " 'anis': 282,\n",
       " 'bangun': 283,\n",
       " 'fitnah': 284,\n",
       " 'mah': 285,\n",
       " 'dahlan': 286,\n",
       " 'butuh': 287,\n",
       " 'polisi': 288,\n",
       " 'erick': 289,\n",
       " 'pimpin': 290,\n",
       " 'kepala': 291,\n",
       " 'kepemimpinan': 292,\n",
       " 'jujur': 293,\n",
       " 'utang': 294,\n",
       " '😂': 295,\n",
       " 'membantu': 296,\n",
       " 'u': 297,\n",
       " 'cerdas': 298,\n",
       " 'mudah': 299,\n",
       " 'terima': 300,\n",
       " 'tenaga': 301,\n",
       " 'terkait': 302,\n",
       " 'hutang': 303,\n",
       " 'mulut': 304,\n",
       " 'bangga': 305,\n",
       " 'era': 306,\n",
       " 'kelompok': 307,\n",
       " 'kunjungan': 308,\n",
       " 'ekonomi': 309,\n",
       " 'timnas': 310,\n",
       " 'gagal': 311,\n",
       " 'kena': 312,\n",
       " '🤣': 313,\n",
       " 'edy': 314,\n",
       " 'agus': 315,\n",
       " 'memimpin': 316,\n",
       " 'janji': 317,\n",
       " 'pki': 318,\n",
       " 'viral': 319,\n",
       " 'relawan': 320,\n",
       " 'jabatan': 321,\n",
       " 'sakit': 322,\n",
       " 'selamat': 323,\n",
       " 'pandjaitan': 324,\n",
       " 'e': 325,\n",
       " 'duet': 326,\n",
       " 'foto': 327,\n",
       " 'miskin': 328,\n",
       " 'barat': 329,\n",
       " 'cina': 330,\n",
       " 'proyek': 331,\n",
       " 'kebanyakan': 332,\n",
       " 'bpk': 333,\n",
       " 'lo': 334,\n",
       " 'pribadi': 335,\n",
       " 'sikap': 336,\n",
       " 'susah': 337,\n",
       " 'nasional': 338,\n",
       " 'anjing': 339,\n",
       " 'cerita': 340,\n",
       " 'aspirasi': 341,\n",
       " 'kalangan': 342,\n",
       " 'sok': 343,\n",
       " 'qorun': 344,\n",
       " 'sifat': 345,\n",
       " 'cantik': 346,\n",
       " 'dungu': 347,\n",
       " 'anggap': 348,\n",
       " 'mengaku': 349,\n",
       " 'melanjutkan': 350,\n",
       " 'cilik': 351,\n",
       " 'isi': 352,\n",
       " 'nyata': 353,\n",
       " 'sadar': 354,\n",
       " 'buruk': 355,\n",
       " 'wan': 356,\n",
       " 'k': 357,\n",
       " 'periode': 358,\n",
       " 'kemarin': 359,\n",
       " 'elu': 360,\n",
       " 'megawati': 361,\n",
       " '00': 362,\n",
       " 'sm': 363,\n",
       " 'layak': 364,\n",
       " 'tua': 365,\n",
       " 'mobil': 366,\n",
       " 'harapan': 367,\n",
       " 'piala': 368,\n",
       " 'hancur': 369,\n",
       " '🙏': 370,\n",
       " 'soekarno': 371,\n",
       " 'istana': 372,\n",
       " 'senyuman': 373,\n",
       " 'listrik': 374,\n",
       " 'drama': 375,\n",
       " 'asing': 376,\n",
       " 'ama': 377,\n",
       " 'alhamdulillah': 378,\n",
       " 'pasangan': 379,\n",
       " 'membagikan': 380,\n",
       " 'komitmen': 381,\n",
       " 'desa': 382,\n",
       " 'buka': 383,\n",
       " 'data': 384,\n",
       " 's': 385,\n",
       " 'kaum': 386,\n",
       " 'puncak': 387,\n",
       " 'penerus': 388,\n",
       " 'nasib': 389,\n",
       " 'hadir': 390,\n",
       " 'bermanfaat': 391,\n",
       " 'momen': 392,\n",
       " 'kepentingan': 393,\n",
       " 'jaman': 394,\n",
       " 'demokrat': 395,\n",
       " 'budi': 396,\n",
       " 'komentar': 397,\n",
       " 'mega': 398,\n",
       " 'spt': 399,\n",
       " 'g': 400,\n",
       " 'gibran': 401,\n",
       " 'ambil': 402,\n",
       " 'super': 403,\n",
       " 'melawan': 404,\n",
       " 'tanah': 405,\n",
       " 'kekuasaan': 406,\n",
       " 'kinerja': 407,\n",
       " 'menjaga': 408,\n",
       " 'widodo': 409,\n",
       " 'utama': 410,\n",
       " '2019': 411,\n",
       " 'penguasa': 412,\n",
       " 'bukti': 413,\n",
       " 'olahraga': 414,\n",
       " 'mendengarkan': 415,\n",
       " 'politikus': 416,\n",
       " 'memilih': 417,\n",
       " 'menerima': 418,\n",
       " 'loh': 419,\n",
       " 'stadion': 420,\n",
       " 'negri': 421,\n",
       " 'gua': 422,\n",
       " 'akun': 423,\n",
       " 'identitas': 424,\n",
       " 'tingkat': 425,\n",
       " 'bang': 426,\n",
       " 'melindungi': 427,\n",
       " 'keputusan': 428,\n",
       " 'y': 429,\n",
       " 'perubahan': 430,\n",
       " 'bro': 431,\n",
       " 'petugas': 432,\n",
       " 'ni': 433,\n",
       " 'ente': 434,\n",
       " 'isu': 435,\n",
       " 'gagasan': 436,\n",
       " 'muslim': 437,\n",
       " 'bawa': 438,\n",
       " 'maksud': 439,\n",
       " 'maritim': 440,\n",
       " 'jelek': 441,\n",
       " 'tujuan': 442,\n",
       " 'tuan': 443,\n",
       " 'pamer': 444,\n",
       " 'cebong': 445,\n",
       " 'najis': 446,\n",
       " 'rusak': 447,\n",
       " 'sekolah': 448,\n",
       " 'proses': 449,\n",
       " 'thohir': 450,\n",
       " 'jateng': 451,\n",
       " 'penjilat': 452,\n",
       " 'jaga': 453,\n",
       " 'aman': 454,\n",
       " 'membela': 455,\n",
       " 'direktur': 456,\n",
       " 'visi': 457,\n",
       " 'vaksin': 458,\n",
       " 'kafir': 459,\n",
       " 'kebijakan': 460,\n",
       " 'ketemu': 461,\n",
       " 'peraturan': 462,\n",
       " 'sembunyi': 463,\n",
       " 'merdeka': 464,\n",
       " 'umat': 465,\n",
       " 'bicara': 466,\n",
       " 'tinggal': 467,\n",
       " 'manfaat': 468,\n",
       " 'kementerian': 469,\n",
       " '🤭': 470,\n",
       " 'kip': 471,\n",
       " 'sepak': 472,\n",
       " 'bahasa': 473,\n",
       " 'wajar': 474,\n",
       " 'anti': 475,\n",
       " 'wajib': 476,\n",
       " 'teman': 477,\n",
       " 'tata': 478,\n",
       " 'suruh': 479,\n",
       " 'yah': 480,\n",
       " 'sampah': 481,\n",
       " 'misi': 482,\n",
       " 'terbukti': 483,\n",
       " 'duit': 484,\n",
       " '😅': 485,\n",
       " 'lupa': 486,\n",
       " 'pilihan': 487,\n",
       " 'kegiatan': 488,\n",
       " 'tolol': 489,\n",
       " 'semarang': 490,\n",
       " 'cepat': 491,\n",
       " 'tsb': 492,\n",
       " 'kuat': 493,\n",
       " 'alias': 494,\n",
       " 'salam': 495,\n",
       " 'sunda': 496,\n",
       " 'uu': 497,\n",
       " 'berjuang': 498,\n",
       " 'mengikuti': 499,\n",
       " 'bego': 500,\n",
       " 'citra': 501,\n",
       " 'pemain': 502,\n",
       " 'koalisi': 503,\n",
       " 'ganti': 504,\n",
       " 'pecat': 505,\n",
       " 'berkuasa': 506,\n",
       " 'dasar': 507,\n",
       " 'kosong': 508,\n",
       " 'said': 509,\n",
       " 'dpp': 510,\n",
       " 'ulama': 511,\n",
       " 'mantan': 512,\n",
       " 'marah': 513,\n",
       " '🤣🤣': 514,\n",
       " 'doa': 515,\n",
       " 'ktt': 516,\n",
       " 'pemerintahan': 517,\n",
       " 'tahi': 518,\n",
       " 'penghargaan': 519,\n",
       " 'biaya': 520,\n",
       " 'cc': 521,\n",
       " 'lbh': 522,\n",
       " 'tugas': 523,\n",
       " '😂😂😂': 524,\n",
       " 'badan': 525,\n",
       " 'papua': 526,\n",
       " 'berpikir': 527,\n",
       " 'sengkuni': 528,\n",
       " 'berharap': 529,\n",
       " 'mengunjungi': 530,\n",
       " 'parah': 531,\n",
       " 'ahok': 532,\n",
       " 'bandung': 533,\n",
       " 'ku': 534,\n",
       " 'soeharto': 535,\n",
       " 'kabar': 536,\n",
       " 'beli': 537,\n",
       " 'ha': 538,\n",
       " 'omongan': 539,\n",
       " 'cek': 540,\n",
       " 'ruwet': 541,\n",
       " 'kelas': 542,\n",
       " 'wajah': 543,\n",
       " 'menghina': 544,\n",
       " 'berkunjung': 545,\n",
       " 'ormas': 546,\n",
       " 'kawal': 547,\n",
       " 'lawan': 548,\n",
       " 'setan': 549,\n",
       " 'bambang': 550,\n",
       " 'ilmu': 551,\n",
       " 'p': 552,\n",
       " 'kelebihan': 553,\n",
       " 'olah': 554,\n",
       " 'bumn': 555,\n",
       " 'via': 556,\n",
       " 'j': 557,\n",
       " 'juta': 558,\n",
       " 'pusat': 559,\n",
       " 'perang': 560,\n",
       " 'tukang': 561,\n",
       " 'mengubah': 562,\n",
       " 'kemampuan': 563,\n",
       " 'zaman': 564,\n",
       " 'ahli': 565,\n",
       " 'kebaikan': 566,\n",
       " 'perusahaan': 567,\n",
       " 'komen': 568,\n",
       " 'gus': 569,\n",
       " '😂😂': 570,\n",
       " 'radikal': 571,\n",
       " 'urus': 572,\n",
       " 'jejak': 573,\n",
       " 'padi': 574,\n",
       " 'bareng': 575,\n",
       " 'buang': 576,\n",
       " 'boneka': 577,\n",
       " 'ambisi': 578,\n",
       " 'tanggung': 579,\n",
       " 'ngerti': 580,\n",
       " 'mundur': 581,\n",
       " 'bertemu': 582,\n",
       " 'kecewa': 583,\n",
       " 'berubah': 584,\n",
       " 'pengamat': 585,\n",
       " 'pembela': 586,\n",
       " 'saudara': 587,\n",
       " 'sri': 588,\n",
       " 'patut': 589,\n",
       " 'ham': 590,\n",
       " 'cuman': 591,\n",
       " 'lepas': 592,\n",
       " 'paksa': 593,\n",
       " 'om': 594,\n",
       " 'gaya': 595,\n",
       " 'sepakat': 596,\n",
       " 'membawa': 597,\n",
       " 'hubungan': 598,\n",
       " 'ruang': 599,\n",
       " 'tidur': 600,\n",
       " 'jusuf': 601,\n",
       " 'kesehatan': 602,\n",
       " 'gara': 603,\n",
       " 'puasa': 604,\n",
       " 'positif': 605,\n",
       " 'narasi': 606,\n",
       " 'muncul': 607,\n",
       " 'komplotan': 608,\n",
       " 'suci': 609,\n",
       " 'laku': 610,\n",
       " 'panggung': 611,\n",
       " 'alam': 612,\n",
       " 'musuh': 613,\n",
       " 'ma': 614,\n",
       " 'produk': 615,\n",
       " 'internasional': 616,\n",
       " 'dana': 617,\n",
       " 'hujan': 618,\n",
       " 'kenyataan': 619,\n",
       " 'mencari': 620,\n",
       " 'front': 621,\n",
       " 'cemberut': 622,\n",
       " 'berbeda': 623,\n",
       " 'mulyani': 624,\n",
       " 'konsisten': 625,\n",
       " 'menjabat': 626,\n",
       " 'bentuk': 627,\n",
       " 'inti': 628,\n",
       " 'dewan': 629,\n",
       " 'omong': 630,\n",
       " 'operasi': 631,\n",
       " 'banjir': 632,\n",
       " 'mohon': 633,\n",
       " 'menanggapi': 634,\n",
       " 'wali': 635,\n",
       " 'keturunan': 636,\n",
       " 'pekerja': 637,\n",
       " 'oligarki': 638,\n",
       " 'menghadapi': 639,\n",
       " 'menunggu': 640,\n",
       " 'berat': 641,\n",
       " 'menjalankan': 642,\n",
       " 'bkn': 643,\n",
       " 'mendadak': 644,\n",
       " 'lantas': 645,\n",
       " 'kondisi': 646,\n",
       " 'mikropon': 647,\n",
       " 'solusi': 648,\n",
       " 'anggota': 649,\n",
       " 'banding': 650,\n",
       " 'usia': 651,\n",
       " 'pertanahan': 652,\n",
       " 'nu': 653,\n",
       " 'debat': 654,\n",
       " 'penjara': 655,\n",
       " 'kalla': 656,\n",
       " 'republik': 657,\n",
       " 'korban': 658,\n",
       " 'komunis': 659,\n",
       " 'kagum': 660,\n",
       " 'ko': 661,\n",
       " '11': 662,\n",
       " 'al': 663,\n",
       " 'dirjen': 664,\n",
       " 'korps': 665,\n",
       " 'beruntung': 666,\n",
       " 'kaki': 667,\n",
       " 'kepedulian': 668,\n",
       " 'demo': 669,\n",
       " 'bbm': 670,\n",
       " 'resmi': 671,\n",
       " 'memikirkan': 672,\n",
       " 'hina': 673,\n",
       " 'blunder': 674,\n",
       " 'mulia': 675,\n",
       " 'motor': 676,\n",
       " 'memuji': 677,\n",
       " 'pagar': 678,\n",
       " 'malas': 679,\n",
       " 'kritik': 680,\n",
       " 'pekerjaan': 681,\n",
       " 'menangis': 682,\n",
       " 'membutuhkan': 683,\n",
       " 'pasukan': 684,\n",
       " 'mesti': 685,\n",
       " 'rencana': 686,\n",
       " 'adat': 687,\n",
       " 'beras': 688,\n",
       " 'golkar': 689,\n",
       " 'selesai': 690,\n",
       " 'infrastruktur': 691,\n",
       " 'kiai': 692,\n",
       " 'kesalahan': 693,\n",
       " 'gelandangan': 694,\n",
       " 'cm': 695,\n",
       " 'putri': 696,\n",
       " 'untung': 697,\n",
       " 'pagi': 698,\n",
       " 'teriak': 699,\n",
       " 'membandingkan': 700,\n",
       " 'babi': 701,\n",
       " 'tulus': 702,\n",
       " 'kampanye': 703,\n",
       " 'asuhan': 704,\n",
       " 'budayawan': 705,\n",
       " 'mencalonkan': 706,\n",
       " 'pajak': 707,\n",
       " 'lancar': 708,\n",
       " 'jam': 709,\n",
       " 'ucapan': 710,\n",
       " 'mengakui': 711,\n",
       " 'cita': 712,\n",
       " 'elektabilitas': 713,\n",
       " 'ridwan': 714,\n",
       " 'harap': 715,\n",
       " 'formula': 716,\n",
       " 'berjalan': 717,\n",
       " 'bahan': 718,\n",
       " 'sari': 719,\n",
       " 'kamis': 720,\n",
       " 'mentri': 721,\n",
       " 'kenal': 722,\n",
       " 'manis': 723,\n",
       " 'buta': 724,\n",
       " 'mencapai': 725,\n",
       " 'pancasila': 726,\n",
       " 'lokasi': 727,\n",
       " 'berbuat': 728,\n",
       " 'persen': 729,\n",
       " 'surya': 730,\n",
       " 'karya': 731,\n",
       " 'km': 732,\n",
       " 'beredar': 733,\n",
       " 'bersatu': 734,\n",
       " 'warung': 735,\n",
       " 'pikiran': 736,\n",
       " 'kecoa': 737,\n",
       " 'buku': 738,\n",
       " 'forum': 739,\n",
       " 'bp': 740,\n",
       " 'mendengar': 741,\n",
       " 'gerombolan': 742,\n",
       " 'penjelasan': 743,\n",
       " 'menyerahkan': 744,\n",
       " 'pindah': 745,\n",
       " 'bokep': 746,\n",
       " 'hilang': 747,\n",
       " 'murah': 748,\n",
       " 'tunggu': 749,\n",
       " 'sang': 750,\n",
       " 'berhasil': 751,\n",
       " 'pengembangan': 752,\n",
       " 'merasakan': 753,\n",
       " 'waras': 754,\n",
       " 'halo': 755,\n",
       " 'penyelenggaraan': 756,\n",
       " 'energi': 757,\n",
       " 'bos': 758,\n",
       " 'kereta': 759,\n",
       " 'bantu': 760,\n",
       " 'mewujudkan': 761,\n",
       " 'gratis': 762,\n",
       " 'penyataan': 763,\n",
       " 'nasionalis': 764,\n",
       " 'perbuatan': 765,\n",
       " 'mengatur': 766,\n",
       " 'blusukan': 767,\n",
       " 'ular': 768,\n",
       " 'dengar': 769,\n",
       " 'salut': 770,\n",
       " 'sandiwara': 771,\n",
       " 'malam': 772,\n",
       " 'tu': 773,\n",
       " 'kak': 774,\n",
       " 'gila': 775,\n",
       " 'solo': 776,\n",
       " 'jual': 777,\n",
       " 'konstitusi': 778,\n",
       " 'bahas': 779,\n",
       " 'berkah': 780,\n",
       " 'pakde': 781,\n",
       " 'psi': 782,\n",
       " 'dpt': 783,\n",
       " '🇮🇩': 784,\n",
       " 'junjungan': 785,\n",
       " 'pembenci': 786,\n",
       " 'angkat': 787,\n",
       " 'pesantren': 788,\n",
       " 'embun': 789,\n",
       " 'lengkap': 790,\n",
       " 'haram': 791,\n",
       " 'memperhatikan': 792,\n",
       " 'siswa': 793,\n",
       " 'membuktikan': 794,\n",
       " 'suku': 795,\n",
       " 'sesungguhnya': 796,\n",
       " '👉': 797,\n",
       " 'logika': 798,\n",
       " 'bahagia': 799,\n",
       " 'sungguh': 800,\n",
       " 'daya': 801,\n",
       " 'jin': 802,\n",
       " 'bumi': 803,\n",
       " 'kekayaan': 804,\n",
       " 'memperbaiki': 805,\n",
       " 'permainan': 806,\n",
       " 'menciptakan': 807,\n",
       " 'kesempatan': 808,\n",
       " 'kekasih': 809,\n",
       " 'ketahuan': 810,\n",
       " 'penolakan': 811,\n",
       " 'mengenal': 812,\n",
       " 'kerjaan': 813,\n",
       " 'bergabung': 814,\n",
       " 'pemimpi': 815,\n",
       " 'simak': 816,\n",
       " 'no': 817,\n",
       " 'jualan': 818,\n",
       " 'kemenangan': 819,\n",
       " 'habib': 820,\n",
       " 'bijak': 821,\n",
       " 'kehidupan': 822,\n",
       " 'to': 823,\n",
       " 'rame': 824,\n",
       " 'stop': 825,\n",
       " 'memahami': 826,\n",
       " 'agenda': 827,\n",
       " 'cucu': 828,\n",
       " 'perjanjian': 829,\n",
       " 'terdengar': 830,\n",
       " 'ragu': 831,\n",
       " 'menyalahkan': 832,\n",
       " 'upaya': 833,\n",
       " 'pabrik': 834,\n",
       " 'zalim': 835,\n",
       " 'pro': 836,\n",
       " 'tahan': 837,\n",
       " 'risma': 838,\n",
       " 'panti': 839,\n",
       " 'surabaya': 840,\n",
       " 'kritis': 841,\n",
       " 'kotak': 842,\n",
       " 'survei': 843,\n",
       " 'melarang': 844,\n",
       " 'jaya': 845,\n",
       " 'sambo': 846,\n",
       " 'busuk': 847,\n",
       " 'arah': 848,\n",
       " 'mahasiswa': 849,\n",
       " 'vs': 850,\n",
       " 'pk': 851,\n",
       " 'rekam': 852,\n",
       " 'keliling': 853,\n",
       " '🔥': 854,\n",
       " 'bunuh': 855,\n",
       " 'atur': 856,\n",
       " 'dadah': 857,\n",
       " 'survey': 858,\n",
       " 'sibuk': 859,\n",
       " 'huruf': 860,\n",
       " 'sumur': 861,\n",
       " 'resapan': 862,\n",
       " 'kitab': 863,\n",
       " 'terhormat': 864,\n",
       " 'daftar': 865,\n",
       " 'munafik': 866,\n",
       " 'monyet': 867,\n",
       " 'kebohongan': 868,\n",
       " 'sepatu': 869,\n",
       " 'laporan': 870,\n",
       " 'nyinyir': 871,\n",
       " 'sawah': 872,\n",
       " 'pandai': 873,\n",
       " 'ide': 874,\n",
       " 'berkat': 875,\n",
       " 'mendorong': 876,\n",
       " 'wapres': 877,\n",
       " 'paloh': 878,\n",
       " 'enak': 879,\n",
       " 'm': 880,\n",
       " 'beban': 881,\n",
       " 'makanan': 882,\n",
       " 'persatuan': 883,\n",
       " 'trans': 884,\n",
       " 'emas': 885,\n",
       " 'agung': 886,\n",
       " 'menyamakan': 887,\n",
       " 'keuangan': 888,\n",
       " 'kebahagiaan': 889,\n",
       " 'polri': 890,\n",
       " 'ajak': 891,\n",
       " 'komnas': 892,\n",
       " 'fokus': 893,\n",
       " 'buah': 894,\n",
       " 'mental': 895,\n",
       " 'susilo': 896,\n",
       " 'amanah': 897,\n",
       " 'khawatir': 898,\n",
       " 'aneh': 899,\n",
       " 'kolaborasi': 900,\n",
       " 'persiapan': 901,\n",
       " 'tampik': 902,\n",
       " 'capek': 903,\n",
       " 'maling': 904,\n",
       " 'mensos': 905,\n",
       " '27': 906,\n",
       " 'hutan': 907,\n",
       " 'sistem': 908,\n",
       " 'yuk': 909,\n",
       " 'ketawa': 910,\n",
       " 'mendoakan': 911,\n",
       " 'keras': 912,\n",
       " 'aktif': 913,\n",
       " 'engkau': 914,\n",
       " 'pelaku': 915,\n",
       " 'arahan': 916,\n",
       " 'bersinergi': 917,\n",
       " 'kek': 918,\n",
       " 'sanksi': 919,\n",
       " 'waspada': 920,\n",
       " 'kehilangan': 921,\n",
       " 'kabinet': 922,\n",
       " 'kuasa': 923,\n",
       " 'kelak': 924,\n",
       " 'serius': 925,\n",
       " 'kang': 926,\n",
       " 'mengerti': 927,\n",
       " 'diskusi': 928,\n",
       " 'prinsip': 929,\n",
       " 'biang': 930,\n",
       " 'raga': 931,\n",
       " 'wanita': 932,\n",
       " 'rendah': 933,\n",
       " 'kekalutan': 934,\n",
       " 'jongos': 935,\n",
       " 'pengecut': 936,\n",
       " 'nusantara': 937,\n",
       " 'subsidi': 938,\n",
       " 'insyaallah': 939,\n",
       " 'bermain': 940,\n",
       " 'sulit': 941,\n",
       " 'merusak': 942,\n",
       " 'saking': 943,\n",
       " 'menanam': 944,\n",
       " 'larang': 945,\n",
       " 'pendapat': 946,\n",
       " 'urutan': 947,\n",
       " 'menarik': 948,\n",
       " 'peringatan': 949,\n",
       " '2014': 950,\n",
       " 'berkomentar': 951,\n",
       " 'pasar': 952,\n",
       " 'jago': 953,\n",
       " 'timur': 954,\n",
       " 'menjilat': 955,\n",
       " 'usaha': 956,\n",
       " 'cikeas': 957,\n",
       " 'sungai': 958,\n",
       " 'melayani': 959,\n",
       " 'desember': 960,\n",
       " 'hajat': 961,\n",
       " 'pemikiran': 962,\n",
       " '👈': 963,\n",
       " 'barang': 964,\n",
       " 'menandai': 965,\n",
       " 'usung': 966,\n",
       " 'benci': 967,\n",
       " 'komunikasi': 968,\n",
       " 'waduk': 969,\n",
       " 'kejujuran': 970,\n",
       " 'tanam': 971,\n",
       " 'bisnis': 972,\n",
       " 'lapor': 973,\n",
       " 'palsu': 974,\n",
       " 'kehadiran': 975,\n",
       " 'tuk': 976,\n",
       " 'ribut': 977,\n",
       " 'keselamatan': 978,\n",
       " 'roboh': 979,\n",
       " 'kandidat': 980,\n",
       " 'bismillah': 981,\n",
       " 'pecel': 982,\n",
       " 'masak': 983,\n",
       " 'peristiwa': 984,\n",
       " 'wilayah': 985,\n",
       " 'antek': 986,\n",
       " 'ulah': 987,\n",
       " 'karakter': 988,\n",
       " 'meninggalkan': 989,\n",
       " 'kades': 990,\n",
       " 'panas': 991,\n",
       " 'pesan': 992,\n",
       " 'umkm': 993,\n",
       " 'modal': 994,\n",
       " 'hitam': 995,\n",
       " 'ekspresi': 996,\n",
       " 'kuliah': 997,\n",
       " 'hotel': 998,\n",
       " 'kebencian': 999,\n",
       " 'kemaren': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Sequence</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_train = tokenizer.texts_to_sequences(X_train)\n",
    "sequence_test = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Padding</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "X_train = pad_sequences(sequence_train, maxlen=100, padding='post', truncating='post')\n",
    "X_test = pad_sequences(sequence_test, maxlen=100, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 269,  242,  786,   19,   37,   14,  858,  284,   81,   19,  200,\n",
       "        713,   17,   17,   29,   17,  465, 3800,    5,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Build Matrix Embedding</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coefs(word,*arr): \n",
    "    return word, np.asarray(arr, dtype='float32')\n",
    "\n",
    "def load_embedding(file):\n",
    "    embeddings_index = dict(get_coefs(*i.split(\" \")) for i in open(file, encoding='utf-8'))\n",
    "    \n",
    "    return embeddings_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_embedding_matrix(embedding, tokenizer, len_voc):\n",
    "    all_embs = np.stack(embedding.values())\n",
    "    emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "    embed_size = all_embs.shape[1]\n",
    "    word_index = tokenizer.word_index\n",
    "    # embedding_matrix = np.random.normal(emb_mean, emb_std, (len_voc, embed_size))\n",
    "    embedding_matrix = np.zeros((len_voc, embed_size))\n",
    "    \n",
    "    for word, i in word_index.items():\n",
    "        if i >= len_voc:\n",
    "            continue\n",
    "        embedding_vector = embedding.get(word)\n",
    "        if embedding_vector is not None: \n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    \n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove = load_embedding('Misc/Embeddings/embeddings100D.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py:3378: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "embed_matrix = make_embedding_matrix(glove, tokenizer, len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6519, 100)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Implement SMOTE</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_values, value_counts = np.unique(y_train_resampled, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 2012\n",
      "1: 2012\n"
     ]
    }
   ],
   "source": [
    "for value, count in zip(unique_values, value_counts):\n",
    "    print(f\"{value}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Create Bi-LSTM Architecture</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 100, 100)          1000000   \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 200)              160800    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 200)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                12864     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,173,729\n",
      "Trainable params: 1,173,729\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_bilstm = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Embedding(10000, 100, input_length=100),\n",
    "        tf.keras.layers.Bidirectional(LSTM(100, dropout=0,recurrent_dropout=0)),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Create Optimizer\n",
    "model_bilstm.compile(\n",
    "        optimizer='adam',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model_bilstm.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Train Model Bi-LSTM</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    if(logs.get('accuracy')>=0.8): #logs.get('val_accuracy')>0.8\n",
    "      print(\"\\nAkurasi telah mencapai > 75%!\")\n",
    "      self.model.stop_training = True\n",
    "callbacks = myCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "126/126 - 13s - loss: 0.6791 - accuracy: 0.5589 - val_loss: 0.6282 - val_accuracy: 0.6856 - 13s/epoch - 104ms/step\n",
      "Epoch 2/10\n",
      "126/126 - 9s - loss: 0.5223 - accuracy: 0.7510 - val_loss: 0.7207 - val_accuracy: 0.6492 - 9s/epoch - 68ms/step\n",
      "Epoch 3/10\n",
      "126/126 - 9s - loss: 0.3236 - accuracy: 0.8588 - val_loss: 0.8901 - val_accuracy: 0.6128 - 9s/epoch - 69ms/step\n",
      "Epoch 4/10\n",
      "126/126 - 9s - loss: 0.1799 - accuracy: 0.9299 - val_loss: 1.1493 - val_accuracy: 0.6469 - 9s/epoch - 69ms/step\n",
      "Epoch 5/10\n",
      "126/126 - 9s - loss: 0.1072 - accuracy: 0.9583 - val_loss: 1.3334 - val_accuracy: 0.6720 - 9s/epoch - 68ms/step\n",
      "Epoch 6/10\n",
      "126/126 - 9s - loss: 0.0453 - accuracy: 0.9851 - val_loss: 1.8363 - val_accuracy: 0.6970 - 9s/epoch - 69ms/step\n",
      "Epoch 7/10\n",
      "126/126 - 9s - loss: 0.0190 - accuracy: 0.9945 - val_loss: 2.2027 - val_accuracy: 0.7039 - 9s/epoch - 69ms/step\n",
      "Epoch 8/10\n",
      "126/126 - 9s - loss: 0.0299 - accuracy: 0.9925 - val_loss: 1.8093 - val_accuracy: 0.6879 - 9s/epoch - 69ms/step\n",
      "Epoch 9/10\n",
      "126/126 - 9s - loss: 0.0220 - accuracy: 0.9940 - val_loss: 1.8406 - val_accuracy: 0.6948 - 9s/epoch - 68ms/step\n",
      "Epoch 10/10\n",
      "126/126 - 9s - loss: 0.0120 - accuracy: 0.9963 - val_loss: 1.9653 - val_accuracy: 0.7175 - 9s/epoch - 68ms/step\n"
     ]
    }
   ],
   "source": [
    "history_bilstm = model_bilstm.fit(\n",
    "        X_train_resampled,\n",
    "        y_train_resampled,\n",
    "        epochs=10,\n",
    "        validation_data=(X_test, y_test),\n",
    "        verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Create LSTM Architecture</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 100, 100)          1000000   \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 100)               80400     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                6464      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,086,929\n",
      "Trainable params: 1,086,929\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_lstm = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Embedding(10000, 100, input_length=100),\n",
    "        tf.keras.layers.LSTM(100),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Create Optimizer\n",
    "model_lstm.compile(\n",
    "        optimizer='adam',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model_lstm.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Train Model LSTM</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "126/126 - 9s - loss: 0.6941 - accuracy: 0.4973 - val_loss: 0.6925 - val_accuracy: 0.5285 - 9s/epoch - 70ms/step\n",
      "Epoch 2/10\n",
      "126/126 - 7s - loss: 0.6940 - accuracy: 0.4801 - val_loss: 0.6931 - val_accuracy: 0.5285 - 7s/epoch - 52ms/step\n",
      "Epoch 3/10\n",
      "126/126 - 6s - loss: 0.6934 - accuracy: 0.5002 - val_loss: 0.6935 - val_accuracy: 0.4715 - 6s/epoch - 52ms/step\n",
      "Epoch 4/10\n",
      "126/126 - 7s - loss: 0.6933 - accuracy: 0.4925 - val_loss: 0.6929 - val_accuracy: 0.5285 - 7s/epoch - 52ms/step\n",
      "Epoch 5/10\n",
      "126/126 - 6s - loss: 0.6934 - accuracy: 0.4901 - val_loss: 0.6940 - val_accuracy: 0.4715 - 6s/epoch - 51ms/step\n",
      "Epoch 6/10\n",
      "126/126 - 6s - loss: 0.6938 - accuracy: 0.4881 - val_loss: 0.6932 - val_accuracy: 0.4715 - 6s/epoch - 51ms/step\n",
      "Epoch 7/10\n",
      "126/126 - 6s - loss: 0.6933 - accuracy: 0.4975 - val_loss: 0.6928 - val_accuracy: 0.5285 - 6s/epoch - 51ms/step\n",
      "Epoch 8/10\n",
      "126/126 - 6s - loss: 0.6934 - accuracy: 0.4943 - val_loss: 0.6929 - val_accuracy: 0.5285 - 6s/epoch - 51ms/step\n",
      "Epoch 9/10\n",
      "126/126 - 6s - loss: 0.6935 - accuracy: 0.4950 - val_loss: 0.6926 - val_accuracy: 0.5285 - 6s/epoch - 51ms/step\n",
      "Epoch 10/10\n",
      "126/126 - 6s - loss: 0.6932 - accuracy: 0.4980 - val_loss: 0.6933 - val_accuracy: 0.4715 - 6s/epoch - 50ms/step\n"
     ]
    }
   ],
   "source": [
    "history_lstm = model_lstm.fit(\n",
    "        X_train_resampled,\n",
    "        y_train_resampled,\n",
    "        epochs=10,\n",
    "        validation_data=(X_test, y_test),\n",
    "        verbose=2\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
