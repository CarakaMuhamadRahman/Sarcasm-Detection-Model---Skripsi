{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4510 entries, 0 to 4509\n",
      "Data columns (total 17 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Unnamed: 0      4510 non-null   int64  \n",
      " 1   Text            4510 non-null   object \n",
      " 2   emoji           4510 non-null   object \n",
      " 3   Tokenized       4510 non-null   object \n",
      " 4   final_text      4494 non-null   object \n",
      " 5   text_emoji      4510 non-null   object \n",
      " 6   Pos_Word        4510 non-null   int64  \n",
      " 7   Neg_Word        4510 non-null   int64  \n",
      " 8   Total_Word      4510 non-null   int64  \n",
      " 9   Pos_Ratio       4510 non-null   float64\n",
      " 10  Neg_Ratio       4510 non-null   float64\n",
      " 11  Sentimen_Text   4510 non-null   object \n",
      " 12  Tokenize_Emoji  4510 non-null   object \n",
      " 13  Pos_Emoji       4510 non-null   int64  \n",
      " 14  Neg_Emoji       4510 non-null   int64  \n",
      " 15  Sentimen_Emoji  4510 non-null   object \n",
      " 16  Sarcasm         4510 non-null   object \n",
      "dtypes: float64(2), int64(6), object(9)\n",
      "memory usage: 599.1+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Text</th>\n",
       "      <th>emoji</th>\n",
       "      <th>Tokenized</th>\n",
       "      <th>final_text</th>\n",
       "      <th>text_emoji</th>\n",
       "      <th>Pos_Word</th>\n",
       "      <th>Neg_Word</th>\n",
       "      <th>Total_Word</th>\n",
       "      <th>Pos_Ratio</th>\n",
       "      <th>Neg_Ratio</th>\n",
       "      <th>Sentimen_Text</th>\n",
       "      <th>Tokenize_Emoji</th>\n",
       "      <th>Pos_Emoji</th>\n",
       "      <th>Neg_Emoji</th>\n",
       "      <th>Sentimen_Emoji</th>\n",
       "      <th>Sarcasm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>kawan2 sunda bersatu jemput arteria dahlan</td>\n",
       "      <td>游때</td>\n",
       "      <td>['kawan', 'sunda', 'bersatu', 'jemput', 'arter...</td>\n",
       "      <td>kawan sunda bersatu jemput arteria dahlan</td>\n",
       "      <td>kawan sunda bersatu jemput arteria dahlan 游때</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Positif</td>\n",
       "      <td>['kawan', 'sunda', 'bersatu', 'jemput', 'arter...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Positif</td>\n",
       "      <td>Negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>arteria dahlan disidang adat sunda daerah menu...</td>\n",
       "      <td>游때</td>\n",
       "      <td>['arteria', 'dahlan', 'sidang', 'adat', 'sunda...</td>\n",
       "      <td>arteria dahlan sidang adat sunda daerah menunt...</td>\n",
       "      <td>arteria dahlan sidang adat sunda daerah menunt...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>Positif</td>\n",
       "      <td>['arteria', 'dahlan', 'sidang', 'adat', 'sunda...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Positif</td>\n",
       "      <td>Negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>ga ditafsirkan membanding bandingkan edy arter...</td>\n",
       "      <td>游때</td>\n",
       "      <td>['ga', 'tafsir', 'membanding', 'membandingkan'...</td>\n",
       "      <td>ga tafsir membanding membandingkan edy arteria...</td>\n",
       "      <td>ga tafsir membanding membandingkan edy arteria...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>Positif</td>\n",
       "      <td>['ga', 'tafsir', 'membanding', 'membandingkan'...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Positif</td>\n",
       "      <td>Negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>nantik ngak divhumas polri nya bilang palsu td...</td>\n",
       "      <td>游때</td>\n",
       "      <td>['nanti', 'tidak', 'divisi humas', 'polri', '....</td>\n",
       "      <td>divisi humas polri bilang palsu mengeluarkan a...</td>\n",
       "      <td>divisi humas polri bilang palsu mengeluarkan a...</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>Negatif</td>\n",
       "      <td>['divisi', 'humas', 'polri', 'bilang', 'palsu'...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Positif</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>urut dada dech kuasa hukum tdk mengerti hukum ...</td>\n",
       "      <td>游때</td>\n",
       "      <td>['urut', 'dada', 'deh', 'kuasa', 'hukum', 'tid...</td>\n",
       "      <td>urut dada deh kuasa hukum mengerti hukum arter...</td>\n",
       "      <td>urut dada deh kuasa hukum mengerti hukum arter...</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>28</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>Positif</td>\n",
       "      <td>['urut', 'dada', 'deh', 'kuasa', 'hukum', 'men...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Positif</td>\n",
       "      <td>Negatif</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               Text  \\\n",
       "0           0         kawan2 sunda bersatu jemput arteria dahlan   \n",
       "1           2  arteria dahlan disidang adat sunda daerah menu...   \n",
       "2           4  ga ditafsirkan membanding bandingkan edy arter...   \n",
       "3           5  nantik ngak divhumas polri nya bilang palsu td...   \n",
       "4           6  urut dada dech kuasa hukum tdk mengerti hukum ...   \n",
       "\n",
       "                           emoji  \\\n",
       "0                              游때   \n",
       "1                              游때   \n",
       "2                              游때   \n",
       "3                              游때   \n",
       "4                              游때   \n",
       "\n",
       "                                           Tokenized  \\\n",
       "0  ['kawan', 'sunda', 'bersatu', 'jemput', 'arter...   \n",
       "1  ['arteria', 'dahlan', 'sidang', 'adat', 'sunda...   \n",
       "2  ['ga', 'tafsir', 'membanding', 'membandingkan'...   \n",
       "3  ['nanti', 'tidak', 'divisi humas', 'polri', '....   \n",
       "4  ['urut', 'dada', 'deh', 'kuasa', 'hukum', 'tid...   \n",
       "\n",
       "                                          final_text  \\\n",
       "0          kawan sunda bersatu jemput arteria dahlan   \n",
       "1  arteria dahlan sidang adat sunda daerah menunt...   \n",
       "2  ga tafsir membanding membandingkan edy arteria...   \n",
       "3  divisi humas polri bilang palsu mengeluarkan a...   \n",
       "4  urut dada deh kuasa hukum mengerti hukum arter...   \n",
       "\n",
       "                                          text_emoji  Pos_Word  Neg_Word  \\\n",
       "0        kawan sunda bersatu jemput arteria dahlan 游때         2         0   \n",
       "1  arteria dahlan sidang adat sunda daerah menunt...         5         4   \n",
       "2  ga tafsir membanding membandingkan edy arteria...         3         2   \n",
       "3  divisi humas polri bilang palsu mengeluarkan a...         4         8   \n",
       "4  urut dada deh kuasa hukum mengerti hukum arter...        14         6   \n",
       "\n",
       "   Total_Word  Pos_Ratio  Neg_Ratio Sentimen_Text  \\\n",
       "0           6   0.333333   0.000000       Positif   \n",
       "1           9   0.555556   0.444444       Positif   \n",
       "2           9   0.333333   0.222222       Positif   \n",
       "3          16   0.250000   0.500000       Negatif   \n",
       "4          28   0.500000   0.214286       Positif   \n",
       "\n",
       "                                      Tokenize_Emoji  Pos_Emoji  Neg_Emoji  \\\n",
       "0  ['kawan', 'sunda', 'bersatu', 'jemput', 'arter...          1          0   \n",
       "1  ['arteria', 'dahlan', 'sidang', 'adat', 'sunda...          1          0   \n",
       "2  ['ga', 'tafsir', 'membanding', 'membandingkan'...          1          0   \n",
       "3  ['divisi', 'humas', 'polri', 'bilang', 'palsu'...          1          0   \n",
       "4  ['urut', 'dada', 'deh', 'kuasa', 'hukum', 'men...          1          0   \n",
       "\n",
       "  Sentimen_Emoji  Sarcasm  \n",
       "0        Positif  Negatif  \n",
       "1        Positif  Negatif  \n",
       "2        Positif  Negatif  \n",
       "3        Positif  Positif  \n",
       "4        Positif  Negatif  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('Datasets_Ready.xlsx')\n",
    "\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unused column/feature\n",
    "df = df.drop(columns='Unnamed: 0')\n",
    "df = df.drop(columns='Text')\n",
    "df = df.drop(columns='emoji')\n",
    "df = df.drop(columns='Tokenized')\n",
    "df = df.drop(columns='final_text')\n",
    "df = df.drop(columns='Pos_Word')\n",
    "df = df.drop(columns='Neg_Word')\n",
    "df = df.drop(columns='Total_Word')\n",
    "df = df.drop(columns='Pos_Ratio')\n",
    "df = df.drop(columns='Neg_Ratio')\n",
    "df = df.drop(columns='Tokenize_Emoji')\n",
    "df = df.drop(columns='Pos_Emoji')\n",
    "df = df.drop(columns='Neg_Emoji')\n",
    "df = df.drop(columns='Sentimen_Emoji')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_emoji</th>\n",
       "      <th>Sentimen_Text</th>\n",
       "      <th>Sarcasm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kawan sunda bersatu jemput arteria dahlan 游때</td>\n",
       "      <td>Positif</td>\n",
       "      <td>Negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>arteria dahlan sidang adat sunda daerah menunt...</td>\n",
       "      <td>Positif</td>\n",
       "      <td>Negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ga tafsir membanding membandingkan edy arteria...</td>\n",
       "      <td>Positif</td>\n",
       "      <td>Negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>divisi humas polri bilang palsu mengeluarkan a...</td>\n",
       "      <td>Negatif</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>urut dada deh kuasa hukum mengerti hukum arter...</td>\n",
       "      <td>Positif</td>\n",
       "      <td>Negatif</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          text_emoji Sentimen_Text  Sarcasm\n",
       "0        kawan sunda bersatu jemput arteria dahlan 游때       Positif  Negatif\n",
       "1  arteria dahlan sidang adat sunda daerah menunt...       Positif  Negatif\n",
       "2  ga tafsir membanding membandingkan edy arteria...       Positif  Negatif\n",
       "3  divisi humas polri bilang palsu mengeluarkan a...       Negatif  Positif\n",
       "4  urut dada deh kuasa hukum mengerti hukum arter...       Positif  Negatif"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ready = df[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Negatif    13\n",
       "Positif     7\n",
       "Name: Sarcasm, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ready['Sarcasm'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_6756\\3562434511.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ready['Sentimen_Text'] = df_ready['Sentimen_Text'].replace('Positif', 1)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_6756\\3562434511.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ready['Sentimen_Text'] = df_ready['Sentimen_Text'].replace('Negatif', 0)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_6756\\3562434511.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ready['Sarcasm'] = df_ready['Sarcasm'].replace('Positif', 1)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_6756\\3562434511.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ready['Sarcasm'] = df_ready['Sarcasm'].replace('Negatif', 0)\n"
     ]
    }
   ],
   "source": [
    "df_ready['Sentimen_Text'] = df_ready['Sentimen_Text'].replace('Positif', 1)\n",
    "df_ready['Sentimen_Text'] = df_ready['Sentimen_Text'].replace('Negatif', 0)\n",
    "\n",
    "df_ready['Sarcasm'] = df_ready['Sarcasm'].replace('Positif', 1)\n",
    "df_ready['Sarcasm'] = df_ready['Sarcasm'].replace('Negatif', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    13\n",
       "1     7\n",
       "Name: Sarcasm, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ready['Sarcasm'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 13, 1: 7})\n"
     ]
    }
   ],
   "source": [
    "print(Counter(df_ready['Sarcasm']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 50\n",
    "len_voc = 40000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train, df_test = train_test_split(df_ready, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing\n",
    "def make_tokenizer(texts, len_voc):\n",
    "    from keras.preprocessing.text import Tokenizer\n",
    "    t = Tokenizer(num_words=len_voc)\n",
    "    t.fit_on_texts(texts)\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = make_tokenizer(df_ready['text_emoji'], len_voc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'arteria': 1,\n",
       " '游때': 2,\n",
       " 'dahlan': 3,\n",
       " 'sunda': 4,\n",
       " 'hukum': 5,\n",
       " 'goblok': 6,\n",
       " 'maaf': 7,\n",
       " 'masyarakat': 8,\n",
       " 'jabar': 9,\n",
       " 'indonesia': 10,\n",
       " 'pejabat': 11,\n",
       " 'bahasa': 12,\n",
       " 'mak': 13,\n",
       " 'polisi': 14,\n",
       " 'adat': 15,\n",
       " 'ga': 16,\n",
       " 'polri': 17,\n",
       " 'plat': 18,\n",
       " 'tsb': 19,\n",
       " 'memaafkan': 20,\n",
       " 'partai': 21,\n",
       " 'demokrasi': 22,\n",
       " 'perjuangan': 23,\n",
       " 'mendadak': 24,\n",
       " 'lu': 25,\n",
       " 'takut': 26,\n",
       " 'doang': 27,\n",
       " 'komentar': 28,\n",
       " 'kawan': 29,\n",
       " 'bersatu': 30,\n",
       " 'jemput': 31,\n",
       " 'sidang': 32,\n",
       " 'daerah': 33,\n",
       " 'menuntut': 34,\n",
       " 'tafsir': 35,\n",
       " 'membanding': 36,\n",
       " 'membandingkan': 37,\n",
       " 'edy': 38,\n",
       " 'menegakkan': 39,\n",
       " 'divisi': 40,\n",
       " 'humas': 41,\n",
       " 'bilang': 42,\n",
       " 'palsu': 43,\n",
       " 'mengeluarkan': 44,\n",
       " 'membenarkan': 45,\n",
       " 'no': 46,\n",
       " 'asli': 47,\n",
       " 'urut': 48,\n",
       " 'dada': 49,\n",
       " 'deh': 50,\n",
       " 'kuasa': 51,\n",
       " 'mengerti': 52,\n",
       " 'dengar': 53,\n",
       " 'pendapat': 54,\n",
       " 'gedung': 55,\n",
       " 'dpr': 56,\n",
       " 'memiliki': 57,\n",
       " 'kekebalan': 58,\n",
       " 'atur': 59,\n",
       " 'konstitusi': 60,\n",
       " 'n': 61,\n",
       " 'uu': 62,\n",
       " 'kubu': 63,\n",
       " 'saran': 64,\n",
       " 'dorong': 65,\n",
       " 'menangkap': 66,\n",
       " 'semoga': 67,\n",
       " 'berpegang': 68,\n",
       " 'komitmen': 69,\n",
       " 'menenggelamkan': 70,\n",
       " 'spt': 71,\n",
       " 'sumbar': 72,\n",
       " 'beruntung': 73,\n",
       " 'kabar': 74,\n",
       " 'e': 75,\n",
       " 'hina': 76,\n",
       " 'suku': 77,\n",
       " 'sakit': 78,\n",
       " 'jiwa': 79,\n",
       " 'menantang': 80,\n",
       " 'rakyat': 81,\n",
       " 'turun': 82,\n",
       " 'kelar': 83,\n",
       " 'provinsi': 84,\n",
       " 'manusia': 85,\n",
       " 'pasteur': 86,\n",
       " 'bandung': 87,\n",
       " 'mulut': 88,\n",
       " 'busuk': 89,\n",
       " 'acara': 90,\n",
       " 'resmi': 91,\n",
       " 'pakai': 92,\n",
       " 'tp': 93,\n",
       " 'penyelenggaraan': 94,\n",
       " 'sanksi': 95,\n",
       " 'memecat': 96,\n",
       " 'congkak': 97,\n",
       " 'arogan': 98,\n",
       " 'yak': 99,\n",
       " 'coba': 100,\n",
       " 'mas': 101,\n",
       " 'kali': 102,\n",
       " 'mengganti': 103,\n",
       " 'bangun': 104,\n",
       " 'cerdik': 105,\n",
       " 'tamparan': 106,\n",
       " 'terdaftar': 107,\n",
       " 'milik': 108,\n",
       " 'emang': 109,\n",
       " 'gemas': 110,\n",
       " 'ama': 111,\n",
       " 'elu': 112,\n",
       " '1': 113,\n",
       " 'gitu': 114,\n",
       " 'memperbaiki': 115,\n",
       " 'butuh': 116,\n",
       " 'suara': 117,\n",
       " '2024': 118,\n",
       " 'kau': 119,\n",
       " 'injakan': 120,\n",
       " 'kaki': 121,\n",
       " 'tanah': 122,\n",
       " 'jahat': 123,\n",
       " 'pernyataan': 124,\n",
       " 'berbicara': 125,\n",
       " 'pecat': 126,\n",
       " 'bikin': 127,\n",
       " 'kena': 128,\n",
       " 'mental': 129,\n",
       " 'orang': 130,\n",
       " 'hajat': 131,\n",
       " 'pernikahan': 132,\n",
       " 'undang': 133,\n",
       " 'kusnandar': 134,\n",
       " 'cari': 135,\n",
       " 'guru': 136,\n",
       " 'santet': 137}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tokenizer.texts_to_sequences(df_train['text_emoji'])\n",
    "X_test = tokenizer.texts_to_sequences(df_test['text_emoji'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import pad_sequences\n",
    "\n",
    "X_train = pad_sequences(X_train, maxlen=max_len, padding='post', truncating='post')\n",
    "X_test = pad_sequences(X_test, maxlen=max_len, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train['Sarcasm'].values\n",
    "y_test = df_test['Sarcasm'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 0, 1, 1, 0, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 0, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_label = np.hstack((y_train, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20,)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coefs(word,*arr): \n",
    "    return word, np.asarray(arr, dtype='float32')\n",
    "\n",
    "def load_embedding(file):\n",
    "    if file == '../input/embeddings/wiki-news-300d-1M/wiki-news-300d-1M.vec':\n",
    "        embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(file) if len(o)>100)\n",
    "    else:\n",
    "        embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(file, encoding='latin'))\n",
    "    return embeddings_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_embedding_matrix(embedding, tokenizer, len_voc):\n",
    "    all_embs = np.stack(embedding.values())\n",
    "    emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "    embed_size = all_embs.shape[1]\n",
    "    word_index = tokenizer.word_index\n",
    "    embedding_matrix = np.random.normal(emb_mean, emb_std, (len_voc, embed_size))\n",
    "    \n",
    "    for word, i in word_index.items():\n",
    "        if i >= len_voc:\n",
    "            continue\n",
    "        embedding_vector = embedding.get(word)\n",
    "        if embedding_vector is not None: \n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    \n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove = load_embedding('embeddings.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py:3378: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "embed_mat = make_embedding_matrix(glove, tokenizer, len_voc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_emb = embed_mat[X_train]\n",
    "X_test_emb = embed_mat[X_test]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>SMOTE</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distances(X_minority, X_majority):\n",
    "    distances = cdist(X_minority, X_majority)\n",
    "    return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neighbors(distances, k):\n",
    "    neighbors = np.argsort(distances)[:, :k]\n",
    "    return neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_samples(X_minority, neighbors):\n",
    "    synthetic_samples = []\n",
    "    for i in range(len(X_minority)):\n",
    "        nn = np.random.choice(neighbors[i])\n",
    "        alpha = np.random.uniform(0, 1)\n",
    "        synthetic_sample = X_minority[i] + alpha * (X_minority[nn] - X_minority[i])\n",
    "        synthetic_samples.append(synthetic_sample)\n",
    "    synthetic_samples = np.array(synthetic_samples)\n",
    "    return synthetic_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smote(X_minority, y_minority, k):\n",
    "    minority_size = len(df_ready[df_ready['Sarcasm']==1])\n",
    "    majority_size = len(df_ready[df_ready['Sarcasm']==0])\n",
    "    \n",
    "    # Menghitung jumlah tetangga terdekat berdasarkan perbandingan antara jumlah sampel minoritas dan mayoritas\n",
    "    k_neighbors = int((majority_size / minority_size) * k)\n",
    "\n",
    "    # Menghitung jarak antara sampel minoritas dan mayoritas\n",
    "    distances = calculate_distances(X_minority, X_minority)\n",
    "    \n",
    "    # Mendapatkan tetangga terdekat untuk setiap sampel minoritas\n",
    "    neighbors = get_neighbors(distances, k_neighbors)\n",
    "    \n",
    "    # Menghasilkan sampel sintetis\n",
    "    synthetic_samples = generate_synthetic_samples(X_minority, neighbors)\n",
    "    \n",
    "    # Menggabungkan sampel minoritas asli dengan sampel sintetis\n",
    "    X_oversampled = np.vstack((X_minority, synthetic_samples))\n",
    "    y_oversampled = np.hstack((y_minority, np.ones(len(synthetic_samples))))\n",
    "    \n",
    "    return X_oversampled, y_oversampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_minority = X_train[y_train == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_oversampled, y_oversampled = smote(X_minority, X_sentiment_minority, y_minority)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_size, max_len, embed_size = X_train_emb.shape\n",
    "# X_train_emb_r = X_train_emb.reshape(train_size, max_len*embed_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_size, max_len, embed_size = X_test_emb.shape\n",
    "# X_test_emb_r = X_test_emb.reshape(test_size, max_len*embed_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack = np.vstack((X_train_emb_r, X_test_emb_r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# smt = SMOTE()\n",
    "# df_smote = smt.fit_resample(stack, stack_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_smote[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique_values, value_counts = np.unique(df_smote[1], return_counts=True)\n",
    "\n",
    "# print(unique_values)\n",
    "# print(value_counts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
